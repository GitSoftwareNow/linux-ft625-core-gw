diff --git a/Documentation/devicetree/bindings/gpio/gpio-phytium.txt b/Documentation/devicetree/bindings/gpio/gpio-phytium.txt
new file mode 100644
index 000000000000..77d4c6c03d00
--- /dev/null
+++ b/Documentation/devicetree/bindings/gpio/gpio-phytium.txt
@@ -0,0 +1,47 @@
+* Phytium GPIO controller
+
+Required properties:
+- compatible : Should contain "phytium,gpio"
+- reg : Address and length of the register set for the device.
+- interrupts: Interrupt mapping for GPIO IRQ.
+- gpio-controller : Marks the device node as a gpio controller.
+- #gpio-cells : Should be 2. The first cell is the pin number and
+  the second cell is used to specify the gpio polarity:
+      0 = active high
+      1 = active low
+- #address-cells : should be 1 (for addressing port subnodes).
+- #size-cells : should be 0 (port subnodes).
+
+The GPIO controller has two ports, each of which are represented as child
+nodes with the following properties:
+
+Required properties:
+- compatible : "phytium,gpio-port"
+- reg : The integer port index of the port, a single cell.
+
+Optional properties:
+- nr-gpios : The number of pins in the port, a single cell.
+
+Example:
+
+gpio: gpio@28004000 {
+	compatible = "phytium,gpio";
+	reg = <0x0 0x28004000 0x0 0x1000>;
+	interrupts = <GIC_SPI 10 IRQ_TYPE_LEVEL_HIGH>;
+	gpio-controller;
+	#gpio-cells = <2>;
+	#address-cells = <1>;
+	#size-cells = <0>;
+
+	porta {
+		compatible = "phytium,gpio-port";
+		reg = <0>;
+		nr-gpios = <8>;
+	};
+
+	portb {
+		compatible = "phytium,gpio-port";
+		reg = <1>;
+		nr-gpios = <8>;
+	};
+};
diff --git a/arch/arm64/Kconfig.platforms b/arch/arm64/Kconfig.platforms
index 393d2b524284..636822d28503 100644
--- a/arch/arm64/Kconfig.platforms
+++ b/arch/arm64/Kconfig.platforms
@@ -139,6 +139,12 @@ config ARCH_MVEBU
 	   - Armada 7K SoC Family
 	   - Armada 8K SoC Family
 
+config ARCH_PHYTIUM
+	bool "Phytium SoC Family"
+	help
+	  This enables support for Phytium ARMv8 SoC family.
+	select ARM_GIC_PHYTIUM_2500
+
 config ARCH_QCOM
 	bool "Qualcomm Platforms"
 	select GPIOLIB
diff --git a/arch/arm64/boot/dts/Makefile b/arch/arm64/boot/dts/Makefile
index 4690364d584b..ff8820d78db5 100644
--- a/arch/arm64/boot/dts/Makefile
+++ b/arch/arm64/boot/dts/Makefile
@@ -16,6 +16,7 @@ subdir-y += lg
 subdir-y += marvell
 subdir-y += mediatek
 subdir-y += nvidia
+subdir-y += phytium
 subdir-y += qcom
 subdir-y += realtek
 subdir-y += renesas
diff --git a/arch/arm64/boot/dts/phytium/Makefile b/arch/arm64/boot/dts/phytium/Makefile
new file mode 100644
index 000000000000..3f82e7ac8301
--- /dev/null
+++ b/arch/arm64/boot/dts/phytium/Makefile
@@ -0,0 +1,9 @@
+dtb-$(CONFIG_ARCH_PHYTIUM) += ft2004-devboard-d4-dsk.dtb
+dtb-$(CONFIG_ARCH_PHYTIUM) += ft1500a-devboard-16c-dsk.dtb
+dtb-$(CONFIG_ARCH_PHYTIUM) += ft2000plus-SR-devboard-64c-dsk.dtb
+dtb-$(CONFIG_ARCH_PHYTIUM) += ft2000plus-MR-devboard-64c-dsk.dtb
+dtb-$(CONFIG_ARCH_PHYTIUM) += ft2000ahk-devboard-dsk.dtb
+
+always		:= $(dtb-y)
+subdir-y	:= $(dts-dirs)
+clean-files	:= *.dtb
diff --git a/arch/arm64/boot/dts/phytium/ft1500a-16c-generic-psci-soc.dtsi b/arch/arm64/boot/dts/phytium/ft1500a-16c-generic-psci-soc.dtsi
new file mode 100644
index 000000000000..5cff9c2f100f
--- /dev/null
+++ b/arch/arm64/boot/dts/phytium/ft1500a-16c-generic-psci-soc.dtsi
@@ -0,0 +1,511 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * dts file for FT-1500A SoC
+ *
+ * Copyright (C) 2019, Phytium Technology Co., Ltd.
+ */
+
+#include <dt-bindings/interrupt-controller/arm-gic.h>
+
+/ {
+	compatible = "phytium,ft1500a";
+	interrupt-parent = <&gic>;
+	#address-cells = <2>;
+	#size-cells = <2>;
+
+	aliases {
+		ethernet0 = &gmac0;
+		ethernet1 = &gmac1;
+	};
+
+	psci {
+		compatible = "arm,psci-1.0", "arm,psci-0.2", "arm,psci";
+		method = "smc";
+		cpu_suspend = <0xc4000001>;
+		cpu_off = <0x84000002>;
+		cpu_on = <0xc4000003>;
+	};
+
+	cpus {
+		#address-cells = <2>;
+		#size-cells = <0>;
+
+		cpu-map {
+			cluster0 {
+				core0 {
+					cpu = <&cpu0>;
+				};
+				core1 {
+					cpu = <&cpu1>;
+				};
+				core2 {
+					cpu = <&cpu2>;
+				};
+				core3 {
+					cpu = <&cpu3>;
+				};
+			};
+
+			cluster1 {
+				core0 {
+					cpu = <&cpu4>;
+				};
+				core1 {
+					cpu = <&cpu5>;
+				};
+				core2 {
+					cpu = <&cpu6>;
+				};
+				core3 {
+					cpu = <&cpu7>;
+				};
+			};
+
+			cluster2 {
+				core0 {
+					cpu = <&cpu8>;
+				};
+				core1 {
+					cpu = <&cpu9>;
+				};
+				core2 {
+					cpu = <&cpu10>;
+				};
+				core3 {
+					cpu = <&cpu11>;
+				};
+			};
+
+			cluster3 {
+				core0 {
+					cpu = <&cpu12>;
+				};
+				core1 {
+					cpu = <&cpu13>;
+				};
+				core2 {
+					cpu = <&cpu14>;
+				};
+				core3 {
+					cpu = <&cpu15>;
+				};
+			};
+		};
+
+		idle-states {
+			entry-method = "arm,psci";
+
+			CPU_SLEEP: cpu-sleep {
+				compatible = "arm,idle-state";
+				local-timer-stop;
+				arm,psci-suspend-param = <0x0010000>;
+				entry-latency-us = <100>;
+				exit-latency-us = <100>;
+				min-residency-us = <200>;
+			};
+		};
+
+		cpu0:cpu@0 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x000>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 0>;
+			clock-latency = <10000>;
+			cooling-min-level = <0>;	/* cooling options */
+			cooling-max-level = <5>;
+			#cooling-cells = <2>;		/* min followed by max */
+		};
+
+		cpu1:cpu@1 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x001>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 0>;
+			clock-latency = <10000>;
+		};
+
+		cpu2:cpu@2 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x002>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 0>;
+			clock-latency = <10000>;
+		};
+
+		cpu3:cpu@3 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x003>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 0>;
+			clock-latency = <10000>;
+		};
+
+		cpu4:cpu@100 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x100>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 1>;
+			clock-latency = <10000>;
+			cooling-min-level = <0>;	/* cooling options */
+			cooling-max-level = <5>;
+			#cooling-cells = <2>;		/* min followed by max */
+		};
+
+		cpu5:cpu@101 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x101>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 1>;
+			clock-latency = <10000>;
+		};
+
+		cpu6:cpu@102 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x102>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 1>;
+			clock-latency = <10000>;
+		};
+
+		cpu7:cpu@103 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x103>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 1>;
+			clock-latency = <10000>;
+		};
+
+		cpu8:cpu@200 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x200>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 2>;
+			clock-latency = <10000>;
+			cooling-min-level = <0>;	/* cooling options */
+			cooling-max-level = <5>;
+			#cooling-cells = <2>;		/* min followed by max */
+		};
+
+		cpu9:cpu@201 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x201>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 2>;
+			clock-latency = <10000>;
+		};
+
+		cpu10:cpu@202 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x202>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 2>;
+			clock-latency = <10000>;
+		};
+
+		cpu11:cpu@203 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x203>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 2>;
+			clock-latency = <10000>;
+		};
+
+		cpu12:cpu@300 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x300>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 3>;
+			clock-latency = <10000>;
+			cooling-min-level = <0>;	/* cooling options */
+			cooling-max-level = <5>;
+			#cooling-cells = <2>;		/* min followed by max */
+		};
+
+		cpu13:cpu@301 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x301>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 3>;
+			clock-latency = <10000>;
+		};
+
+		cpu14:cpu@302 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x302>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 3>;
+			clock-latency = <10000>;
+		};
+
+		cpu15:cpu@303 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x303>;
+			enable-method = "psci";
+			cpu-idle-states = <&CPU_SLEEP>;
+			clocks = <&cpuclk 3>;
+			clock-latency = <10000>;
+		};
+	};
+
+	gic: interrupt-controller@29800000 {
+		compatible = "arm,gic-v3";
+		#interrupt-cells = <3>;
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+		interrupt-controller;
+		reg = <0x0 0x29800000 0 0x10000>,	/* GICD */
+		      <0x0 0x29a00000 0 0x200000>,	/* GICR */
+		      <0x0 0x29c00000 0 0x10000>,	/* GICC */
+		      <0x0 0x29c10000 0 0x10000>,	/* GICH */
+		      <0x0 0x29c20000 0 0x10000>;	/* GICV */
+		interrupts = <GIC_PPI 9 IRQ_TYPE_LEVEL_HIGH>;
+
+		its: gic-its@29820000 {
+			compatible = "arm,gic-v3-its";
+			msi-controller;
+			reg = <0x0 0x29820000 0x0 0x20000>;
+		};
+	};
+
+	timer {
+		compatible = "arm,armv8-timer";
+		interrupts = <GIC_PPI 13 IRQ_TYPE_LEVEL_LOW>,
+			     <GIC_PPI 14 IRQ_TYPE_LEVEL_LOW>,
+			     <GIC_PPI 11 IRQ_TYPE_LEVEL_LOW>,
+			     <GIC_PPI 10 IRQ_TYPE_LEVEL_LOW>;
+		clock-frequency = <50000000>;
+	};
+
+	pmu {
+		compatible = "arm,armv8-pmuv3";
+		interrupts = <GIC_PPI 7 IRQ_TYPE_LEVEL_LOW>;
+	};
+
+	clocks {
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+
+		/* 50 MHz reference crystal */
+		refclk: refclk {
+			compatible = "fixed-clock";
+			#clock-cells = <0>;
+			clock-frequency = <50000000>;
+		};
+
+		clk_100mhz: clk_100mhz {
+			compatible = "fixed-clock";
+			#clock-cells = <0>;
+			clocks = <&refclk>;
+			clock-frequency = <100000000>;
+		};
+
+		cpuclk: cpuclk {
+			compatible = "phytium,1500a-cpu-clock";
+			#clock-cells = <1>;
+			reg = <0x0 0x28100600 0x0 0x10>;
+			clocks = <&refclk>;
+			mode = <0x2>; /* 0: do not use pll, 1: partially use pll, 2: totally use pll */
+			/*big-clock;*/
+			clock-output-names = "cluster0-clk",
+					     "cluster1-clk",
+					     "cluster2-clk",
+					     "cluster3-clk";
+		};
+
+		gmacclk: gmacclk {
+			compatible = "phytium,1500a-gmac-clock";
+			#clock-cells = <0>;
+			reg = <0x0 0x2810050c 0x0 0x4>;
+			clocks = <&refclk>;
+			clock-frequency = <500000000>;
+			clock-output-names = "gmac-clk";
+		};
+	};
+
+	soc {
+		compatible = "simple-bus";
+		#address-cells = <2>;
+		#size-cells = <2>;
+		dma-coherent;
+		ranges;
+
+		uart0: serial@28000000 {
+			compatible = "snps,dw-apb-uart";
+			reg = <0x0 0x28000000 0x0 0x1000>;
+			clock-frequency = <50000000>;
+			interrupts = <GIC_SPI 34 IRQ_TYPE_LEVEL_HIGH>;
+			reg-shift = <2>;
+			reg-io-width = <4>;
+			status = "disabled";
+		};
+
+		uart1: serial@28001000 {
+			compatible = "snps,dw-apb-uart";
+			reg = <0x0 0x28001000 0x0 0x1000>;
+			clock-frequency = <50000000>;
+			interrupts = <GIC_SPI 35 IRQ_TYPE_LEVEL_HIGH>;
+			reg-shift = <2>;
+			reg-io-width = <4>;
+			status = "disabled";
+		};
+
+		i2c0: i2c@28002000 {
+			#address-cells = <1>;
+			#size-cells = <0>;
+			compatible = "snps,designware-i2c";
+			reg = <0x0 0x28002000 0x0 0x1000>;
+			interrupts = <GIC_SPI 36 IRQ_TYPE_LEVEL_HIGH>;
+			clock-frequency = <100000>;
+			clocks = <&clk_100mhz>;
+			status = "disabled";
+		};
+
+		i2c1: i2c@28003000 {
+			#address-cells = <1>;
+			#size-cells = <0>;
+			compatible = "snps,designware-i2c";
+			reg = <0x0 0x28003000 0x0 0x1000>;
+			interrupts = <GIC_SPI 37 IRQ_TYPE_LEVEL_HIGH>;
+			clock-frequency = <100000>;
+			clocks = <&clk_100mhz>;
+			status = "disabled";
+		};
+
+		wdt0: watchdog@28004000 {
+			compatible = "snps,dw-wdt";
+			reg = <0x0 0x28004000 0x0 0x1000>;
+			clocks = <&refclk>;
+			interrupts = <GIC_SPI 38 IRQ_TYPE_LEVEL_HIGH>;
+			status = "disabled";
+		};
+
+		wdt1: watchdog@28005000 {
+			compatible = "snps,dw-wdt";
+			reg = <0x0 0x28005000 0x0 0x1000>;
+			clocks = <&refclk>;
+			interrupts = <GIC_SPI 39 IRQ_TYPE_LEVEL_HIGH>;
+			status = "disabled";
+		};
+
+		gpio: gpio@28006000 {
+			compatible = "snps,dw-apb-gpio";
+			reg = <0x0 0x28006000 0x0 0x1000>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+			status = "disabled";
+			porta: gpio-controller@0 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <2>;
+				snps,nr-gpios = <8>;
+				reg = <0>;
+			};
+			portb: gpio-controller@1 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <2>;
+				snps,nr-gpios = <8>;
+				reg = <1>;
+			};
+			portc: gpio-controller@2 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <2>;
+				snps,nr-gpios = <8>;
+				reg = <2>;
+			};
+			portd: gpio-controller@3 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <2>;
+				snps,nr-gpios = <8>;
+				reg = <3>;
+			};
+		};
+
+		gmac0: ethernet@28c00000 {
+			compatible = "snps,dwmac";
+			reg = <0 0x28c00000 0x0 0x2000>;
+			interrupts = <GIC_SPI 44 IRQ_TYPE_LEVEL_HIGH>;
+			interrupt-names = "macirq";
+			clocks = <&gmacclk>;
+			clock-names = "stmmaceth";
+			snps,pbl = <32>;
+			snps,fixed-burst;
+			snps,burst_len = <0xe>;
+			snps,force_sf_dma_mode;
+			snps,multicast-filter-bins = <64>;
+			snps,perfect-filter-entries = <1>;
+			max-frame-size = <9000>;
+			status = "disabled";
+		};
+
+		gmac1: ethernet@28c02000 {
+			compatible = "snps,dwmac";
+			reg = <0 0x28c02000 0x0 0x2000>;
+			interrupts = <GIC_SPI 45 IRQ_TYPE_LEVEL_HIGH>;
+			interrupt-names = "macirq";
+			clocks = <&gmacclk>;
+			clock-names = "stmmaceth";
+			snps,pbl = <32>;
+			snps,fixed-burst;
+			snps,burst_len = <0xe>;
+			snps,force_sf_dma_mode;
+			snps,multicast-filter-bins = <64>;
+			snps,perfect-filter-entries = <1>;
+			max-frame-size = <9000>;
+			status = "disabled";
+		};
+
+		pcie0: pcie-controller {
+			compatible = "pci-host-ecam-generic";
+			device_type = "pci";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			#interrupt-cells = <1>;
+			reg = <0 0x40000000 0 0x10000000>;
+			msi-parent = <&its>;
+			interrupt-map-mask = <0x0000 0x0 0x0 0x7>;
+			interrupt-map = <0x0 0x0 0x0 0x1 &gic 0x0 0x0 GIC_SPI 0x33 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x2 &gic 0x0 0x0 GIC_SPI 0x34 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x3 &gic 0x0 0x0 GIC_SPI 0x35 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x4 &gic 0x0 0x0 GIC_SPI 0x36 IRQ_TYPE_LEVEL_HIGH>;
+			ranges = <0x01000000 0x00 0x00000000 0x00 0x50000000 0x00 0x1000000>,
+				 <0x02000000 0x00 0x60000000 0x00 0x60000000 0x00 0x20000000>,
+				 <0x43000000 0x01 0x00000000 0x01 0x00000000 0x01 0x00000000>;
+		};
+	};
+};
diff --git a/arch/arm64/boot/dts/phytium/ft1500a-devboard-16c-dsk.dts b/arch/arm64/boot/dts/phytium/ft1500a-devboard-16c-dsk.dts
new file mode 100644
index 000000000000..ed2127496e95
--- /dev/null
+++ b/arch/arm64/boot/dts/phytium/ft1500a-devboard-16c-dsk.dts
@@ -0,0 +1,51 @@
+/*
+ * DTS file for Phytium FT1500A Generic board
+ *
+ * Copyright (C) 2015, Phytium Technology Co., Ltd.
+ *
+ * This file is licensed under a dual GPLv2 or BSD license.
+ */
+
+/dts-v1/;
+/memreserve/ 0x80000000 0x80000;
+
+#include "ft1500a-16c-generic-psci-soc.dtsi"
+
+/ {
+	model = "FT1500A-16CORE-DSK Development Board";
+	compatible = "phytium,ft-1500a";
+
+	chosen {
+		linux,pci-probe-only = <1>;
+		stdout-path = "uart1:115200n8";
+	};
+
+	memory {
+		device_type = "memory";
+		reg = <0x0 0x80000000 0x0 0x80000000>;	/* Updated by bootloader */
+	};
+};
+
+&uart1 {
+	status = "ok";
+};
+
+&i2c0 {
+	status = "ok";
+};
+
+&i2c1 {
+	status = "ok";
+};
+
+&wdt0 {
+	status = "ok";
+};
+
+&gmac0 {
+	phy-mode = "gmii";
+};
+
+&gmac1 {
+	phy-mode = "gmii";
+};
diff --git a/arch/arm64/boot/dts/phytium/ft2000ahk-devboard-dsk.dts b/arch/arm64/boot/dts/phytium/ft2000ahk-devboard-dsk.dts
new file mode 100644
index 000000000000..4afbbf9c827b
--- /dev/null
+++ b/arch/arm64/boot/dts/phytium/ft2000ahk-devboard-dsk.dts
@@ -0,0 +1,52 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * DTS file for Phytium FT-2000A/2 devboard (FT-2000A-HK-DSK series)
+ *
+ * Copyright (C) 2019, Phytium Techonlogy Co., Ltd.
+ */
+
+/dts-v1/;
+
+#include "ft2000ahk-generic-spintable-soc.dtsi"
+
+/ {
+	model = "FT-2000A-HK-DSK Development Board";
+	compatible = "phytium,ft-2000ahk";
+	#address-cells = <2>;
+	#size-cells = <2>;
+
+	chosen {
+		linux,pci-probe-only = <1>;
+	};
+
+	memory {
+		device_type = "memory";
+		reg = <0x0 0x80000000 0x0 0x80000000>;
+	};
+};
+
+&i2c0 {
+	status = "ok";
+	rtc@68 {
+		compatible = "dallas,ds1339";
+		reg = <0x68>;
+	};
+};
+
+&uart1 {
+	status = "ok";
+};
+
+&gmac0 {
+	status = "ok";
+	phy-mode = "rgmii";
+};
+
+&gmac1 {
+	status = "ok";
+	phy-mode = "rgmii";
+};
+
+&gpio {
+	status = "ok";
+};
diff --git a/arch/arm64/boot/dts/phytium/ft2000ahk-generic-spintable-soc.dtsi b/arch/arm64/boot/dts/phytium/ft2000ahk-generic-spintable-soc.dtsi
new file mode 100644
index 000000000000..81393fc55bec
--- /dev/null
+++ b/arch/arm64/boot/dts/phytium/ft2000ahk-generic-spintable-soc.dtsi
@@ -0,0 +1,253 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * dts file for FT-2000A/2 SoC
+ *
+ * Copyright (C) 2019, Phytium Technology Co., Ltd.
+ */
+
+#include <dt-bindings/interrupt-controller/arm-gic.h>
+
+/ {
+	compatible = "phytium,ft2000ahk";
+	interrupt-parent = <&gic>;
+	#address-cells = <2>;
+	#size-cells = <2>;
+
+	aliases {
+		ethernet0 = &gmac0;
+		ethernet1 = &gmac1;
+	};
+
+	cpus {
+		#address-cells = <2>;
+		#size-cells = <0>;
+
+		cpu0: cpu@0 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x0>;
+			enable-method = "spin-table";
+			cpu-release-addr = <0x0 0x8007fff0>;
+		};
+
+		cpu1: cpu@1 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x1>;
+			enable-method = "spin-table";
+			cpu-release-addr = <0x0 0x8007fff0>;
+		};
+	};
+
+	gic: interrupt-controller@71800000 {
+		compatible = "arm,gic-400";
+		#interrupt-cells = <3>;
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+		interrupt-controller;
+		reg = <0x0 0x71801000 0x0 0x1000>,
+		      <0x0 0x71802000 0x0 0x2000>,
+		      <0x0 0x71804000 0x0 0x1000>,
+		      <0x0 0x71805000 0x0 0x1000>;
+	};
+
+	timer {
+		compatible = "arm,armv8-timer";
+		interrupts = <GIC_PPI 13 IRQ_TYPE_LEVEL_LOW>,
+			     <GIC_PPI 14 IRQ_TYPE_LEVEL_LOW>,
+			     <GIC_PPI 11 IRQ_TYPE_LEVEL_LOW>,
+			     <GIC_PPI 10 IRQ_TYPE_LEVEL_LOW>;
+		clock-frequency = <50000000>;
+	};
+
+	pmu {
+		compatible = "arm,armv8-pmuv3";
+		interrupts = <GIC_SPI 0 IRQ_TYPE_LEVEL_HIGH>,
+			     <GIC_SPI 1 IRQ_TYPE_LEVEL_HIGH>;
+		interrupt-affinity = <&cpu0 &cpu1>;
+	};
+
+	soc {
+		compatible = "simple-bus";
+		#address-cells = <2>;
+		#size-cells = <2>;
+		dma-coherent;
+		ranges;
+
+		clocks {
+			refclk: refclk {
+				compatible = "fixed-clock";
+				#clock-cells = <0>;
+				clock-frequency = <50000000>;
+			};
+
+			clk250mhz: clk250mhz {
+				compatible = "fixed-clock";
+				#clock-cells = <0>;
+				clock-frequency = <250000000>;
+			};
+
+			clk500mhz: clk500mhz {
+				compatible = "fixed-clock";
+				#clock-cells = <0>;
+				clock-frequency = <500000000>;
+			};
+		};
+
+		uart0: uart@70000000 {
+			compatible = "snps,dw-apb-uart";
+			reg = <0x0 0x70000000 0x0 0x1000>;
+			clock-frequency = <50000000>;
+			interrupts = <GIC_SPI 4 IRQ_TYPE_LEVEL_HIGH>;
+			reg-shift = <2>;
+			reg-io-width = <4>;
+			status = "disabled";
+		};
+
+		uart1: uart@70001000 {
+			compatible = "snps,dw-apb-uart";
+			reg = <0x0 0x70001000 0x0 0x1000>;
+			clock-frequency = <50000000>;
+			interrupts = <GIC_SPI 5 IRQ_TYPE_LEVEL_HIGH>;
+			reg-shift = <2>;
+			reg-io-width = <4>;
+			status = "disabled";
+		};
+
+		i2c0: i2c@70002000 {
+			#address-cells = <1>;
+			#size-cells = <0>;
+			compatible = "snps,designware-i2c";
+			reg = <0x0 0x70002000 0x0 0x1000>;
+			interrupts = <GIC_SPI 6 IRQ_TYPE_LEVEL_HIGH>;
+			clock-frequency = <100000>;
+			clocks = <&refclk>;
+			status = "disabled";
+		};
+
+		i2c1: i2c@70003000 {
+			#address-cells = <01>;
+			#size-cells = <0>;
+			compatible = "snps,designware-i2c";
+			reg = <0x0 0x70003000 0x0 0x1000>;
+			interrupts = <GIC_SPI 7 IRQ_TYPE_LEVEL_HIGH>;
+			clock-frequency = <100000>;
+			clocks = <&refclk>;
+			status = "disabled";
+		};
+
+		watchdog0: wd@70004000 {
+			compatible = "snps,dw-wdt";
+			reg = <0x0 0x70004000 0x0 0x1000>;
+			clocks = <&refclk>;
+			interrupts = <GIC_SPI 8 IRQ_TYPE_LEVEL_HIGH>;
+			status = "disabled";
+		};
+
+		watchdog1: wd@70005000 {
+			compatible = "snps,dw-wdt";
+			reg = <0x0 0x70005000 0x0 0x1000>;
+			clocks = <&refclk>;
+			interrupts = <GIC_SPI 9 IRQ_TYPE_LEVEL_HIGH>;
+			status = "disabled";
+		};
+
+		gpio: gpio@70006000 {
+			compatible = "snps,dw-apb-gpio";
+			reg = <0x0 0x70006000 0x0 0x1000>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+			status = "disabled";
+
+			porta: gpio-controller@0 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <2>;
+				snps,nr-gpios = <8>;
+				reg = <0>;
+			};
+
+			portb: gpio-controller@1 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <2>;
+				snps,nr-gpios = <8>;
+				reg = <1>;
+			};
+
+			portc: gpio-controller@2 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <2>;
+				snps,nr-gpios = <8>;
+				reg = <2>;
+			};
+
+			portd: gpio-controller@3 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <2>;
+				snps,nr-gpios = <8>;
+				reg = <3>;
+			};
+		};
+
+		gmac0: eth@70c00000 {
+			compatible = "snps,dwmac";
+			reg = <0x0 0x70c00000 0x0 0x2000>;
+			interrupts = <GIC_SPI 14 IRQ_TYPE_LEVEL_HIGH>;
+			interrupt-names = "macirq";
+			clocks = <&clk500mhz>;
+			clock-names = "stmmaceth";
+			status = "disabled";
+
+			snps,pbl = <16>;
+			snps,fixed-burst;
+			snps,burst_len = <14>;
+			snps,force_sf_dma_mode;
+			snps,multicast-filter-bins = <64>;
+			snps,perfect-filter-entries = <128>;
+			tx-fifo-depth = <4096>;
+			rx-fifo-depth = <4096>;
+			max-frame-size = <9000>;
+		};
+
+		gmac1: eth@70c10000 {
+			compatible = "snps,dwmac";
+			reg = <0x0 0x70c10000 0x0 0x2000>;
+			interrupts = <GIC_SPI 15 IRQ_TYPE_LEVEL_HIGH>;
+			interrupt-names = "macirq";
+			clocks = <&clk500mhz>;
+			clock-names = "stmmaceth";
+			status = "disabled";
+
+			snps,pbl = <16>;
+			snps,fixed-burst;
+			snps,burst_len = <14>;
+			snps,force_sf_dma_mode;
+			snps,multicast-filter-bins = <64>;
+			snps,perfect-filter-entries = <128>;
+			tx-fifo-depth = <4096>;
+			rx-fifo-depth = <4096>;
+			max-frame-size = <9000>;
+		};
+
+		pcie: pcie {
+			compatible = "pci-host-ecam-generic";
+			device_type = "pci";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			#interrupt-cells = <1>;
+			reg = <0x0 0x40000000 0x0 0x4000000>;
+			interrupt-map-mask = <0x0 0x0 0x0 0x7>;
+			interrupt-map = <0x00 0x0 0x0 0x1 &gic 0x00 0x00 GIC_SPI 0x17 IRQ_TYPE_LEVEL_HIGH>,
+					<0x00 0x0 0x0 0x2 &gic 0x00 0x00 GIC_SPI 0x16 IRQ_TYPE_LEVEL_HIGH>,
+					<0x00 0x0 0x0 0x3 &gic 0x00 0x00 GIC_SPI 0x15 IRQ_TYPE_LEVEL_HIGH>,
+					<0x00 0x0 0x0 0x4 &gic 0x00 0x00 GIC_SPI 0x14 IRQ_TYPE_LEVEL_HIGH>;
+			ranges = <0x01000000 0x0 0x00000000 0x0 0x44000000 0x0 0x01000000>,
+				 <0x02000000 0x0 0x48000000 0x0 0x48000000 0x0 0x18000000>,
+				 <0x03000000 0x1 0x00000000 0x1 0x00000000 0x1 0x00000000>;
+		};
+	};
+};
diff --git a/arch/arm64/boot/dts/phytium/ft2000plus-MR-devboard-64c-dsk.dts b/arch/arm64/boot/dts/phytium/ft2000plus-MR-devboard-64c-dsk.dts
new file mode 100644
index 000000000000..7c2ee8e60dce
--- /dev/null
+++ b/arch/arm64/boot/dts/phytium/ft2000plus-MR-devboard-64c-dsk.dts
@@ -0,0 +1,136 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * DTS file for Phytium FT-2000plus devboard.
+ *
+ * Copyright (C) 2019, Phytium Technology Co., Ltd.
+ */
+
+/dts-v1/;
+/memreserve/ 0x0000000080000000 0x0000000000010000;
+
+#include "ft2000plus-MR-psci-soc.dtsi"
+
+/ {
+	model = "FT-2000plus Development Board";
+	compatible = "phytium,ft-2000plus";
+
+	chosen {
+		linux,pci-probe-only = <1>;
+	};
+
+	/* NUMA Node-0 */
+        memory@00 {
+                device_type = "memory";
+		/* 0 - 512MiB (512MiB)*/
+                reg = <0x00000000 0x00000000 0x0 0x20000000>;
+                numa-node-id = <0>;
+        };
+        memory@01 {
+                device_type = "memory";
+		/* 2GiB - 4GiB (2GiB) */
+                reg = <0x00000000 0x80000000 0x0 0x80000000>;
+                numa-node-id = <0>;
+        };
+        memory@02 {
+                device_type = "memory";
+		/* 512GiB - 516GiB (4GiB) */
+                reg = <0x00000080 0x00000000 0x1 0x00000000>;
+                numa-node-id = <0>;
+        };
+	/* NUMA Node-1 */
+        memory@10 {
+                device_type = "memory";
+		/* 1024GiB - 1028GiB (4GiB) */
+                reg = <0x00000100 0x00000000 0x1 0x00000000>;
+                numa-node-id = <1>;
+        };
+        memory@11 {
+                device_type = "memory";
+		/* 1536GiB - 1540GiB (4GiB) */
+                reg = <0x00000180 0x00000000 0x1 0x00000000>;
+                numa-node-id = <1>;
+        };
+	/* NUMA Node-2 */
+        memory@20 {
+                device_type = "memory";
+		/* 2048GiB - 2052GiB (4GiB) */
+                reg = <0x00000200 0x00000000 0x1 0x00000000>;
+                numa-node-id = <2>;
+        };
+        memory@21 {
+                device_type = "memory";
+		/* 2560GiB - 2564GiB (4GiB) */
+                reg = <0x00000280 0x00000000 0x1 0x00000000>;
+                numa-node-id = <2>;
+        };
+	/* NUMA Node-3 */
+        memory@30 {
+                device_type = "memory";
+		/* 3072GiB - 3076GiB (4GiB) */
+                reg = <0x00000300 0x00000000 0x1 0x00000000>;
+                numa-node-id = <3>;
+        };
+        memory@31 {
+                device_type = "memory";
+		/* 3584GiB - 3588GiB (4GiB) */
+                reg = <0x00000380 0x00000000 0x1 0x00000000>;
+                numa-node-id = <3>;
+        };
+	/* NUMA Node-4 */
+        memory@40 {
+                device_type = "memory";
+		/* 4096GiB - 4100GiB (4GiB) */
+                reg = <0x00000400 0x00000000 0x1 0x00000000>;
+                numa-node-id = <4>;
+        };
+        memory@41 {
+                device_type = "memory";
+		/* 4608GiB - 4612GiB (4GiB) */
+                reg = <0x00000480 0x00000000 0x1 0x00000000>;
+                numa-node-id = <4>;
+        };
+	/* NUMA Node-5 */
+        memory@50 {
+                device_type = "memory";
+		/* 5120GiB - 5124GiB (4GiB) */
+                reg = <0x00000500 0x00000000 0x1 0x00000000>;
+                numa-node-id = <5>;
+        };
+        memory@51 {
+                device_type = "memory";
+		/* 5632GiB - 5636GiB (4GiB) */
+                reg = <0x00000580 0x00000000 0x1 0x00000000>;
+                numa-node-id = <5>;
+        };
+	/* NUMA Node-6 */
+        memory@60 {
+                device_type = "memory";
+		/* 6144GiB - 6148GiB (4GiB) */
+                reg = <0x00000600 0x00000000 0x1 0x00000000>;
+                numa-node-id = <6>;
+        };
+        memory@61 {
+                device_type = "memory";
+		/* 6656GiB - 6660GiB (4GiB) */
+                reg = <0x00000680 0x00000000 0x1 0x00000000>;
+                numa-node-id = <6>;
+        };
+	/* NUMA Node-7 */
+        memory@70 {
+                device_type = "memory";
+		/* 7168GiB - 7172GiB (4GiB) */
+                reg = <0x00000700 0x00000000 0x1 0x00000000>;
+                numa-node-id = <7>;
+        };
+        memory@71 {
+                device_type = "memory";
+		/* 7680GiB - 7684GiB (4GiB) */
+                reg = <0x00000780 0x00000000 0x1 0x00000000>;
+                numa-node-id = <7>;
+        };
+
+};
+
+&uart1 {
+	status = "ok";
+};
diff --git a/arch/arm64/boot/dts/phytium/ft2000plus-MR-psci-soc.dtsi b/arch/arm64/boot/dts/phytium/ft2000plus-MR-psci-soc.dtsi
new file mode 100644
index 000000000000..8ac066cd075a
--- /dev/null
+++ b/arch/arm64/boot/dts/phytium/ft2000plus-MR-psci-soc.dtsi
@@ -0,0 +1,1062 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * dts file for FT-2000plus SoC
+ *
+ * Copyright (C) 2018-2019, Phytium Technology Co., Ltd.
+ */
+
+#include <dt-bindings/interrupt-controller/arm-gic.h>
+
+/ {
+	compatible = "phytium,ft2000plus";
+	interrupt-parent = <&gic>;
+	#address-cells = <2>;
+	#size-cells = <2>;
+
+	psci {
+		compatible = "arm,psci-1.0";
+		method = "smc";
+		cpu_suspend = <0xc4000001>;
+		cpu_off = <0x84000002>;
+		cpu_on = <0xc4000003>;
+		sys_poweroff = <0x84000008>;
+		sys_reset = <0x84000009>;
+	};
+
+	cpus {
+		#address-cells = <0x2>;
+		#size-cells = <0x0>;
+
+		cpu-map {
+			cluster0 {
+				core0 {
+					cpu = <&cpu0>;
+				};
+				core1 {
+					cpu = <&cpu1>;
+				};
+				core2 {
+					cpu = <&cpu2>;
+				};
+				core3 {
+					cpu = <&cpu3>;
+				};
+			};
+
+			cluster1 {
+				core0 {
+					cpu = <&cpu4>;
+				};
+				core1 {
+					cpu = <&cpu5>;
+				};
+				core2 {
+					cpu = <&cpu6>;
+				};
+				core3 {
+					cpu = <&cpu7>;
+				};
+			};
+
+			cluster2 {
+				core0 {
+					cpu = <&cpu8>;
+				};
+				core1 {
+					cpu = <&cpu9>;
+				};
+				core2 {
+					cpu = <&cpu10>;
+				};
+				core3 {
+					cpu = <&cpu11>;
+				};
+			};
+
+			cluster3 {
+				core0 {
+					cpu = <&cpu12>;
+				};
+				core1 {
+					cpu = <&cpu13>;
+				};
+				core2 {
+					cpu = <&cpu14>;
+				};
+				core3 {
+					cpu = <&cpu15>;
+				};
+			};
+
+			cluster4 {
+				core0 {
+					cpu = <&cpu16>;
+				};
+				core1 {
+					cpu = <&cpu17>;
+				};
+				core2 {
+					cpu = <&cpu18>;
+				};
+				core3 {
+					cpu = <&cpu19>;
+				};
+			};
+
+			cluster5 {
+				core0 {
+					cpu = <&cpu20>;
+				};
+				core1 {
+					cpu = <&cpu21>;
+				};
+				core2 {
+					cpu = <&cpu22>;
+				};
+				core3 {
+					cpu = <&cpu23>;
+				};
+			};
+
+			cluster6 {
+				core0 {
+					cpu = <&cpu24>;
+				};
+				core1 {
+					cpu = <&cpu25>;
+				};
+				core2 {
+					cpu = <&cpu26>;
+				};
+				core3 {
+					cpu = <&cpu27>;
+				};
+			};
+
+			cluster7 {
+				core0 {
+					cpu = <&cpu28>;
+				};
+				core1 {
+					cpu = <&cpu29>;
+				};
+				core2 {
+					cpu = <&cpu30>;
+				};
+				core3 {
+					cpu = <&cpu31>;
+				};
+			};
+
+			cluster8 {
+				core0 {
+					cpu = <&cpu32>;
+				};
+				core1 {
+					cpu = <&cpu33>;
+				};
+				core2 {
+					cpu = <&cpu34>;
+				};
+				core3 {
+					cpu = <&cpu35>;
+				};
+			};
+
+			cluster9 {
+				core0 {
+					cpu = <&cpu36>;
+				};
+				core1 {
+					cpu = <&cpu37>;
+				};
+				core2 {
+					cpu = <&cpu38>;
+				};
+				core3 {
+					cpu = <&cpu39>;
+				};
+			};
+
+			cluster10 {
+				core0 {
+					cpu = <&cpu40>;
+				};
+				core1 {
+					cpu = <&cpu41>;
+				};
+				core2 {
+					cpu = <&cpu42>;
+				};
+				core3 {
+					cpu = <&cpu43>;
+				};
+			};
+
+			cluster11 {
+				core0 {
+					cpu = <&cpu44>;
+				};
+				core1 {
+					cpu = <&cpu45>;
+				};
+				core2 {
+					cpu = <&cpu46>;
+				};
+				core3 {
+					cpu = <&cpu47>;
+				};
+			};
+
+			cluster12 {
+				core0 {
+					cpu = <&cpu48>;
+				};
+				core1 {
+					cpu = <&cpu49>;
+				};
+				core2 {
+					cpu = <&cpu50>;
+				};
+				core3 {
+					cpu = <&cpu51>;
+				};
+			};
+
+			cluster13 {
+				core0 {
+					cpu = <&cpu52>;
+				};
+				core1 {
+					cpu = <&cpu53>;
+				};
+				core2 {
+					cpu = <&cpu54>;
+				};
+				core3 {
+					cpu = <&cpu55>;
+				};
+			};
+
+			cluster14 {
+				core0 {
+					cpu = <&cpu56>;
+				};
+				core1 {
+					cpu = <&cpu57>;
+				};
+				core2 {
+					cpu = <&cpu58>;
+				};
+				core3 {
+					cpu = <&cpu59>;
+				};
+			};
+
+			cluster15 {
+				core0 {
+					cpu = <&cpu60>;
+				};
+				core1 {
+					cpu = <&cpu61>;
+				};
+				core2 {
+					cpu = <&cpu62>;
+				};
+				core3 {
+					cpu = <&cpu63>;
+				};
+			};
+		};
+
+		cpu0: cpu@0 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x0>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu1: cpu@1 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x1>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu2: cpu@2 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x2>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu3: cpu@3 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x3>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu4: cpu@100 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x100>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu5: cpu@101 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x101>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu6: cpu@102 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x102>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu7: cpu@103 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x103>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu8: cpu@200 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x200>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu9: cpu@201 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x201>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu10: cpu@202 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x202>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu11: cpu@203 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x203>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu12: cpu@300 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x300>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu13: cpu@301 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x301>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu14: cpu@302 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x302>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu15: cpu@303 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x303>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu16: cpu@400 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x400>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu17: cpu@401 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x401>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu18: cpu@402 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x402>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu19: cpu@403 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x403>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu20: cpu@500 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x500>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu21: cpu@501 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x501>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu22: cpu@502 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x502>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu23: cpu@503 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x503>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu24: cpu@600 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x600>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu25: cpu@601 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x601>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu26: cpu@602 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x602>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu27: cpu@603 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x603>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu28: cpu@700 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x700>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu29: cpu@701 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x701>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu30: cpu@702 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x702>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu31: cpu@703 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x703>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu32: cpu@800 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x800>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu33: cpu@801 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x801>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu34: cpu@802 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x802>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu35: cpu@803 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x803>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu36: cpu@900 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x900>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu37: cpu@901 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x901>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu38: cpu@902 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x902>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu39: cpu@903 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x903>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu40: cpu@a00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xa00>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu41: cpu@a01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xa01>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu42: cpu@a02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xa02>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu43: cpu@a03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xa03>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu44: cpu@b00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xb00>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu45: cpu@b01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xb01>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu46: cpu@b02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xb02>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu47: cpu@b03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xb03>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu48: cpu@c00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xc00>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu49: cpu@c01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xc01>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu50: cpu@c02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xc02>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu51: cpu@c03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xc03>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu52: cpu@d00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xd00>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu53: cpu@d01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xd01>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu54: cpu@d02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xd02>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu55: cpu@d03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xd03>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu56: cpu@e00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xe00>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu57: cpu@e01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xe01>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu58: cpu@e02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xe02>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu59: cpu@e03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xe03>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu60: cpu@f00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xf00>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu61: cpu@f01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xf01>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu62: cpu@f02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xf02>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu63: cpu@f03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xf03>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+	};
+
+	distance-map {
+		compatible = "numa-distance-map-v1";
+		distance-matrix = <0x0 0x0 0x0a>,
+				  <0x0 0x1 0x14>,
+				  <0x0 0x2 0x28>,
+				  <0x0 0x3 0x1e>,
+				  <0x0 0x4 0x14>,
+				  <0x0 0x5 0x1e>,
+				  <0x0 0x6 0x32>,
+				  <0x0 0x7 0x28>,
+				  <0x1 0x0 0x14>,
+				  <0x1 0x1 0x0a>,
+				  <0x1 0x2 0x1e>,
+				  <0x1 0x3 0x14>,
+				  <0x1 0x4 0x1e>,
+				  <0x1 0x5 0x14>,
+				  <0x1 0x6 0x28>,
+				  <0x1 0x7 0x1e>,
+				  <0x2 0x0 0x28>,
+				  <0x2 0x1 0x1e>,
+				  <0x2 0x2 0x0a>,
+				  <0x2 0x3 0x14>,
+				  <0x2 0x4 0x32>,
+				  <0x2 0x5 0x28>,
+				  <0x2 0x6 0x14>,
+				  <0x2 0x7 0x1e>,
+				  <0x3 0x0 0x1e>,
+				  <0x3 0x1 0x14>,
+				  <0x3 0x2 0x14>,
+				  <0x3 0x3 0x0a>,
+				  <0x3 0x4 0x28>,
+				  <0x3 0x5 0x1e>,
+				  <0x3 0x6 0x1e>,
+				  <0x3 0x7 0x14>,
+				  <0x4 0x0 0x14>,
+				  <0x4 0x1 0x1e>,
+				  <0x4 0x2 0x32>,
+				  <0x4 0x3 0x28>,
+				  <0x4 0x4 0x0a>,
+				  <0x4 0x5 0x14>,
+				  <0x4 0x6 0x28>,
+				  <0x4 0x7 0x1e>,
+				  <0x5 0x0 0x1e>,
+				  <0x5 0x1 0x14>,
+				  <0x5 0x2 0x28>,
+				  <0x5 0x3 0x1e>,
+				  <0x5 0x4 0x14>,
+				  <0x5 0x5 0x0a>,
+				  <0x5 0x6 0x1e>,
+				  <0x5 0x7 0x14>,
+				  <0x6 0x0 0x32>,
+				  <0x6 0x1 0x28>,
+				  <0x6 0x2 0x14>,
+				  <0x6 0x3 0x1e>,
+				  <0x6 0x4 0x28>,
+				  <0x6 0x5 0x1e>,
+				  <0x6 0x6 0x0a>,
+				  <0x6 0x7 0x14>,
+				  <0x7 0x0 0x28>,
+				  <0x7 0x1 0x1e>,
+				  <0x7 0x2 0x1e>,
+				  <0x7 0x3 0x14>,
+				  <0x7 0x4 0x1e>,
+				  <0x7 0x5 0x14>,
+				  <0x7 0x6 0x14>,
+				  <0x7 0x7 0x0a>;
+	};
+
+
+	gic: interrupt-controller@8002a000000 {
+		compatible = "arm,gic-v3";
+                #interrupt-cells = <3>;
+                #address-cells = <2>;
+                #size-cells = <2>;
+		ranges;
+		interrupt-controller;
+		reg = <0x0800 0x2a000000 0 0x10000>,    /* GICD */
+		      <0x0800 0x2a800000 0 0x800000>,   /* GICR */
+		      <0x0800 0x29c00000 0 0x10000>,    /* GICC */
+		      <0x0800 0x29c10000 0 0x10000>,    /* GICH */
+		      <0x0800 0x29c20000 0 0x10000>;    /* GICV */
+		interrupts = <GIC_PPI 9 IRQ_TYPE_LEVEL_HIGH>;
+
+                its: gic-its@8002a020000 {
+                        compatible = "arm,gic-v3-its";
+                        msi-controller;
+                        reg = <0x0800 0x2a020000 0x0 0x20000>;
+                };
+	};
+
+        timer {
+                compatible = "arm,armv8-timer";
+                interrupts = <GIC_PPI 13 IRQ_TYPE_LEVEL_LOW>,
+                             <GIC_PPI 14 IRQ_TYPE_LEVEL_LOW>,
+                             <GIC_PPI 11 IRQ_TYPE_LEVEL_LOW>,
+                             <GIC_PPI 10 IRQ_TYPE_LEVEL_LOW>;
+                clock-frequency = <50000000>;
+        };
+
+	soc {
+		compatible = "simple-bus";
+		#address-cells = <2>;
+		#size-cells = <2>;
+		dma-coherent;
+		ranges;
+
+                uart0: serial@28000000 {
+                        compatible = "snps,dw-apb-uart";
+                        reg = <0x800 0x28000000 0x0 0x1000>;
+                        clock-frequency = <50000000>;
+                        interrupts = <GIC_SPI 34 IRQ_TYPE_LEVEL_HIGH>;
+                        reg-shift = <2>;
+                        reg-io-width = <4>;
+                        status = "disabled";
+                };
+
+                uart1: serial@28001000 {
+                        compatible = "snps,dw-apb-uart";
+                        reg = <0x800 0x28001000 0x0 0x1000>;
+                        clock-frequency = <50000000>;
+                        interrupts = <GIC_SPI 35 IRQ_TYPE_LEVEL_HIGH>;
+                        reg-shift = <2>;
+                        reg-io-width = <4>;
+                        status = "disabled";
+                };
+
+		gpio0:gpio@80028006000 {
+			compatible = "snps,dw-apb-gpio";
+			reg = <0x800 0x28006000 0x0 0x1000>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+			status = "ok";
+
+			gpio-controller@0 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <0x2>;
+				snps,nr-gpios = <0x8>;
+				reg = <0x0>;
+			};
+
+			gpio-controller@1 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <0x2>;
+				snps,nr-gpios = <0x8>;
+				reg = <0x1>;
+			};
+
+			gpio-controller@2 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <0x2>;
+				snps,nr-gpios = <0x8>;
+				reg = <0x2>;
+			};
+
+			gpio-controller@3 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <0x2>;
+				snps,nr-gpios = <0x8>;
+				reg = <0x3>;
+			};
+		};
+
+		i2c0: i2c@80028002000 {
+			compatible = "snps,designware-i2c";
+			reg = <0x800 0x28002000 0x0 0x1000>;
+                        interrupts = <GIC_SPI 36 IRQ_TYPE_LEVEL_HIGH>;
+			clock-frequency = <100000>;
+			status = "ok";
+		};
+
+		i2c1: i2c@80028003000 {
+			compatible = "snps,designware-i2c";
+			reg = <0x800 0x28003000 0x0 0x1000>;
+                        interrupts = <GIC_SPI 37 IRQ_TYPE_LEVEL_HIGH>;
+			clock-frequency = <100000>;
+			status = "ok";
+		};
+
+		pcie0: peu0-c0 {
+			compatible = "pci-host-ecam-generic";
+			device_type = "pci";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			#interrupt-cells = <1>;
+			reg = <0x800 0x40000000 0 0x2000000>;
+			msi-parent = <&its>;
+			bus-range = <0 0x1f>;
+			interrupt-map-mask = <0x0 0x0 0x0 0x7>;
+			interrupt-map = <0x0 0x0 0x0 0x1 &gic 0x0 0x0 GIC_SPI 0x33 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x2 &gic 0x0 0x0 GIC_SPI 0x34 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x3 &gic 0x0 0x0 GIC_SPI 0x35 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x4 &gic 0x0 0x0 GIC_SPI 0x36 IRQ_TYPE_LEVEL_HIGH>;
+			ranges = <0x01000000 0x00 0x00000000 0x800 0x50000000 0x00 0x00300000>,
+				 <0x02000000 0x00 0x60000000 0x800 0x60000000 0x00 0x08000000>,
+				 <0x03000000 0x20 0x00000000 0x820 0x00000000 0x08 0x00000000>;
+		};
+
+		pcie1: peu0-c1 {
+			compatible = "pci-host-ecam-generic";
+			device_type = "pci";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			#interrupt-cells = <1>;
+			reg = <0x800 0x42000000 0 0x2000000>;
+			msi-parent = <&its>;
+			bus-range = <0x20 0x3f>;
+			interrupt-map-mask = <0x0 0x0 0x0 0x7>;
+			interrupt-map = <0x0 0x0 0x0 0x1 &gic 0x0 0x0 GIC_SPI 0x33 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x2 &gic 0x0 0x0 GIC_SPI 0x34 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x3 &gic 0x0 0x0 GIC_SPI 0x35 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x4 &gic 0x0 0x0 GIC_SPI 0x36 IRQ_TYPE_LEVEL_HIGH>;
+			ranges = <0x01000000 0x00 0x00300000 0x800 0x50300000 0x00 0x00300000>,
+				 <0x02000000 0x00 0x68000000 0x800 0x68000000 0x00 0x04000000>,
+				 <0x03000000 0x28 0x00000000 0x828 0x00000000 0x04 0x00000000>;
+		};
+
+		pcie2: peu0-c2 {
+			compatible = "pci-host-ecam-generic";
+			device_type = "pci";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			#interrupt-cells = <1>;
+			reg = <0x800 0x44000000 0 0x1000000>;
+			msi-parent = <&its>;
+			bus-range = <0x40 0x4f>;
+			interrupt-map-mask = <0x0 0x0 0x0 0x7>;
+			interrupt-map = <0x0 0x0 0x0 0x1 &gic 0x0 0x0 GIC_SPI 0x33 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x2 &gic 0x0 0x0 GIC_SPI 0x34 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x3 &gic 0x0 0x0 GIC_SPI 0x35 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x4 &gic 0x0 0x0 GIC_SPI 0x36 IRQ_TYPE_LEVEL_HIGH>;
+			ranges = <0x01000000 0x00 0x00600000 0x800 0x50600000 0x00 0x00300000>,
+				 <0x02000000 0x00 0x6c000000 0x800 0x6c000000 0x00 0x02000000>,
+				 <0x03000000 0x2c 0x00000000 0x82c 0x00000000 0x04 0x00000000>;
+		};
+
+		pcie3: peu1-c0 {
+			compatible = "pci-host-ecam-generic";
+			device_type = "pci";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			#interrupt-cells = <1>;
+			reg = <0x800 0x45000000 0 0x2000000>;
+			msi-parent = <&its>;
+			bus-range = <0x50 0x6f>;
+			interrupt-map-mask = <0x0 0x0 0x0 0x7>;
+			interrupt-map = <0x0 0x0 0x0 0x1 &gic 0x0 0x0 GIC_SPI 0x33 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x2 &gic 0x0 0x0 GIC_SPI 0x34 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x3 &gic 0x0 0x0 GIC_SPI 0x35 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x4 &gic 0x0 0x0 GIC_SPI 0x36 IRQ_TYPE_LEVEL_HIGH>;
+			ranges = <0x01000000 0x00 0x00900000 0x800 0x50900000 0x00 0x00300000>,
+				 <0x02000000 0x00 0x6e000000 0x800 0x6e000000 0x00 0x0a000000>,
+				 <0x03000000 0x20 0x00000000 0x830 0x00000000 0x08 0x00000000>;
+		};
+
+		pcie4: peu1-c1 {
+			compatible = "pci-host-ecam-generic";
+			device_type = "pci";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			#interrupt-cells = <1>;
+			reg = <0x800 0x47000000 0 0x1000000>;
+			msi-parent = <&its>;
+			bus-range = <0x70 0x7f>;
+			interrupt-map-mask = <0x0 0x0 0x0 0x7>;
+			interrupt-map = <0x0 0x0 0x0 0x1 &gic 0x0 0x0 GIC_SPI 0x33 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x2 &gic 0x0 0x0 GIC_SPI 0x34 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x3 &gic 0x0 0x0 GIC_SPI 0x35 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x4 &gic 0x0 0x0 GIC_SPI 0x36 IRQ_TYPE_LEVEL_HIGH>;
+			ranges = <0x01000000 0x00 0x00c00000 0x800 0x50c00000 0x00 0x00300000>,
+				 <0x02000000 0x00 0x78000000 0x800 0x78000000 0x00 0x08000000>,
+				 <0x03000000 0x38 0x00000000 0x838 0x00000000 0x08 0x00000000>;
+		};
+	};
+};
diff --git a/arch/arm64/boot/dts/phytium/ft2000plus-SR-devboard-64c-dsk.dts b/arch/arm64/boot/dts/phytium/ft2000plus-SR-devboard-64c-dsk.dts
new file mode 100644
index 000000000000..3e3e1e4a1c38
--- /dev/null
+++ b/arch/arm64/boot/dts/phytium/ft2000plus-SR-devboard-64c-dsk.dts
@@ -0,0 +1,136 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * DTS file for Phytium FT-2000plus devboard.
+ *
+ * Copyright (C) 2019, Phytium Technology Co., Ltd.
+ */
+
+/dts-v1/;
+/memreserve/ 0x0000000080000000 0x0000000000010000;
+
+#include "ft2000plus-SR-psci-soc.dtsi"
+
+/ {
+	model = "FT-2000plus Development Board";
+	compatible = "phytium,ft-2000plus";
+
+	chosen {
+		linux,pci-probe-only = <1>;
+	};
+
+	/* NUMA Node-0 */
+        memory@00 {
+                device_type = "memory";
+		/* 0 - 512MiB (512MiB)*/
+                reg = <0x00000000 0x00000000 0x0 0x20000000>;
+                numa-node-id = <0>;
+        };
+        memory@01 {
+                device_type = "memory";
+		/* 2GiB - 4GiB (2GiB) */
+                reg = <0x00000000 0x80000000 0x0 0x80000000>;
+                numa-node-id = <0>;
+        };
+        memory@02 {
+                device_type = "memory";
+		/* 512GiB - 516GiB (4GiB) */
+                reg = <0x00000080 0x00000000 0x1 0x00000000>;
+                numa-node-id = <0>;
+        };
+	/* NUMA Node-1 */
+        memory@10 {
+                device_type = "memory";
+		/* 1024GiB - 1028GiB (4GiB) */
+                reg = <0x00000100 0x00000000 0x1 0x00000000>;
+                numa-node-id = <1>;
+        };
+        memory@11 {
+                device_type = "memory";
+		/* 1536GiB - 1540GiB (4GiB) */
+                reg = <0x00000180 0x00000000 0x1 0x00000000>;
+                numa-node-id = <1>;
+        };
+	/* NUMA Node-2 */
+        memory@20 {
+                device_type = "memory";
+		/* 2048GiB - 2052GiB (4GiB) */
+                reg = <0x00000200 0x00000000 0x1 0x00000000>;
+                numa-node-id = <2>;
+        };
+        memory@21 {
+                device_type = "memory";
+		/* 2560GiB - 2564GiB (4GiB) */
+                reg = <0x00000280 0x00000000 0x1 0x00000000>;
+                numa-node-id = <2>;
+        };
+	/* NUMA Node-3 */
+        memory@30 {
+                device_type = "memory";
+		/* 3072GiB - 3076GiB (4GiB) */
+                reg = <0x00000300 0x00000000 0x1 0x00000000>;
+                numa-node-id = <3>;
+        };
+        memory@31 {
+                device_type = "memory";
+		/* 3584GiB - 3588GiB (4GiB) */
+                reg = <0x00000380 0x00000000 0x1 0x00000000>;
+                numa-node-id = <3>;
+        };
+	/* NUMA Node-4 */
+        memory@40 {
+                device_type = "memory";
+		/* 4096GiB - 4100GiB (4GiB) */
+                reg = <0x00000400 0x00000000 0x1 0x00000000>;
+                numa-node-id = <4>;
+        };
+        memory@41 {
+                device_type = "memory";
+		/* 4608GiB - 4612GiB (4GiB) */
+                reg = <0x00000480 0x00000000 0x1 0x00000000>;
+                numa-node-id = <4>;
+        };
+	/* NUMA Node-5 */
+        memory@50 {
+                device_type = "memory";
+		/* 5120GiB - 5124GiB (4GiB) */
+                reg = <0x00000500 0x00000000 0x1 0x00000000>;
+                numa-node-id = <5>;
+        };
+        memory@51 {
+                device_type = "memory";
+		/* 5632GiB - 5636GiB (4GiB) */
+                reg = <0x00000580 0x00000000 0x1 0x00000000>;
+                numa-node-id = <5>;
+        };
+	/* NUMA Node-6 */
+        memory@60 {
+                device_type = "memory";
+		/* 6144GiB - 6148GiB (4GiB) */
+                reg = <0x00000600 0x00000000 0x1 0x00000000>;
+                numa-node-id = <6>;
+        };
+        memory@61 {
+                device_type = "memory";
+		/* 6656GiB - 6660GiB (4GiB) */
+                reg = <0x00000680 0x00000000 0x1 0x00000000>;
+                numa-node-id = <6>;
+        };
+	/* NUMA Node-7 */
+        memory@70 {
+                device_type = "memory";
+		/* 7168GiB - 7172GiB (4GiB) */
+                reg = <0x00000700 0x00000000 0x1 0x00000000>;
+                numa-node-id = <7>;
+        };
+        memory@71 {
+                device_type = "memory";
+		/* 7680GiB - 7684GiB (4GiB) */
+                reg = <0x00000780 0x00000000 0x1 0x00000000>;
+                numa-node-id = <7>;
+        };
+
+};
+
+&uart1 {
+	status = "ok";
+};
diff --git a/arch/arm64/boot/dts/phytium/ft2000plus-SR-psci-soc.dtsi b/arch/arm64/boot/dts/phytium/ft2000plus-SR-psci-soc.dtsi
new file mode 100644
index 000000000000..e50f0e62154b
--- /dev/null
+++ b/arch/arm64/boot/dts/phytium/ft2000plus-SR-psci-soc.dtsi
@@ -0,0 +1,986 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * dts file for FT-2000plus SoC
+ *
+ * Copyright (C) 2018-2019, Phytium Technology Co., Ltd.
+ */
+
+#include <dt-bindings/interrupt-controller/arm-gic.h>
+
+/ {
+	compatible = "phytium,ft2000plus";
+	interrupt-parent = <&gic>;
+	#address-cells = <2>;
+	#size-cells = <2>;
+
+	psci {
+		compatible = "arm,psci-1.0";
+		method = "smc";
+		cpu_suspend = <0xc4000001>;
+		cpu_off = <0x84000002>;
+		cpu_on = <0xc4000003>;
+		sys_poweroff = <0x84000008>;
+		sys_reset = <0x84000009>;
+	};
+
+	cpus {
+		#address-cells = <0x2>;
+		#size-cells = <0x0>;
+
+		cpu-map {
+			cluster0 {
+				core0 {
+					cpu = <&cpu0>;
+				};
+				core1 {
+					cpu = <&cpu1>;
+				};
+				core2 {
+					cpu = <&cpu2>;
+				};
+				core3 {
+					cpu = <&cpu3>;
+				};
+			};
+
+			cluster1 {
+				core0 {
+					cpu = <&cpu4>;
+				};
+				core1 {
+					cpu = <&cpu5>;
+				};
+				core2 {
+					cpu = <&cpu6>;
+				};
+				core3 {
+					cpu = <&cpu7>;
+				};
+			};
+
+			cluster2 {
+				core0 {
+					cpu = <&cpu8>;
+				};
+				core1 {
+					cpu = <&cpu9>;
+				};
+				core2 {
+					cpu = <&cpu10>;
+				};
+				core3 {
+					cpu = <&cpu11>;
+				};
+			};
+
+			cluster3 {
+				core0 {
+					cpu = <&cpu12>;
+				};
+				core1 {
+					cpu = <&cpu13>;
+				};
+				core2 {
+					cpu = <&cpu14>;
+				};
+				core3 {
+					cpu = <&cpu15>;
+				};
+			};
+
+			cluster4 {
+				core0 {
+					cpu = <&cpu16>;
+				};
+				core1 {
+					cpu = <&cpu17>;
+				};
+				core2 {
+					cpu = <&cpu18>;
+				};
+				core3 {
+					cpu = <&cpu19>;
+				};
+			};
+
+			cluster5 {
+				core0 {
+					cpu = <&cpu20>;
+				};
+				core1 {
+					cpu = <&cpu21>;
+				};
+				core2 {
+					cpu = <&cpu22>;
+				};
+				core3 {
+					cpu = <&cpu23>;
+				};
+			};
+
+			cluster6 {
+				core0 {
+					cpu = <&cpu24>;
+				};
+				core1 {
+					cpu = <&cpu25>;
+				};
+				core2 {
+					cpu = <&cpu26>;
+				};
+				core3 {
+					cpu = <&cpu27>;
+				};
+			};
+
+			cluster7 {
+				core0 {
+					cpu = <&cpu28>;
+				};
+				core1 {
+					cpu = <&cpu29>;
+				};
+				core2 {
+					cpu = <&cpu30>;
+				};
+				core3 {
+					cpu = <&cpu31>;
+				};
+			};
+
+			cluster8 {
+				core0 {
+					cpu = <&cpu32>;
+				};
+				core1 {
+					cpu = <&cpu33>;
+				};
+				core2 {
+					cpu = <&cpu34>;
+				};
+				core3 {
+					cpu = <&cpu35>;
+				};
+			};
+
+			cluster9 {
+				core0 {
+					cpu = <&cpu36>;
+				};
+				core1 {
+					cpu = <&cpu37>;
+				};
+				core2 {
+					cpu = <&cpu38>;
+				};
+				core3 {
+					cpu = <&cpu39>;
+				};
+			};
+
+			cluster10 {
+				core0 {
+					cpu = <&cpu40>;
+				};
+				core1 {
+					cpu = <&cpu41>;
+				};
+				core2 {
+					cpu = <&cpu42>;
+				};
+				core3 {
+					cpu = <&cpu43>;
+				};
+			};
+
+			cluster11 {
+				core0 {
+					cpu = <&cpu44>;
+				};
+				core1 {
+					cpu = <&cpu45>;
+				};
+				core2 {
+					cpu = <&cpu46>;
+				};
+				core3 {
+					cpu = <&cpu47>;
+				};
+			};
+
+			cluster12 {
+				core0 {
+					cpu = <&cpu48>;
+				};
+				core1 {
+					cpu = <&cpu49>;
+				};
+				core2 {
+					cpu = <&cpu50>;
+				};
+				core3 {
+					cpu = <&cpu51>;
+				};
+			};
+
+			cluster13 {
+				core0 {
+					cpu = <&cpu52>;
+				};
+				core1 {
+					cpu = <&cpu53>;
+				};
+				core2 {
+					cpu = <&cpu54>;
+				};
+				core3 {
+					cpu = <&cpu55>;
+				};
+			};
+
+			cluster14 {
+				core0 {
+					cpu = <&cpu56>;
+				};
+				core1 {
+					cpu = <&cpu57>;
+				};
+				core2 {
+					cpu = <&cpu58>;
+				};
+				core3 {
+					cpu = <&cpu59>;
+				};
+			};
+
+			cluster15 {
+				core0 {
+					cpu = <&cpu60>;
+				};
+				core1 {
+					cpu = <&cpu61>;
+				};
+				core2 {
+					cpu = <&cpu62>;
+				};
+				core3 {
+					cpu = <&cpu63>;
+				};
+			};
+		};
+
+		cpu0: cpu@0 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x0>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu1: cpu@1 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x1>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu2: cpu@2 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x2>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu3: cpu@3 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x3>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu4: cpu@100 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x100>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu5: cpu@101 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x101>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu6: cpu@102 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x102>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu7: cpu@103 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x103>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu8: cpu@200 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x200>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu9: cpu@201 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x201>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu10: cpu@202 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x202>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu11: cpu@203 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x203>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu12: cpu@300 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x300>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu13: cpu@301 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x301>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu14: cpu@302 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x302>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu15: cpu@303 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x303>;
+			enable-method = "psci";
+			numa-node-id = <1>;
+		};
+
+		cpu16: cpu@400 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x400>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu17: cpu@401 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x401>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu18: cpu@402 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x402>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu19: cpu@403 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x403>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu20: cpu@500 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x500>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu21: cpu@501 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x501>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu22: cpu@502 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x502>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu23: cpu@503 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x503>;
+			enable-method = "psci";
+			numa-node-id = <2>;
+		};
+
+		cpu24: cpu@600 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x600>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu25: cpu@601 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x601>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu26: cpu@602 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x602>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu27: cpu@603 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x603>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu28: cpu@700 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x700>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu29: cpu@701 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x701>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu30: cpu@702 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x702>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu31: cpu@703 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x703>;
+			enable-method = "psci";
+			numa-node-id = <3>;
+		};
+
+		cpu32: cpu@800 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x800>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu33: cpu@801 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x801>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu34: cpu@802 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x802>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu35: cpu@803 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x803>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu36: cpu@900 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x900>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu37: cpu@901 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x901>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu38: cpu@902 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x902>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu39: cpu@903 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x903>;
+			enable-method = "psci";
+			numa-node-id = <4>;
+		};
+
+		cpu40: cpu@a00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xa00>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu41: cpu@a01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xa01>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu42: cpu@a02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xa02>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu43: cpu@a03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xa03>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu44: cpu@b00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xb00>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu45: cpu@b01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xb01>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu46: cpu@b02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xb02>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu47: cpu@b03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xb03>;
+			enable-method = "psci";
+			numa-node-id = <5>;
+		};
+
+		cpu48: cpu@c00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xc00>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu49: cpu@c01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xc01>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu50: cpu@c02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xc02>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu51: cpu@c03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xc03>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu52: cpu@d00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xd00>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu53: cpu@d01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xd01>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu54: cpu@d02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xd02>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu55: cpu@d03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xd03>;
+			enable-method = "psci";
+			numa-node-id = <6>;
+		};
+
+		cpu56: cpu@e00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xe00>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu57: cpu@e01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xe01>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu58: cpu@e02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xe02>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu59: cpu@e03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xe03>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu60: cpu@f00 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xf00>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu61: cpu@f01 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xf01>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu62: cpu@f02 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xf02>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+
+		cpu63: cpu@f03 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0xf03>;
+			enable-method = "psci";
+			numa-node-id = <7>;
+		};
+	};
+
+	distance-map {
+		compatible = "numa-distance-map-v1";
+		distance-matrix = <0x0 0x0 0x0a>,
+				  <0x0 0x1 0x14>,
+				  <0x0 0x2 0x28>,
+				  <0x0 0x3 0x1e>,
+				  <0x0 0x4 0x14>,
+				  <0x0 0x5 0x1e>,
+				  <0x0 0x6 0x32>,
+				  <0x0 0x7 0x28>,
+				  <0x1 0x0 0x14>,
+				  <0x1 0x1 0x0a>,
+				  <0x1 0x2 0x1e>,
+				  <0x1 0x3 0x14>,
+				  <0x1 0x4 0x1e>,
+				  <0x1 0x5 0x14>,
+				  <0x1 0x6 0x28>,
+				  <0x1 0x7 0x1e>,
+				  <0x2 0x0 0x28>,
+				  <0x2 0x1 0x1e>,
+				  <0x2 0x2 0x0a>,
+				  <0x2 0x3 0x14>,
+				  <0x2 0x4 0x32>,
+				  <0x2 0x5 0x28>,
+				  <0x2 0x6 0x14>,
+				  <0x2 0x7 0x1e>,
+				  <0x3 0x0 0x1e>,
+				  <0x3 0x1 0x14>,
+				  <0x3 0x2 0x14>,
+				  <0x3 0x3 0x0a>,
+				  <0x3 0x4 0x28>,
+				  <0x3 0x5 0x1e>,
+				  <0x3 0x6 0x1e>,
+				  <0x3 0x7 0x14>,
+				  <0x4 0x0 0x14>,
+				  <0x4 0x1 0x1e>,
+				  <0x4 0x2 0x32>,
+				  <0x4 0x3 0x28>,
+				  <0x4 0x4 0x0a>,
+				  <0x4 0x5 0x14>,
+				  <0x4 0x6 0x28>,
+				  <0x4 0x7 0x1e>,
+				  <0x5 0x0 0x1e>,
+				  <0x5 0x1 0x14>,
+				  <0x5 0x2 0x28>,
+				  <0x5 0x3 0x1e>,
+				  <0x5 0x4 0x14>,
+				  <0x5 0x5 0x0a>,
+				  <0x5 0x6 0x1e>,
+				  <0x5 0x7 0x14>,
+				  <0x6 0x0 0x32>,
+				  <0x6 0x1 0x28>,
+				  <0x6 0x2 0x14>,
+				  <0x6 0x3 0x1e>,
+				  <0x6 0x4 0x28>,
+				  <0x6 0x5 0x1e>,
+				  <0x6 0x6 0x0a>,
+				  <0x6 0x7 0x14>,
+				  <0x7 0x0 0x28>,
+				  <0x7 0x1 0x1e>,
+				  <0x7 0x2 0x1e>,
+				  <0x7 0x3 0x14>,
+				  <0x7 0x4 0x1e>,
+				  <0x7 0x5 0x14>,
+				  <0x7 0x6 0x14>,
+				  <0x7 0x7 0x0a>;
+	};
+
+
+	gic: interrupt-controller@8002a000000 {
+		compatible = "arm,gic-v3";
+                #interrupt-cells = <3>;
+                #address-cells = <2>;
+                #size-cells = <2>;
+		ranges;
+		interrupt-controller;
+		reg = <0x0800 0x2a000000 0 0x10000>,    /* GICD */
+		      <0x0800 0x2a800000 0 0x800000>,   /* GICR */
+		      <0x0800 0x29c00000 0 0x10000>,    /* GICC */
+		      <0x0800 0x29c10000 0 0x10000>,    /* GICH */
+		      <0x0800 0x29c20000 0 0x10000>;    /* GICV */
+		interrupts = <GIC_PPI 9 IRQ_TYPE_LEVEL_HIGH>;
+
+                its: gic-its@8002a020000 {
+                        compatible = "arm,gic-v3-its";
+                        msi-controller;
+                        reg = <0x0800 0x2a020000 0x0 0x20000>;
+                };
+	};
+
+        timer {
+                compatible = "arm,armv8-timer";
+                interrupts = <GIC_PPI 13 IRQ_TYPE_LEVEL_LOW>,
+                             <GIC_PPI 14 IRQ_TYPE_LEVEL_LOW>,
+                             <GIC_PPI 11 IRQ_TYPE_LEVEL_LOW>,
+                             <GIC_PPI 10 IRQ_TYPE_LEVEL_LOW>;
+                clock-frequency = <50000000>;
+        };
+
+	soc {
+		compatible = "simple-bus";
+		#address-cells = <2>;
+		#size-cells = <2>;
+		dma-coherent;
+		ranges;
+
+                uart0: serial@28000000 {
+                        compatible = "snps,dw-apb-uart";
+                        reg = <0x800 0x28000000 0x0 0x1000>;
+                        clock-frequency = <50000000>;
+                        interrupts = <GIC_SPI 34 IRQ_TYPE_LEVEL_HIGH>;
+                        reg-shift = <2>;
+                        reg-io-width = <4>;
+                        status = "disabled";
+                };
+
+                uart1: serial@28001000 {
+                        compatible = "snps,dw-apb-uart";
+                        reg = <0x800 0x28001000 0x0 0x1000>;
+                        clock-frequency = <50000000>;
+                        interrupts = <GIC_SPI 35 IRQ_TYPE_LEVEL_HIGH>;
+                        reg-shift = <2>;
+                        reg-io-width = <4>;
+                        status = "disabled";
+                };
+
+		gpio0:gpio@80028006000 {
+			compatible = "snps,dw-apb-gpio";
+			reg = <0x800 0x28006000 0x0 0x1000>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+			status = "ok";
+
+			gpio-controller@0 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <0x2>;
+				snps,nr-gpios = <0x8>;
+				reg = <0x0>;
+			};
+
+			gpio-controller@1 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <0x2>;
+				snps,nr-gpios = <0x8>;
+				reg = <0x1>;
+			};
+
+			gpio-controller@2 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <0x2>;
+				snps,nr-gpios = <0x8>;
+				reg = <0x2>;
+			};
+
+			gpio-controller@3 {
+				compatible = "snps,dw-apb-gpio-port";
+				gpio-controller;
+				#gpio-cells = <0x2>;
+				snps,nr-gpios = <0x8>;
+				reg = <0x3>;
+			};
+		};
+
+		i2c0: i2c@80028002000 {
+			compatible = "snps,designware-i2c";
+			reg = <0x800 0x28002000 0x0 0x1000>;
+                        interrupts = <GIC_SPI 36 IRQ_TYPE_LEVEL_HIGH>;
+			clock-frequency = <100000>;
+			status = "ok";
+		};
+
+		i2c1: i2c@80028003000 {
+			compatible = "snps,designware-i2c";
+			reg = <0x800 0x28003000 0x0 0x1000>;
+                        interrupts = <GIC_SPI 37 IRQ_TYPE_LEVEL_HIGH>;
+			clock-frequency = <100000>;
+			status = "ok";
+		};
+
+		pcie0: peu0-c0 {
+			compatible = "pci-host-ecam-generic";
+			device_type = "pci";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			#interrupt-cells = <1>;
+			reg = <0x800 0x40000000 0 0x10000000>;
+			msi-parent = <&its>;
+			bus-range = <0 0xff>;
+			interrupt-map-mask = <0x0 0x0 0x0 0x7>;
+			interrupt-map = <0x0 0x0 0x0 0x1 &gic 0x0 0x0 GIC_SPI 0x33 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x2 &gic 0x0 0x0 GIC_SPI 0x34 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x3 &gic 0x0 0x0 GIC_SPI 0x35 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x4 &gic 0x0 0x0 GIC_SPI 0x36 IRQ_TYPE_LEVEL_HIGH>;
+			ranges = <0x01000000 0x00 0x00000000 0x800 0x50000000 0x00 0x00f00000>,
+				 <0x02000000 0x00 0x60000000 0x800 0x60000000 0x00 0x20000000>,
+				 <0x03000000 0x20 0x00000000 0x820 0x00000000 0x20 0x00000000>;
+		};
+	};
+};
diff --git a/arch/arm64/boot/dts/phytium/ft2004-devboard-d4-dsk.dts b/arch/arm64/boot/dts/phytium/ft2004-devboard-d4-dsk.dts
new file mode 100644
index 000000000000..b97581991b00
--- /dev/null
+++ b/arch/arm64/boot/dts/phytium/ft2004-devboard-d4-dsk.dts
@@ -0,0 +1,73 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * DTS file for phytium FT-2000/4 devboard (FT-2000/4-D4-DSK series)
+ *
+ * Copyright (C) 2018-2019, Phytium Technology Co., Ltd.
+ */
+
+/dts-v1/;
+/memreserve/ 0x80000000 0x10000;
+
+#include "ft2004-generic-psci-soc.dtsi"
+
+/{
+	model = "FT-2000/4-D4-DSK Development Board";
+	compatible = "phytium,ft-2004";
+	#address-cells = <2>;
+	#size-cells = <2>;
+
+	chosen {
+		stdout-path = "uart1:115200n8";
+	};
+
+	memory@00{
+		device_type = "memory";
+		reg = <0x0 0x80000000 0x1 0x00000000>;
+	};
+
+	memory@01{
+		device_type = "memory";
+		reg = <0x20 0x00000000 0x1 0x00000000>;
+	};
+
+	firmware {
+		optee {
+			compatible = "linaro,optee-tz";
+			method = "smc";
+		};
+	};
+};
+
+&rtc0 {
+	status = "ok";
+};
+
+&uart1 {
+	status = "ok";
+};
+
+&gmac0 {
+	status = "ok";
+	phy-mode = "rgmii-id";
+};
+
+&gmac1 {
+	status = "ok";
+	phy-mode = "rgmii-id";
+};
+
+&spi0 {
+	status = "ok";
+};
+
+&qspi {
+	status = "ok";
+};
+
+&i2c0 {
+	status = "ok";
+};
+
+&i2c1 {
+	status = "ok";
+};
diff --git a/arch/arm64/boot/dts/phytium/ft2004-generic-psci-soc.dtsi b/arch/arm64/boot/dts/phytium/ft2004-generic-psci-soc.dtsi
new file mode 100644
index 000000000000..1ee1c330c465
--- /dev/null
+++ b/arch/arm64/boot/dts/phytium/ft2004-generic-psci-soc.dtsi
@@ -0,0 +1,417 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * dts file for FT-2000/4 SoC
+ *
+ * Copyright (C) 2018-2019, Phytium Technology Co., Ltd.
+ */
+
+#include <dt-bindings/interrupt-controller/arm-gic.h>
+
+/ {
+	compatible = "phytium,ft2004";
+	interrupt-parent = <&gic>;
+	#address-cells = <2>;
+	#size-cells = <2>;
+
+	aliases {
+		ethernet0 = &gmac0;
+		ethernet1 = &gmac1;
+	};
+
+	psci {
+		compatible   = "arm,psci-1.0";
+		method       = "smc";
+		cpu_suspend  = <0xc4000001>;
+		cpu_off      = <0x84000002>;
+		cpu_on       = <0xc4000003>;
+		sys_poweroff = <0x84000008>;
+		sys_reset    = <0x84000009>;
+	};
+
+	cpus {
+		#address-cells = <0x2>;
+		#size-cells = <0x0>;
+
+		cpu0: cpu@0 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x0>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu1: cpu@1 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x1>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu2: cpu@100 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x100>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+
+		cpu3: cpu@101 {
+			device_type = "cpu";
+			compatible = "arm,armv8";
+			reg = <0x0 0x101>;
+			enable-method = "psci";
+			numa-node-id = <0>;
+		};
+	};
+
+	gic: interrupt-controller@29900000 {
+		compatible = "arm,gic-v3";
+		#interrupt-cells = <3>;
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+		interrupt-controller;
+		reg = <0x0 0x29900000 0 0x20000>,       /* GICD */
+		      <0x0 0x29980000 0 0x80000>,       /* GICR */
+		      <0x0 0x29c00000 0 0x10000>,       /* GICC */
+		      <0x0 0x29c10000 0 0x10000>,       /* GICH */
+		      <0x0 0x29c20000 0 0x10000>;       /* GICV */
+		interrupts = <GIC_PPI 9 IRQ_TYPE_LEVEL_HIGH>;
+
+		its: gic-its@29920000 {
+			compatible = "arm,gic-v3-its";
+			msi-controller;
+			reg = <0x0 0x29920000 0x0 0x20000>;
+		};
+	};
+
+	timer {
+		compatible = "arm,armv8-timer";
+		interrupts = <GIC_PPI 13 IRQ_TYPE_LEVEL_LOW>,
+			     <GIC_PPI 14 IRQ_TYPE_LEVEL_LOW>,
+			     <GIC_PPI 11 IRQ_TYPE_LEVEL_LOW>,
+			     <GIC_PPI 10 IRQ_TYPE_LEVEL_LOW>;
+		clock-frequency = <48000000>;
+	};
+
+	clocks {
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+
+		clk250mhz: clk250mhz {
+			compatible = "fixed-clock";
+			#clock-cells = <0>;
+			clock-frequency = <250000000>;
+		};
+
+		sysclk_48mhz: clk48mhz {
+			compatible = "fixed-clock";
+			#clock-cells = <0>;
+			clock-frequency = <48000000>;
+		};
+
+		sysclk_600mhz: clk600mhz {
+			compatible = "fixed-clock";
+			#clock-cells = <0>;
+			clock-frequency = <600000000>;
+		};
+	};
+
+	soc {
+		compatible = "simple-bus";
+		#address-cells = <2>;
+		#size-cells = <2>;
+		dma-coherent;
+		ranges;
+
+		gpio0: gpio@28004000 {
+			compatible = "phytium,gpio";
+			reg = <0x0 0x28004000 0x0 0x1000>;
+			interrupts = <GIC_SPI 10 IRQ_TYPE_LEVEL_HIGH>;
+			gpio-controller;
+			#gpio-cells = <2>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+
+			porta {
+				compatible = "phytium,gpio-port";
+				reg = <0>;
+				nr-gpios = <8>;
+			};
+
+			portb {
+				compatible = "phytium,gpio-port";
+				reg = <1>;
+				nr-gpios = <8>;
+			};
+		};
+
+		gpio1: gpio@28005000 {
+			compatible = "phytium,gpio";
+			reg = <0x0 0x28005000 0x0 0x1000>;
+			interrupts = <GIC_SPI 11 IRQ_TYPE_LEVEL_HIGH>;
+			gpio-controller;
+			#gpio-cells = <2>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+
+			porta {
+				compatible = "phytium,gpio-port";
+				reg = <0>;
+				nr-gpios = <8>;
+			};
+
+			portb {
+				compatible = "phytium,gpio-port";
+				reg = <1>;
+				nr-gpios = <8>;
+			};
+		};
+
+		uart0: uart@28000000 {
+			compatible = "arm,pl011", "arm,primecell";
+			reg = <0x0 0x28000000 0x0 0x1000>;
+			baud = <115200>;
+			reg-shift = <2>;
+			reg-io-width = <4>;
+			interrupts = <GIC_SPI 6 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_48mhz &sysclk_48mhz>;
+			clock-names = "uartclk", "apb_pclk";
+		};
+
+		uart1: uart@28001000 {
+			compatible = "arm,pl011", "arm,primecell";
+			reg = <0x0 0x28001000 0x0 0x1000>;
+			baud = <115200>;
+			reg-shift = <2>;
+			reg-io-width = <4>;
+			interrupts = <GIC_SPI 7 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_48mhz &sysclk_48mhz>;
+			clock-names = "uartclk", "apb_pclk";
+		};
+
+		uart2: uart@28002000 {
+			compatible = "arm,pl011", "arm,primecell";
+			reg = <0x0 0x28002000 0x0 0x1000>;
+			baud = <115200>;
+			reg-shift = <2>;
+			reg-io-width = <4>;
+			interrupts = <GIC_SPI 8 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_48mhz &sysclk_48mhz>;
+			clock-names = "uartclk", "apb_pclk";
+		};
+
+		uart3: uart@28003000 {
+			compatible = "arm,pl011", "arm,primecell";
+			reg = <0x0 0x28003000 0x0 0x1000>;
+			baud = <115200>;
+			reg-shift = <2>;
+			reg-io-width = <4>;
+			interrupts = <GIC_SPI 9 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_48mhz &sysclk_48mhz>;
+			clock-names = "uartclk", "apb_pclk";
+		};
+
+		sdci: sdci@28207c00 {
+			compatible = "phytium,sdci";
+			reg = <0x0 0x28207c00 0x0 0x100>;
+			interrupts = <GIC_SPI 20 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 21 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 22 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_600mhz &sysclk_600mhz>;
+			clock-names = "phytium_sdc_clk";
+		};
+
+		watchdog0: watchdog@2800a000 {
+			compatible = "arm,sbsa-gwdt";
+			reg = <0x0 0x2800b000 0x0 0x1000>,
+			      <0x0 0x2800a000 0x0 0x1000>;
+			interrupts = <GIC_SPI 16 IRQ_TYPE_LEVEL_HIGH>;
+			timeout-sec = <30>;
+		};
+
+		watchdog1: watchdog@28016000 {
+			compatible = "arm,sbsa-gwdt";
+			reg = <0x0 0x28017000 0x0 0x1000>,
+			      <0x0 0x28016000 0x0 0x1000>;
+			interrupts = <GIC_SPI 17 IRQ_TYPE_LEVEL_HIGH>;
+			timeout-sec = <30>;
+		};
+
+		rtc0: rtc@2800d000 {
+			compatible = "phytium,rtc";
+			reg = <0x0 0x2800d000 0x0 0x1000>;
+			clocks = <&sysclk_48mhz>;
+			clock-names = "rtc_pclk";
+			interrupts = <GIC_SPI 4 IRQ_TYPE_LEVEL_HIGH>;
+			status = "disabled";
+		};
+
+		i2c0: i2c@28006000 {
+			compatible = "snps,designware-i2c";
+			reg = <0x0 0x28006000 0x0 0x1000>;
+			interrupts = <GIC_SPI 12 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_48mhz>;
+			status = "disabled";
+		};
+
+		i2c1: i2c@28007000 {
+			compatible = "snps,designware-i2c";
+			reg = <0x0 0x28007000 0x0 0x1000>;
+			interrupts = <GIC_SPI 13 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_48mhz>;
+			status = "disabled";
+		};
+
+		i2c2: i2c@28008000 {
+			compatible = "snps,designware-i2c";
+			reg = <0x0 0x28008000 0x0 0x1000>;
+			interrupts = <GIC_SPI 14 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_48mhz>;
+			status = "disabled";
+		};
+
+		i2c3: i2c@28009000 {
+			compatible = "snps,designware-i2c";
+			reg = <0x0 0x28009000 0x0 0x1000>;
+			interrupts = <GIC_SPI 15 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_48mhz>;
+			status = "disabled";
+		};
+
+		spi0: spi@2800c000 {
+			compatible = "phytium,spi";
+			interrupts = <GIC_SPI 18 IRQ_TYPE_LEVEL_HIGH>;
+			reg = <0x0 0x2800c000 0x0 0x1000>;
+			clocks = <&sysclk_48mhz>;
+			num-cs = <4>;
+		};
+
+		spi1: spi@28013000 {
+			compatible = "phytium,spi";
+			interrupts = <GIC_SPI 19 IRQ_TYPE_LEVEL_HIGH>;
+			reg = <0x0 0x28013000 0x0 0x1000>;
+			clocks = <&sysclk_48mhz>;
+			num-cs = <4>;
+		};
+
+		qspi: qspi@28014000 {
+			compatible = "phytium,qspi";
+			reg = <0x0 0x28014000 0x0     0x1000>,
+			      <0x0        0x0 0x0 0x02000000>;
+			reg-names = "qspi", "qspi_mm";
+			clocks = <&sysclk_600mhz>;
+
+			flash@0 {
+				spi-rx-bus-width = <1>;
+				spi-max-frequency = <600000000>;
+			};
+		};
+
+		pcie: pcie {
+			compatible = "pci-host-ecam-generic";
+			device_type = "pci";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			#interrupt-cells = <1>;
+			reg = <0x0 0x40000000 0x0 0x10000000>;
+			msi-parent = <&its>;
+			bus-range = <0x0 0xff>;
+			interrupt-map-mask = <0x0 0x0 0x0 0x7>;
+			interrupt-map = <0x0 0x0 0x0 0x1 &gic 0x0 0x0 GIC_SPI 28 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x2 &gic 0x0 0x0 GIC_SPI 29 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x3 &gic 0x0 0x0 GIC_SPI 30 IRQ_TYPE_LEVEL_HIGH>,
+					<0x0 0x0 0x0 0x4 &gic 0x0 0x0 GIC_SPI 31 IRQ_TYPE_LEVEL_HIGH>;
+			ranges = <0x01000000 0x00 0x00000000 0x0  0x50000000  0x0  0x00f00000>,
+				 <0x02000000 0x00 0x58000000 0x0  0x58000000  0x0  0x28000000>,
+				 <0x03000000 0x10 0x00000000 0x10 0x00000000 0x10  0x00000000>;
+		};
+
+		phytium_axi_setup: stmmac-axi-config {
+			snps,wr_osr_lmt = <0>;
+			snps,rd_osr_lmt = <0>;
+			snps,blen = <0 0 0 0 16 8 4>;
+		};
+
+		gmac0: eth@2820c000 {
+			compatible = "snps,dwmac";
+			reg = <0x0 0x2820c000 0x0 0x2000>;
+			interrupts = <GIC_SPI 49 IRQ_TYPE_LEVEL_HIGH>;
+			interrupt-names = "macirq";
+			clocks = <&clk250mhz>;
+			clock-names = "stmmaceth";
+			status = "disabled";
+
+			snps,pbl = <16>;
+			snps,fixed-burst;
+			snps,axi-config = <&phytium_axi_setup>;
+			snps,force_sf_dma_mode;
+			snps,multicast-filter-bins = <64>;
+			snps,perfect-filter-entries = <128>;
+			tx-fifo-depth = <4096>;
+			rx-fifo-depth = <4096>;
+			max-frame-size = <9000>;
+		};
+
+		gmac1: eth@28210000 {
+			compatible = "snps,dwmac";
+			reg = <0x0 0x28210000 0x0 0x2000>;
+			interrupts = <GIC_SPI 50 IRQ_TYPE_LEVEL_HIGH>;
+			interrupt-names = "macirq";
+			clocks = <&clk250mhz>;
+			clock-names = "stmmaceth";
+			status = "disabled";
+
+			snps,pbl = <16>;
+			snps,fixed-burst;
+			snps,axi-config = <&phytium_axi_setup>;
+			snps,force_sf_dma_mode;
+			snps,multicast-filter-bins = <64>;
+			snps,perfect-filter-entries = <128>;
+			snps,rx-queues-to-use = <2>;
+			tx-fifo-depth = <4096>;
+			rx-fifo-depth = <4096>;
+			max-frame-size = <9000>;
+		};
+
+		can0: can@28207000 {
+			compatible = "phytium,can";
+			reg = <0x0 0x28207000 0x0 0x400>;
+			interrupts = <GIC_SPI 87 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_600mhz>;
+			clock-names = "phytium_can_clk";
+			tx-fifo-depth = <0x40>;
+			rx-fifo-depth = <0x40>;
+		};
+
+		can1: can@28207400 {
+			compatible = "phytium,can";
+			reg = <0x0 0x28207400 0x0 0x400>;
+			interrupts = <GIC_SPI 91 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_600mhz>;
+			clock-names = "phytium_can_clk";
+			tx-fifo-depth = <0x40>;
+			rx-fifo-depth = <0x40>;
+		};
+
+		can2: can@028207800 {
+			compatible = "phytium,can";
+			reg = <0x0 0x28207800 0x0 0x400>;
+			interrupts = <GIC_SPI 92 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_600mhz>;
+			clock-names = "phytium_can_clk";
+			tx-fifo-depth = <0x40>;
+			rx-fifo-depth = <0x40>;
+		};
+
+		hda: hda@28206000 {
+			compatible = "phytium,hda";
+			reg = <0 0x28206000 0x0 0x1000>;
+			interrupts = <GIC_SPI 23 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&sysclk_48mhz>;
+			clock-names = "phytium_hda_clk";
+		};
+	};
+};
diff --git a/arch/arm64/configs/defconfig b/arch/arm64/configs/defconfig
index db8d364f8476..326216599d66 100644
--- a/arch/arm64/configs/defconfig
+++ b/arch/arm64/configs/defconfig
@@ -45,6 +45,7 @@ CONFIG_ARCH_HISI=y
 CONFIG_ARCH_MEDIATEK=y
 CONFIG_ARCH_MESON=y
 CONFIG_ARCH_MVEBU=y
+CONFIG_ARCH_PHYTIUM=y
 CONFIG_ARCH_QCOM=y
 CONFIG_ARCH_ROCKCHIP=y
 CONFIG_ARCH_SEATTLE=y
@@ -234,7 +235,8 @@ CONFIG_SMC91X=y
 CONFIG_SMSC911X=y
 CONFIG_SNI_AVE=y
 CONFIG_SNI_NETSEC=y
-CONFIG_STMMAC_ETH=m
+CONFIG_STMMAC_ETH=y
+CONFIG_STMMAC_PLATFORM=y
 CONFIG_MDIO_BUS_MUX_MMIOREG=y
 CONFIG_AT803X_PHY=m
 CONFIG_MARVELL_PHY=m
@@ -322,6 +324,8 @@ CONFIG_SPI_BCM2835AUX=m
 CONFIG_SPI_MESON_SPICC=m
 CONFIG_SPI_MESON_SPIFC=m
 CONFIG_SPI_ORION=y
+CONFIG_SPI_PHYTIUM=y
+CONFIG_SPI_PHYTIUM_QUADSPI=y
 CONFIG_SPI_PL022=y
 CONFIG_SPI_ROCKCHIP=y
 CONFIG_SPI_QUP=y
@@ -347,6 +351,7 @@ CONFIG_GPIO_XGENE_SB=y
 CONFIG_GPIO_PCA953X=y
 CONFIG_GPIO_PCA953X_IRQ=y
 CONFIG_GPIO_MAX77620=y
+CONFIG_GPIO_PHYTIUM=y
 CONFIG_POWER_AVS=y
 CONFIG_ROCKCHIP_IODOMAIN=y
 CONFIG_POWER_RESET_MSM=y
@@ -476,6 +481,7 @@ CONFIG_SND_SOC_RT5514_SPI=m
 CONFIG_SND_SOC_RT5645=m
 CONFIG_SND_SIMPLE_CARD=m
 CONFIG_SND_AUDIO_GRAPH_CARD=m
+CONFIG_SND_HDA_PHYTIUM=m
 CONFIG_I2C_HID=m
 CONFIG_USB=y
 CONFIG_USB_OTG=y
@@ -528,6 +534,7 @@ CONFIG_MMC_DW_ROCKCHIP=y
 CONFIG_MMC_SUNXI=y
 CONFIG_MMC_BCM2835=y
 CONFIG_MMC_SDHCI_XENON=y
+CONFIG_MMC_PHYTIUM_SDCI=y
 CONFIG_NEW_LEDS=y
 CONFIG_LEDS_CLASS=y
 CONFIG_LEDS_GPIO=y
@@ -553,6 +560,7 @@ CONFIG_RTC_DRV_SUN6I=y
 CONFIG_RTC_DRV_ARMADA38X=y
 CONFIG_RTC_DRV_TEGRA=y
 CONFIG_RTC_DRV_XGENE=y
+CONFIG_RTC_DRV_PHYTIUM=y
 CONFIG_DMADEVICES=y
 CONFIG_DMA_BCM2835=m
 CONFIG_K3_DMA=y
@@ -711,3 +719,5 @@ CONFIG_CRYPTO_AES_ARM64_CE_CCM=y
 CONFIG_CRYPTO_AES_ARM64_CE_BLK=y
 CONFIG_CRYPTO_CHACHA20_NEON=m
 CONFIG_CRYPTO_AES_ARM64_BS=m
+CONFIG_CAN=y
+CONFIG_CAN_PHYTIUM=y
diff --git a/drivers/acpi/acpi_apd.c b/drivers/acpi/acpi_apd.c
index 2664452fa112..bed74949d039 100644
--- a/drivers/acpi/acpi_apd.c
+++ b/drivers/acpi/acpi_apd.c
@@ -162,6 +162,12 @@ static const struct apd_device_desc hip08_i2c_desc = {
 	.setup = acpi_apd_setup,
 	.fixed_clk_rate = 250000000,
 };
+
+static const struct apd_device_desc phytium_i2c_desc = {
+	.setup = acpi_apd_setup,
+	.fixed_clk_rate = 200000000,
+};
+
 static const struct apd_device_desc thunderx2_i2c_desc = {
 	.setup = acpi_apd_setup,
 	.fixed_clk_rate = 125000000,
@@ -234,6 +240,7 @@ static const struct acpi_device_id acpi_apd_device_ids[] = {
 	{ "CAV9007",  APD_ADDR(thunderx2_i2c_desc) },
 	{ "HISI02A1", APD_ADDR(hip07_i2c_desc) },
 	{ "HISI02A2", APD_ADDR(hip08_i2c_desc) },
+	{ "PHYT0003", APD_ADDR(phytium_i2c_desc) },
 #endif
 	{ }
 };
diff --git a/drivers/gpio/Kconfig b/drivers/gpio/Kconfig
index 4f52c3a8ec99..80d8ef1ce387 100644
--- a/drivers/gpio/Kconfig
+++ b/drivers/gpio/Kconfig
@@ -404,6 +404,15 @@ config GPIO_OMAP
 	help
 	  Say yes here to enable GPIO support for TI OMAP SoCs.
 
+config GPIO_PHYTIUM
+	tristate "Phytium GPIO support"
+	default y if ARCH_PHYTIUM
+	depends on ARM64
+	select IRQ_DOMAIN
+	select GENERIC_IRQ_CHIP
+	help
+	  Say yes here to enable GPIO support for Phytium SoCs.
+
 config GPIO_PL061
 	bool "PrimeCell PL061 GPIO support"
 	depends on ARM_AMBA
diff --git a/drivers/gpio/Makefile b/drivers/gpio/Makefile
index c256aff66a65..bff63b3e3b00 100644
--- a/drivers/gpio/Makefile
+++ b/drivers/gpio/Makefile
@@ -95,6 +95,7 @@ obj-$(CONFIG_GPIO_MXC)		+= gpio-mxc.o
 obj-$(CONFIG_GPIO_MXS)		+= gpio-mxs.o
 obj-$(CONFIG_GPIO_OCTEON)	+= gpio-octeon.o
 obj-$(CONFIG_GPIO_OMAP)		+= gpio-omap.o
+obj-$(CONFIG_GPIO_PHYTIUM)	+= gpio-phytium.o
 obj-$(CONFIG_GPIO_PCA953X)	+= gpio-pca953x.o
 obj-$(CONFIG_GPIO_PCF857X)	+= gpio-pcf857x.o
 obj-$(CONFIG_GPIO_PCH)		+= gpio-pch.o
diff --git a/drivers/gpio/gpio-phytium.c b/drivers/gpio/gpio-phytium.c
new file mode 100644
index 000000000000..f9140c684efd
--- /dev/null
+++ b/drivers/gpio/gpio-phytium.c
@@ -0,0 +1,600 @@
+/*
+ * Support functions for Phytium GPIO
+ *
+ * Copyright (c) 2019, Phytium Corporation.
+ * Written by Chen Baozi <chenbaozi@phytium.com.cn>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/acpi.h>
+#include <linux/err.h>
+#include <linux/gpio/driver.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/ioport.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/irqchip/chained_irq.h>
+#include <linux/bitops.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/property.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+
+#include "gpiolib.h"
+
+#define GPIO_SWPORTA_DR		0x00 /* WR Port A Output Data Register */
+#define GPIO_SWPORTA_DDR	0x04 /* WR Port A Data Direction Register */
+#define GPIO_EXT_PORTA		0x08 /* RO Port A Input Data Register */
+#define GPIO_SWPORTB_DR		0x0c /* WR Port B Output Data Register */
+#define GPIO_SWPORTB_DDR	0x10 /* WR Port B Data Direction Register */
+#define GPIO_EXT_PORTB		0x14 /* RO Port B Input Data Register */
+
+#define GPIO_INTEN		0x18 /* WR Port A Interrput Enable Register */
+#define GPIO_INTMASK		0x1c /* WR Port A Interrupt Mask Register */
+#define GPIO_INTTYPE_LEVEL	0x20 /* WR Port A Interrupt Level Register */
+#define GPIO_INT_POLARITY	0x24 /* WR Port A Interrupt Polarity Register */
+#define GPIO_INTSTATUS		0x28 /* RO Port A Interrupt Status Register */
+#define GPIO_RAW_INTSTATUS	0x2c /* RO Port A Raw Interrupt Status Register */
+#define GPIO_LS_SYNC		0x30 /* WR Level-sensitive Synchronization Enable Register */
+#define GPIO_DEBOUNCE		0x34 /* WR Debounce Enable Register */
+#define GPIO_PORTA_EOI		0x38 /* WO Port A Clear Interrupt Register */
+
+#define MAX_NPORTS		2
+#define NGPIO_DEFAULT		8
+#define NGPIO_MAX		32
+#define GPIO_PORT_STRIDE	(GPIO_EXT_PORTB - GPIO_EXT_PORTA)
+
+struct pin_loc {
+	unsigned port;
+	unsigned offset;
+};
+
+#ifdef CONFIG_PM_SLEEP
+struct phytium_gpio_ctx {
+	u32 swporta_dr;
+	u32 swporta_ddr;
+	u32 ext_porta;
+	u32 swportb_dr;
+	u32 swportb_ddr;
+	u32 ext_portb;
+	u32 inten;
+	u32 intmask;
+	u32 inttype_level;
+	u32 int_polarity;
+	u32 intstatus;
+	u32 raw_intstatus;
+	u32 ls_sync;
+	u32 debounce;
+};
+#endif
+
+struct phytium_gpio {
+	raw_spinlock_t		lock;
+	void __iomem		*regs;
+	struct gpio_chip	gc;
+	unsigned int		ngpio[2];
+	int			irq;
+#ifdef CONFIG_PM_SLEEP
+	struct phytium_gpio_ctx	ctx;
+#endif
+};
+
+static int get_pin_location(struct phytium_gpio *gpio, unsigned int offset,
+			    struct pin_loc *pl)
+{
+	int ret;
+
+	if (offset < gpio->ngpio[0]) {
+		pl->port = 0;
+		pl->offset = offset;
+		ret = 0;
+	} else if (offset < (gpio->ngpio[0] + gpio->ngpio[1])) {
+		pl->port = 1;
+		pl->offset = offset - gpio->ngpio[0];
+		ret = 0;
+	} else {
+		ret = -EINVAL;
+	}
+
+	return ret;
+}
+
+static void phytium_gpio_toggle_trigger(struct phytium_gpio *gpio,
+					unsigned int offset)
+{
+	struct gpio_chip *gc;
+	u32 pol;
+	int val;
+
+	/* Only port A can provide interrupt source */
+	if (offset >= gpio->ngpio[0])
+		return;
+
+	gc = &gpio->gc;
+
+	pol = readl(gpio->regs + GPIO_INT_POLARITY);
+	/* Just read the current value right out of the data register */
+	val = gc->get(gc, offset);
+	if (val)
+		pol &= ~BIT(offset);
+	else
+		pol |= ~BIT(offset);
+
+	writel(pol, gpio->regs + GPIO_INT_POLARITY);
+}
+
+static void phytium_gpio_irq_ack(struct irq_data *d)
+{
+	struct gpio_chip *gc = irq_data_get_irq_chip_data(d);
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	u32 val = BIT(irqd_to_hwirq(d));
+
+	raw_spin_lock(&gpio->lock);
+
+	writel(val , gpio->regs + GPIO_PORTA_EOI);
+
+	raw_spin_unlock(&gpio->lock);
+}
+
+static void phytium_gpio_irq_mask(struct irq_data *d)
+{
+	struct gpio_chip *gc = irq_data_get_irq_chip_data(d);
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	u32 val;
+
+	/* Only port A can provide interrupt source */
+	if (irqd_to_hwirq(d) >= gpio->ngpio[0])
+		return;
+
+	raw_spin_lock(&gpio->lock);
+
+	val = readl(gpio->regs + GPIO_INTMASK);
+	val |= BIT(irqd_to_hwirq(d));
+	writel(val, gpio->regs + GPIO_INTMASK);
+
+	raw_spin_unlock(&gpio->lock);
+}
+
+static void phytium_gpio_irq_unmask(struct irq_data *d)
+{
+	struct gpio_chip *gc = irq_data_get_irq_chip_data(d);
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	u32 val;
+
+	/* Only port A can provide interrupt source */
+	if (irqd_to_hwirq(d) >= gpio->ngpio[0])
+		return;
+
+	raw_spin_lock(&gpio->lock);
+
+	val = readl(gpio->regs + GPIO_INTMASK);
+	val &= ~BIT(irqd_to_hwirq(d));
+	writel(val, gpio->regs + GPIO_INTMASK);
+
+	raw_spin_unlock(&gpio->lock);
+}
+
+static int phytium_gpio_irq_set_type(struct irq_data *d, unsigned int flow_type)
+{
+	struct gpio_chip *gc = irq_data_get_irq_chip_data(d);
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	int hwirq = irqd_to_hwirq(d);
+	unsigned long flags, lvl, pol;
+
+	if (hwirq < 0 || hwirq >= gpio->ngpio[0])
+		return -EINVAL;
+
+	if ((flow_type & (IRQ_TYPE_LEVEL_HIGH | IRQ_TYPE_LEVEL_LOW)) &&
+	    (flow_type & (IRQ_TYPE_EDGE_RISING | IRQ_TYPE_EDGE_FALLING))) {
+		dev_err(gc->parent,
+			"trying to configure line %d for both level and edge "
+			"detection, choose one!\n",
+			hwirq);
+		return -EINVAL;
+	}
+
+	raw_spin_lock_irqsave(&gpio->lock, flags);
+
+	lvl = readl(gpio->regs + GPIO_INTTYPE_LEVEL);
+	pol = readl(gpio->regs + GPIO_INT_POLARITY);
+
+	switch (flow_type) {
+	case IRQ_TYPE_EDGE_BOTH:
+		lvl |= BIT(hwirq);
+		phytium_gpio_toggle_trigger(gpio, hwirq);
+		irq_set_handler_locked(d, handle_edge_irq);
+		dev_dbg(gc->parent, "line %d: IRQ on both edges\n", hwirq);
+		break;
+	case IRQ_TYPE_EDGE_RISING:
+		lvl |= BIT(hwirq);
+		pol |= BIT(hwirq);
+		irq_set_handler_locked(d, handle_edge_irq);
+		dev_dbg(gc->parent, "line %d: IRQ on RISING edge\n", hwirq);
+		break;
+	case IRQ_TYPE_EDGE_FALLING:
+		lvl |= BIT(hwirq);
+		pol &= ~BIT(hwirq);
+		irq_set_handler_locked(d, handle_edge_irq);
+		dev_dbg(gc->parent, "line %d: IRQ on FALLING edge\n", hwirq);
+		break;
+	case IRQ_TYPE_LEVEL_HIGH:
+		lvl &= ~BIT(hwirq);
+		pol |= BIT(hwirq);
+		irq_set_handler_locked(d, handle_level_irq);
+		dev_dbg(gc->parent, "line %d: IRQ on HIGH level\n", hwirq);
+		break;
+	case IRQ_TYPE_LEVEL_LOW:
+		lvl &= ~BIT(hwirq);
+		pol &= ~BIT(hwirq);
+		irq_set_handler_locked(d, handle_level_irq);
+		dev_dbg(gc->parent, "line %d: IRQ on LOW level\n", hwirq);
+		break;
+	}
+
+	writel(lvl, gpio->regs + GPIO_INTTYPE_LEVEL);
+	if (flow_type != IRQ_TYPE_EDGE_BOTH)
+		writel(pol, gpio->regs + GPIO_INT_POLARITY);
+
+	raw_spin_unlock_irqrestore(&gpio->lock, flags);
+
+	return 0;
+}
+
+static void phytium_gpio_irq_enable(struct irq_data *d)
+{
+	struct gpio_chip *gc = irq_data_get_irq_chip_data(d);
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	unsigned long flags;
+	u32 val;
+
+	/* Only port A can provide interrupt source */
+	if (irqd_to_hwirq(d) >= gpio->ngpio[0])
+		return;
+
+	raw_spin_lock_irqsave(&gpio->lock, flags);
+
+	val = readl(gpio->regs + GPIO_INTEN);
+	val |= BIT(irqd_to_hwirq(d));
+	writel(val, gpio->regs + GPIO_INTEN);
+
+	raw_spin_unlock_irqrestore(&gpio->lock, flags);
+}
+
+static void phytium_gpio_irq_disable(struct irq_data *d)
+{
+	struct gpio_chip *gc = irq_data_get_irq_chip_data(d);
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	unsigned long flags;
+	u32 val;
+
+	/* Only port A can provide interrupt source */
+	if (irqd_to_hwirq(d) >= gpio->ngpio[0])
+		return;
+
+	raw_spin_lock_irqsave(&gpio->lock, flags);
+
+	val = readl(gpio->regs + GPIO_INTEN);
+	val &= ~BIT(irqd_to_hwirq(d));
+	writel(val, gpio->regs + GPIO_INTEN);
+
+	raw_spin_unlock_irqrestore(&gpio->lock, flags);
+}
+
+static void phytium_gpio_irq_handler(struct irq_desc *desc)
+{
+	struct gpio_chip *gc = irq_desc_get_handler_data(desc);
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	struct irq_chip *irqchip = irq_desc_get_chip(desc);
+	unsigned long pending;
+	int offset;
+
+	chained_irq_enter(irqchip, desc);
+
+	pending = readl(gpio->regs + GPIO_INTSTATUS);
+	if (pending) {
+		for_each_set_bit(offset, &pending, gpio->ngpio[0]) {
+			int gpio_irq = irq_find_mapping(gc->irq.domain,
+							offset);
+			generic_handle_irq(gpio_irq);
+
+			if ((irq_get_trigger_type(gpio_irq) &
+			    IRQ_TYPE_SENSE_MASK) == IRQ_TYPE_EDGE_BOTH)
+				phytium_gpio_toggle_trigger(gpio, offset);
+		}
+	}
+
+	chained_irq_exit(irqchip, desc);
+}
+
+static struct irq_chip phytium_gpio_irqchip = {
+	.name 			= "phytium_gpio",
+	.irq_ack		= phytium_gpio_irq_ack,
+	.irq_mask		= phytium_gpio_irq_mask,
+	.irq_unmask		= phytium_gpio_irq_unmask,
+	.irq_set_type		= phytium_gpio_irq_set_type,
+	.irq_enable		= phytium_gpio_irq_enable,
+	.irq_disable		= phytium_gpio_irq_disable,
+};
+
+static const struct of_device_id phytium_gpio_of_match[] = {
+	{ .compatible = "phytium,gpio", },
+	{ }
+};
+MODULE_DEVICE_TABLE(of, phytium_gpio_of_match);
+
+static const struct acpi_device_id phytium_gpio_acpi_match[] = {
+	{ "PHYT0001", 0 },
+	{ }
+};
+MODULE_DEVICE_TABLE(acpi, phytium_gpio_acpi_match);
+
+static int phytium_gpio_get_direction(struct gpio_chip *gc, unsigned offset)
+{
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	struct pin_loc loc;
+	void __iomem *ddr;
+
+	if (get_pin_location(gpio, offset, &loc))
+		return -EINVAL;
+	ddr = gpio->regs + GPIO_SWPORTA_DDR + (loc.port * GPIO_PORT_STRIDE);
+
+	return !(readl(ddr) & BIT(loc.offset));
+}
+
+static int phytium_gpio_direction_input(struct gpio_chip *gc, unsigned offset)
+{
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	struct pin_loc loc;
+	unsigned long flags;
+	void __iomem *ddr;
+
+	if (get_pin_location(gpio, offset, &loc))
+		return -EINVAL;
+	ddr = gpio->regs + GPIO_SWPORTA_DDR + (loc.port * GPIO_PORT_STRIDE);
+
+	raw_spin_lock_irqsave(&gpio->lock, flags);
+
+	writel(readl(ddr) & ~(BIT(loc.offset)), ddr);
+
+	raw_spin_unlock_irqrestore(&gpio->lock, flags);
+
+	return 0;
+}
+
+static void phytium_gpio_set(struct gpio_chip *gc, unsigned offset, int value)
+{
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	struct pin_loc loc;
+	void __iomem *dr;
+	unsigned long flags;
+	u32 mask;
+
+	if (get_pin_location(gpio, offset, &loc))
+		return;
+	dr = gpio->regs + GPIO_SWPORTA_DR + (loc.port * GPIO_PORT_STRIDE);
+
+	raw_spin_lock_irqsave(&gpio->lock, flags);
+
+	if (value)
+		mask = readl(dr) | BIT(loc.offset);
+	else
+		mask = readl(dr) & ~BIT(loc.offset);
+
+	writel(mask, dr);
+
+	raw_spin_unlock_irqrestore(&gpio->lock, flags);
+
+	return;
+}
+
+static int phytium_gpio_direction_output(struct gpio_chip *gc, unsigned offset,
+					 int value)
+{
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	struct pin_loc loc;
+	unsigned long flags;
+	void __iomem *ddr;
+
+	if (get_pin_location(gpio, offset, &loc))
+		return -EINVAL;
+	ddr = gpio->regs + GPIO_SWPORTA_DDR + (loc.port * GPIO_PORT_STRIDE);
+
+	raw_spin_lock_irqsave(&gpio->lock, flags);
+
+	writel(readl(ddr) | BIT(loc.offset), ddr);
+
+	raw_spin_unlock_irqrestore(&gpio->lock, flags);
+
+	phytium_gpio_set(gc, offset, value);
+
+	return 0;
+}
+
+static int phytium_gpio_get(struct gpio_chip *gc, unsigned offset)
+{
+	struct phytium_gpio *gpio = gpiochip_get_data(gc);
+	struct pin_loc loc;
+	void __iomem *dat;
+
+	if (get_pin_location(gpio, offset, &loc))
+		return -EINVAL;
+
+	dat = gpio->regs + GPIO_EXT_PORTA + (loc.port * GPIO_PORT_STRIDE);
+
+	return !!(readl(dat) & BIT(loc.offset));
+}
+
+static int phytium_gpio_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct phytium_gpio *gpio;
+	struct fwnode_handle *fwnode;
+	int err;
+
+	gpio = devm_kzalloc(&pdev->dev, sizeof(*gpio), GFP_KERNEL);
+	if (!gpio)
+		return -ENOMEM;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	gpio->regs = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(gpio->regs))
+		return PTR_ERR(gpio->regs);
+
+	gpio->irq = -ENXIO;
+	gpio->irq = platform_get_irq(pdev, 0);
+	if (gpio->irq < 0)
+		dev_warn(dev, "no irq is found.\n");
+
+	if (!device_get_child_node_count(dev))
+		return -ENODEV;
+
+	device_for_each_child_node(dev, fwnode) {
+		int idx;
+
+		if (fwnode_property_read_u32(fwnode, "reg", &idx) ||
+		    idx >= MAX_NPORTS) {
+			dev_err(dev, "missing/invalid port index\n");
+			fwnode_handle_put(fwnode);
+			return -EINVAL;
+		}
+
+		if (fwnode_property_read_u32(fwnode, "nr-gpios",
+					     &gpio->ngpio[idx])) {
+			dev_info(dev,
+				 "failed to get number of gpios for Port%c\n",
+				 idx ? 'B' : 'A');
+			gpio->ngpio[idx] = NGPIO_DEFAULT;
+		}
+	}
+
+	/* irq_chip support */
+	raw_spin_lock_init(&gpio->lock);
+
+	gpio->gc.base = -1;
+	gpio->gc.get_direction = phytium_gpio_get_direction;
+	gpio->gc.direction_input = phytium_gpio_direction_input;
+	gpio->gc.direction_output = phytium_gpio_direction_output;
+	gpio->gc.get = phytium_gpio_get;
+	gpio->gc.set = phytium_gpio_set;
+	gpio->gc.ngpio = gpio->ngpio[0] + gpio->ngpio[1];
+	gpio->gc.label = dev_name(dev);
+	gpio->gc.parent = dev;
+	gpio->gc.owner = THIS_MODULE;
+
+	err = gpiochip_add_data(&gpio->gc, gpio);
+	if (err) {
+		dev_err(dev, "failed to register gpiochip\n");
+		goto err1;
+	}
+
+	err = gpiochip_irqchip_add(&gpio->gc, &phytium_gpio_irqchip,
+				   0, handle_bad_irq, IRQ_TYPE_NONE);
+	if (err) {
+		dev_info(dev, "could not add irqchip\n");
+		goto err0;
+	}
+	gpiochip_set_chained_irqchip(&gpio->gc, &phytium_gpio_irqchip,
+				     gpio->irq,
+				     phytium_gpio_irq_handler);
+
+	platform_set_drvdata(pdev, gpio);
+	dev_info(dev, "Phytium GPIO controller @%pa registered\n",
+		&res->start);
+
+	return 0;
+
+err1:
+	gpiochip_remove(&gpio->gc);
+err0:
+	return err;
+}
+
+static int phytium_gpio_remove(struct platform_device *pdev)
+{
+	struct phytium_gpio *gpio = platform_get_drvdata(pdev);
+
+	gpiochip_remove(&gpio->gc);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM_SLEEP
+static int phytium_gpio_suspend(struct device *dev)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct phytium_gpio *gpio = platform_get_drvdata(pdev);
+	unsigned long flags;
+
+	raw_spin_lock_irqsave(&gpio->lock, flags);
+
+	gpio->ctx.swporta_dr = readl(gpio->regs + GPIO_SWPORTA_DR);
+	gpio->ctx.swporta_ddr = readl(gpio->regs + GPIO_SWPORTA_DDR);
+	gpio->ctx.ext_porta = readl(gpio->regs + GPIO_EXT_PORTA);
+	gpio->ctx.swportb_dr = readl(gpio->regs + GPIO_SWPORTB_DR);
+	gpio->ctx.swportb_ddr = readl(gpio->regs + GPIO_SWPORTB_DDR);
+	gpio->ctx.ext_portb = readl(gpio->regs + GPIO_EXT_PORTB);
+
+	gpio->ctx.inten = readl(gpio->regs + GPIO_INTEN);
+	gpio->ctx.intmask = readl(gpio->regs + GPIO_INTMASK);
+	gpio->ctx.inttype_level = readl(gpio->regs + GPIO_INTTYPE_LEVEL);
+	gpio->ctx.int_polarity = readl(gpio->regs + GPIO_INT_POLARITY);
+	gpio->ctx.debounce = readl(gpio->regs + GPIO_DEBOUNCE);
+
+	raw_spin_unlock_irqrestore(&gpio->lock, flags);
+
+	return 0;
+}
+
+static int phytium_gpio_resume(struct device *dev)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct phytium_gpio *gpio = platform_get_drvdata(pdev);
+	unsigned long flags;
+
+	raw_spin_lock_irqsave(&gpio->lock, flags);
+
+	writel(gpio->ctx.swporta_dr, gpio->regs + GPIO_SWPORTA_DR);
+	writel(gpio->ctx.swporta_ddr, gpio->regs + GPIO_SWPORTA_DDR);
+	writel(gpio->ctx.ext_porta, gpio->regs + GPIO_EXT_PORTA);
+	writel(gpio->ctx.swportb_dr, gpio->regs + GPIO_SWPORTB_DR);
+	writel(gpio->ctx.swportb_ddr, gpio->regs + GPIO_SWPORTB_DDR);
+	writel(gpio->ctx.ext_portb, gpio->regs + GPIO_EXT_PORTB);
+
+	writel(gpio->ctx.inten, gpio->regs + GPIO_INTEN);
+	writel(gpio->ctx.intmask, gpio->regs + GPIO_INTMASK);
+	writel(gpio->ctx.inttype_level, gpio->regs + GPIO_INTTYPE_LEVEL);
+	writel(gpio->ctx.int_polarity, gpio->regs + GPIO_INT_POLARITY);
+	writel(gpio->ctx.debounce, gpio->regs + GPIO_DEBOUNCE);
+
+	writel(0xffffffff, gpio->regs + GPIO_PORTA_EOI);
+
+	raw_spin_unlock_irqrestore(&gpio->lock, flags);
+
+	return 0;
+}
+#endif
+
+static SIMPLE_DEV_PM_OPS(phytium_gpio_pm_ops, phytium_gpio_suspend,
+			 phytium_gpio_resume);
+
+static struct platform_driver phytium_gpio_driver = {
+	.driver		= {
+		.name	= "gpio-phytium",
+		.pm	= &phytium_gpio_pm_ops,
+		.of_match_table = of_match_ptr(phytium_gpio_of_match),
+		.acpi_match_table = ACPI_PTR(phytium_gpio_acpi_match),
+	},
+	.probe		= phytium_gpio_probe,
+	.remove		= phytium_gpio_remove,
+};
+
+module_platform_driver(phytium_gpio_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Chen Baozi <chenbaozi@phytium.com.cn>");
+MODULE_DESCRIPTION("Phytium GPIO driver");
diff --git a/drivers/i2c/busses/i2c-designware-platdrv.c b/drivers/i2c/busses/i2c-designware-platdrv.c
index b5750fd85125..3818b7a0a847 100644
--- a/drivers/i2c/busses/i2c-designware-platdrv.c
+++ b/drivers/i2c/busses/i2c-designware-platdrv.c
@@ -151,6 +151,7 @@ static const struct acpi_device_id dw_i2c_acpi_match[] = {
 	{ "APMC0D0F", 0 },
 	{ "HISI02A1", 0 },
 	{ "HISI02A2", 0 },
+	{ "PHYT0003", 0 },
 	{ }
 };
 MODULE_DEVICE_TABLE(acpi, dw_i2c_acpi_match);
diff --git a/drivers/irqchip/Kconfig b/drivers/irqchip/Kconfig
index 383e7b70221d..3af69a0c264a 100644
--- a/drivers/irqchip/Kconfig
+++ b/drivers/irqchip/Kconfig
@@ -57,6 +57,15 @@ config ARM_GIC_V3_ITS_FSL_MC
 	depends on FSL_MC_BUS
 	default ARM_GIC_V3_ITS
 
+config ARM_GIC_PHYTIUM_2500
+	bool
+	select IRQ_DOMAIN
+	select GENERIC_IRQ_MULTI_HANDLER
+	select IRQ_DOMAIN_HIERARCHY
+	select PARTITION_PERCPU
+	select GENERIC_IRQ_EFFECTIVE_AFF_MASK
+	select GENERIC_MSI_IRQ_DOMAIN
+
 config ARM_NVIC
 	bool
 	select IRQ_DOMAIN
diff --git a/drivers/irqchip/Makefile b/drivers/irqchip/Makefile
index fbd1ec8070ef..7ee4db82d983 100644
--- a/drivers/irqchip/Makefile
+++ b/drivers/irqchip/Makefile
@@ -31,6 +31,7 @@ obj-$(CONFIG_ARM_GIC_V3)		+= irq-gic-v3.o irq-gic-v3-mbi.o irq-gic-common.o
 obj-$(CONFIG_ARM_GIC_V3_ITS)		+= irq-gic-v3-its.o irq-gic-v3-its-platform-msi.o irq-gic-v4.o
 obj-$(CONFIG_ARM_GIC_V3_ITS_PCI)	+= irq-gic-v3-its-pci-msi.o
 obj-$(CONFIG_ARM_GIC_V3_ITS_FSL_MC)	+= irq-gic-v3-its-fsl-mc-msi.o
+obj-$(CONFIG_ARM_GIC_PHYTIUM_2500)	+= irq-gic-phytium-2500.o irq-gic-phytium-2500-its.o
 obj-$(CONFIG_PARTITION_PERCPU)		+= irq-partition-percpu.o
 obj-$(CONFIG_HISILICON_IRQ_MBIGEN)	+= irq-mbigen.o
 obj-$(CONFIG_ARM_NVIC)			+= irq-nvic.o
diff --git a/drivers/irqchip/irq-gic-phytium-2500-its.c b/drivers/irqchip/irq-gic-phytium-2500-its.c
new file mode 100644
index 000000000000..b70cc7f945de
--- /dev/null
+++ b/drivers/irqchip/irq-gic-phytium-2500-its.c
@@ -0,0 +1,3862 @@
+/*
+ * Copyright (C) 2020 Phytium Corporation.
+ * Author: Wang Yinfeng <wangyinfeng@phytium.com.cn>
+ *         Chen Baozi <chenbaozi@phytium.com.cn>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/acpi.h>
+#include <linux/acpi_iort.h>
+#include <linux/bitmap.h>
+#include <linux/cpu.h>
+#include <linux/delay.h>
+#include <linux/dma-iommu.h>
+#include <linux/interrupt.h>
+#include <linux/irqdomain.h>
+#include <linux/list.h>
+#include <linux/list_sort.h>
+#include <linux/log2.h>
+#include <linux/mm.h>
+#include <linux/msi.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/of_pci.h>
+#include <linux/of_platform.h>
+#include <linux/percpu.h>
+#include <linux/slab.h>
+#include <linux/syscore_ops.h>
+
+#include <linux/irqchip.h>
+#include <linux/irqchip/arm-gic-phytium-2500.h>
+#include <linux/irqchip/arm-gic-v4.h>
+
+#include <asm/cputype.h>
+#include <asm/exception.h>
+#include <asm/smp_plat.h>
+
+#include "irq-gic-common.h"
+
+#define ITS_FLAGS_CMDQ_NEEDS_FLUSHING		(1ULL << 0)
+#define ITS_FLAGS_WORKAROUND_CAVIUM_22375	(1ULL << 1)
+#define ITS_FLAGS_WORKAROUND_CAVIUM_23144	(1ULL << 2)
+#define ITS_FLAGS_SAVE_SUSPEND_STATE		(1ULL << 3)
+
+#define RDIST_FLAGS_PROPBASE_NEEDS_FLUSHING	(1 << 0)
+
+static u32 lpi_id_bits;
+
+/*
+ * We allocate memory for PROPBASE to cover 2 ^ lpi_id_bits LPIs to
+ * deal with (one configuration byte per interrupt). PENDBASE has to
+ * be 64kB aligned (one bit per LPI, plus 8192 bits for SPI/PPI/SGI).
+ */
+#define LPI_NRBITS		lpi_id_bits
+#define LPI_PROPBASE_SZ		ALIGN(BIT(LPI_NRBITS), SZ_64K)
+#define LPI_PENDBASE_SZ		ALIGN(BIT(LPI_NRBITS) / 8, SZ_64K)
+
+#define LPI_PROP_DEFAULT_PRIO	0xa0
+
+/*
+ * Collection structure - just an ID, and a redistributor address to
+ * ping. We use one per CPU as a bag of interrupts assigned to this
+ * CPU.
+ */
+struct its_collection {
+	u64			target_address;
+	u16			col_id;
+};
+
+/*
+ * The ITS_BASER structure - contains memory information, cached
+ * value of BASER register configuration and ITS page size.
+ */
+struct its_baser {
+	void		*base;
+	u64		val;
+	u32		order;
+	u32		psz;
+};
+
+struct its_device;
+
+/*
+ * The ITS structure - contains most of the infrastructure, with the
+ * top-level MSI domain, the command queue, the collections, and the
+ * list of devices writing to it.
+ */
+struct its_node {
+	raw_spinlock_t		lock;
+	struct list_head	entry;
+	void __iomem		*base;
+	phys_addr_t		phys_base;
+	struct its_cmd_block	*cmd_base;
+	struct its_cmd_block	*cmd_write;
+	struct its_baser	tables[GITS_BASER_NR_REGS];
+	struct its_collection	*collections;
+	struct fwnode_handle	*fwnode_handle;
+	u64			(*get_msi_base)(struct its_device *its_dev);
+	u64			cbaser_save;
+	u32			ctlr_save;
+	struct list_head	its_device_list;
+	u64			flags;
+	unsigned long		list_nr;
+	u32			ite_size;
+	u32			device_ids;
+	int			numa_node;
+	unsigned int		msi_domain_flags;
+	u32			pre_its_base; /* for Socionext Synquacer */
+	bool			is_v4;
+	int			vlpi_redist_offset;
+};
+
+#define ITS_ITT_ALIGN		SZ_256
+
+/* The maximum number of VPEID bits supported by VLPI commands */
+#define ITS_MAX_VPEID_BITS	(16)
+#define ITS_MAX_VPEID		(1 << (ITS_MAX_VPEID_BITS))
+
+/* Convert page order to size in bytes */
+#define PAGE_ORDER_TO_SIZE(o)	(PAGE_SIZE << (o))
+
+struct event_lpi_map {
+	unsigned long		*lpi_map;
+	u16			*col_map;
+	irq_hw_number_t		lpi_base;
+	int			nr_lpis;
+	struct mutex		vlpi_lock;
+	struct its_vm		*vm;
+	struct its_vlpi_map	*vlpi_maps;
+	int			nr_vlpis;
+};
+
+/*
+ * The ITS view of a device - belongs to an ITS, owns an interrupt
+ * translation table, and a list of interrupts.  If it some of its
+ * LPIs are injected into a guest (GICv4), the event_map.vm field
+ * indicates which one.
+ */
+struct its_device {
+	struct list_head	entry;
+	struct its_node		*its;
+	struct event_lpi_map	event_map;
+	void			*itt;
+	u32			nr_ites;
+	u32			device_id;
+};
+
+static struct {
+	raw_spinlock_t		lock;
+	struct its_device	*dev;
+	struct its_vpe		**vpes;
+	int			next_victim;
+} vpe_proxy;
+
+static LIST_HEAD(its_nodes);
+static DEFINE_RAW_SPINLOCK(its_lock);
+static struct rdists *gic_rdists;
+static struct irq_domain *its_parent;
+
+static unsigned long its_list_map;
+static u16 vmovp_seq_num;
+static DEFINE_RAW_SPINLOCK(vmovp_lock);
+
+static DEFINE_IDA(its_vpeid_ida);
+
+#define gic_data_rdist()		(raw_cpu_ptr(gic_rdists->rdist))
+#define gic_data_rdist_rd_base()	(gic_data_rdist()->rd_base)
+#define gic_data_rdist_vlpi_base()	(gic_data_rdist_rd_base() + SZ_128K)
+
+static struct its_collection *dev_event_to_col(struct its_device *its_dev,
+					       u32 event)
+{
+	struct its_node *its = its_dev->its;
+
+	return its->collections + its_dev->event_map.col_map[event];
+}
+
+static struct its_collection *valid_col(struct its_collection *col)
+{
+	if (WARN_ON_ONCE(col->target_address & GENMASK_ULL(0, 15)))
+		return NULL;
+
+	return col;
+}
+
+static struct its_vpe *valid_vpe(struct its_node *its, struct its_vpe *vpe)
+{
+	if (valid_col(its->collections + vpe->col_idx))
+		return vpe;
+
+	return NULL;
+}
+
+/*
+ * ITS command descriptors - parameters to be encoded in a command
+ * block.
+ */
+struct its_cmd_desc {
+	union {
+		struct {
+			struct its_device *dev;
+			u32 event_id;
+		} its_inv_cmd;
+
+		struct {
+			struct its_device *dev;
+			u32 event_id;
+		} its_clear_cmd;
+
+		struct {
+			struct its_device *dev;
+			u32 event_id;
+		} its_int_cmd;
+
+		struct {
+			struct its_device *dev;
+			int valid;
+		} its_mapd_cmd;
+
+		struct {
+			struct its_collection *col;
+			int valid;
+		} its_mapc_cmd;
+
+		struct {
+			struct its_device *dev;
+			u32 phys_id;
+			u32 event_id;
+		} its_mapti_cmd;
+
+		struct {
+			struct its_device *dev;
+			struct its_collection *col;
+			u32 event_id;
+		} its_movi_cmd;
+
+		struct {
+			struct its_device *dev;
+			u32 event_id;
+		} its_discard_cmd;
+
+		struct {
+			struct its_collection *col;
+		} its_invall_cmd;
+
+		struct {
+			struct its_vpe *vpe;
+		} its_vinvall_cmd;
+
+		struct {
+			struct its_vpe *vpe;
+			struct its_collection *col;
+			bool valid;
+		} its_vmapp_cmd;
+
+		struct {
+			struct its_vpe *vpe;
+			struct its_device *dev;
+			u32 virt_id;
+			u32 event_id;
+			bool db_enabled;
+		} its_vmapti_cmd;
+
+		struct {
+			struct its_vpe *vpe;
+			struct its_device *dev;
+			u32 event_id;
+			bool db_enabled;
+		} its_vmovi_cmd;
+
+		struct {
+			struct its_vpe *vpe;
+			struct its_collection *col;
+			u16 seq_num;
+			u16 its_list;
+		} its_vmovp_cmd;
+	};
+};
+
+/*
+ * The ITS command block, which is what the ITS actually parses.
+ */
+struct its_cmd_block {
+	u64	raw_cmd[4];
+};
+
+#define ITS_CMD_QUEUE_SZ		SZ_64K
+#define ITS_CMD_QUEUE_NR_ENTRIES	(ITS_CMD_QUEUE_SZ / sizeof(struct its_cmd_block))
+
+typedef struct its_collection *(*its_cmd_builder_t)(struct its_node *,
+						    struct its_cmd_block *,
+						    struct its_cmd_desc *);
+
+typedef struct its_vpe *(*its_cmd_vbuilder_t)(struct its_node *,
+					      struct its_cmd_block *,
+					      struct its_cmd_desc *);
+
+static void its_mask_encode(u64 *raw_cmd, u64 val, int h, int l)
+{
+	u64 mask = GENMASK_ULL(h, l);
+	*raw_cmd &= ~mask;
+	*raw_cmd |= (val << l) & mask;
+}
+
+static void its_encode_cmd(struct its_cmd_block *cmd, u8 cmd_nr)
+{
+	its_mask_encode(&cmd->raw_cmd[0], cmd_nr, 7, 0);
+}
+
+static void its_encode_devid(struct its_cmd_block *cmd, u32 devid)
+{
+	its_mask_encode(&cmd->raw_cmd[0], devid, 63, 32);
+}
+
+static void its_encode_event_id(struct its_cmd_block *cmd, u32 id)
+{
+	its_mask_encode(&cmd->raw_cmd[1], id, 31, 0);
+}
+
+static void its_encode_phys_id(struct its_cmd_block *cmd, u32 phys_id)
+{
+	its_mask_encode(&cmd->raw_cmd[1], phys_id, 63, 32);
+}
+
+static void its_encode_size(struct its_cmd_block *cmd, u8 size)
+{
+	its_mask_encode(&cmd->raw_cmd[1], size, 4, 0);
+}
+
+static void its_encode_itt(struct its_cmd_block *cmd, u64 itt_addr)
+{
+	its_mask_encode(&cmd->raw_cmd[2], itt_addr >> 8, 51, 8);
+}
+
+static void its_encode_valid(struct its_cmd_block *cmd, int valid)
+{
+	its_mask_encode(&cmd->raw_cmd[2], !!valid, 63, 63);
+}
+
+static void its_encode_target(struct its_cmd_block *cmd, u64 target_addr)
+{
+	its_mask_encode(&cmd->raw_cmd[2], target_addr >> 16, 51, 16);
+}
+
+static void its_encode_collection(struct its_cmd_block *cmd, u16 col)
+{
+	its_mask_encode(&cmd->raw_cmd[2], col, 15, 0);
+}
+
+static void its_encode_vpeid(struct its_cmd_block *cmd, u16 vpeid)
+{
+	its_mask_encode(&cmd->raw_cmd[1], vpeid, 47, 32);
+}
+
+static void its_encode_virt_id(struct its_cmd_block *cmd, u32 virt_id)
+{
+	its_mask_encode(&cmd->raw_cmd[2], virt_id, 31, 0);
+}
+
+static void its_encode_db_phys_id(struct its_cmd_block *cmd, u32 db_phys_id)
+{
+	its_mask_encode(&cmd->raw_cmd[2], db_phys_id, 63, 32);
+}
+
+static void its_encode_db_valid(struct its_cmd_block *cmd, bool db_valid)
+{
+	its_mask_encode(&cmd->raw_cmd[2], db_valid, 0, 0);
+}
+
+static void its_encode_seq_num(struct its_cmd_block *cmd, u16 seq_num)
+{
+	its_mask_encode(&cmd->raw_cmd[0], seq_num, 47, 32);
+}
+
+static void its_encode_its_list(struct its_cmd_block *cmd, u16 its_list)
+{
+	its_mask_encode(&cmd->raw_cmd[1], its_list, 15, 0);
+}
+
+static void its_encode_vpt_addr(struct its_cmd_block *cmd, u64 vpt_pa)
+{
+	its_mask_encode(&cmd->raw_cmd[3], vpt_pa >> 16, 51, 16);
+}
+
+static void its_encode_vpt_size(struct its_cmd_block *cmd, u8 vpt_size)
+{
+	its_mask_encode(&cmd->raw_cmd[3], vpt_size, 4, 0);
+}
+
+static inline void its_fixup_cmd(struct its_cmd_block *cmd)
+{
+	/* Let's fixup BE commands */
+	cmd->raw_cmd[0] = cpu_to_le64(cmd->raw_cmd[0]);
+	cmd->raw_cmd[1] = cpu_to_le64(cmd->raw_cmd[1]);
+	cmd->raw_cmd[2] = cpu_to_le64(cmd->raw_cmd[2]);
+	cmd->raw_cmd[3] = cpu_to_le64(cmd->raw_cmd[3]);
+}
+
+static struct its_collection *its_build_mapd_cmd(struct its_node *its,
+						 struct its_cmd_block *cmd,
+						 struct its_cmd_desc *desc)
+{
+	unsigned long itt_addr;
+	u8 size = ilog2(desc->its_mapd_cmd.dev->nr_ites);
+
+	itt_addr = virt_to_phys(desc->its_mapd_cmd.dev->itt);
+	itt_addr = ALIGN(itt_addr, ITS_ITT_ALIGN);
+
+	its_encode_cmd(cmd, GITS_CMD_MAPD);
+	its_encode_devid(cmd, desc->its_mapd_cmd.dev->device_id);
+	its_encode_size(cmd, size - 1);
+	its_encode_itt(cmd, itt_addr);
+	its_encode_valid(cmd, desc->its_mapd_cmd.valid);
+
+	its_fixup_cmd(cmd);
+
+	return NULL;
+}
+
+static struct its_collection *its_build_mapc_cmd(struct its_node *its,
+						 struct its_cmd_block *cmd,
+						 struct its_cmd_desc *desc)
+{
+	its_encode_cmd(cmd, GITS_CMD_MAPC);
+	its_encode_collection(cmd, desc->its_mapc_cmd.col->col_id);
+	its_encode_target(cmd, desc->its_mapc_cmd.col->target_address);
+	its_encode_valid(cmd, desc->its_mapc_cmd.valid);
+
+	its_fixup_cmd(cmd);
+
+	return desc->its_mapc_cmd.col;
+}
+
+static struct its_collection *its_build_mapti_cmd(struct its_node *its,
+						  struct its_cmd_block *cmd,
+						  struct its_cmd_desc *desc)
+{
+	struct its_collection *col;
+
+	col = dev_event_to_col(desc->its_mapti_cmd.dev,
+			       desc->its_mapti_cmd.event_id);
+
+	its_encode_cmd(cmd, GITS_CMD_MAPTI);
+	its_encode_devid(cmd, desc->its_mapti_cmd.dev->device_id);
+	its_encode_event_id(cmd, desc->its_mapti_cmd.event_id);
+	its_encode_phys_id(cmd, desc->its_mapti_cmd.phys_id);
+	its_encode_collection(cmd, col->col_id);
+
+	its_fixup_cmd(cmd);
+
+	return valid_col(col);
+}
+
+static struct its_collection *its_build_movi_cmd(struct its_node *its,
+						 struct its_cmd_block *cmd,
+						 struct its_cmd_desc *desc)
+{
+	struct its_collection *col;
+
+	col = dev_event_to_col(desc->its_movi_cmd.dev,
+			       desc->its_movi_cmd.event_id);
+
+	its_encode_cmd(cmd, GITS_CMD_MOVI);
+	its_encode_devid(cmd, desc->its_movi_cmd.dev->device_id);
+	its_encode_event_id(cmd, desc->its_movi_cmd.event_id);
+	its_encode_collection(cmd, desc->its_movi_cmd.col->col_id);
+
+	its_fixup_cmd(cmd);
+
+	return valid_col(col);
+}
+
+static struct its_collection *its_build_discard_cmd(struct its_node *its,
+						    struct its_cmd_block *cmd,
+						    struct its_cmd_desc *desc)
+{
+	struct its_collection *col;
+
+	col = dev_event_to_col(desc->its_discard_cmd.dev,
+			       desc->its_discard_cmd.event_id);
+
+	its_encode_cmd(cmd, GITS_CMD_DISCARD);
+	its_encode_devid(cmd, desc->its_discard_cmd.dev->device_id);
+	its_encode_event_id(cmd, desc->its_discard_cmd.event_id);
+
+	its_fixup_cmd(cmd);
+
+	return valid_col(col);
+}
+
+static struct its_collection *its_build_inv_cmd(struct its_node *its,
+						struct its_cmd_block *cmd,
+						struct its_cmd_desc *desc)
+{
+	struct its_collection *col;
+
+	col = dev_event_to_col(desc->its_inv_cmd.dev,
+			       desc->its_inv_cmd.event_id);
+
+	its_encode_cmd(cmd, GITS_CMD_INV);
+	its_encode_devid(cmd, desc->its_inv_cmd.dev->device_id);
+	its_encode_event_id(cmd, desc->its_inv_cmd.event_id);
+
+	its_fixup_cmd(cmd);
+
+	return valid_col(col);
+}
+
+static struct its_collection *its_build_int_cmd(struct its_node *its,
+						struct its_cmd_block *cmd,
+						struct its_cmd_desc *desc)
+{
+	struct its_collection *col;
+
+	col = dev_event_to_col(desc->its_int_cmd.dev,
+			       desc->its_int_cmd.event_id);
+
+	its_encode_cmd(cmd, GITS_CMD_INT);
+	its_encode_devid(cmd, desc->its_int_cmd.dev->device_id);
+	its_encode_event_id(cmd, desc->its_int_cmd.event_id);
+
+	its_fixup_cmd(cmd);
+
+	return valid_col(col);
+}
+
+static struct its_collection *its_build_clear_cmd(struct its_node *its,
+						  struct its_cmd_block *cmd,
+						  struct its_cmd_desc *desc)
+{
+	struct its_collection *col;
+
+	col = dev_event_to_col(desc->its_clear_cmd.dev,
+			       desc->its_clear_cmd.event_id);
+
+	its_encode_cmd(cmd, GITS_CMD_CLEAR);
+	its_encode_devid(cmd, desc->its_clear_cmd.dev->device_id);
+	its_encode_event_id(cmd, desc->its_clear_cmd.event_id);
+
+	its_fixup_cmd(cmd);
+
+	return valid_col(col);
+}
+
+static struct its_collection *its_build_invall_cmd(struct its_node *its,
+						   struct its_cmd_block *cmd,
+						   struct its_cmd_desc *desc)
+{
+	its_encode_cmd(cmd, GITS_CMD_INVALL);
+	its_encode_collection(cmd, desc->its_mapc_cmd.col->col_id);
+
+	its_fixup_cmd(cmd);
+
+	return NULL;
+}
+
+static struct its_vpe *its_build_vinvall_cmd(struct its_node *its,
+					     struct its_cmd_block *cmd,
+					     struct its_cmd_desc *desc)
+{
+	its_encode_cmd(cmd, GITS_CMD_VINVALL);
+	its_encode_vpeid(cmd, desc->its_vinvall_cmd.vpe->vpe_id);
+
+	its_fixup_cmd(cmd);
+
+	return valid_vpe(its, desc->its_vinvall_cmd.vpe);
+}
+
+static struct its_vpe *its_build_vmapp_cmd(struct its_node *its,
+					   struct its_cmd_block *cmd,
+					   struct its_cmd_desc *desc)
+{
+	unsigned long vpt_addr;
+	u64 target;
+
+	vpt_addr = virt_to_phys(page_address(desc->its_vmapp_cmd.vpe->vpt_page));
+	target = desc->its_vmapp_cmd.col->target_address + its->vlpi_redist_offset;
+
+	its_encode_cmd(cmd, GITS_CMD_VMAPP);
+	its_encode_vpeid(cmd, desc->its_vmapp_cmd.vpe->vpe_id);
+	its_encode_valid(cmd, desc->its_vmapp_cmd.valid);
+	its_encode_target(cmd, target);
+	its_encode_vpt_addr(cmd, vpt_addr);
+	its_encode_vpt_size(cmd, LPI_NRBITS - 1);
+
+	its_fixup_cmd(cmd);
+
+	return valid_vpe(its, desc->its_vmapp_cmd.vpe);
+}
+
+static struct its_vpe *its_build_vmapti_cmd(struct its_node *its,
+					    struct its_cmd_block *cmd,
+					    struct its_cmd_desc *desc)
+{
+	u32 db;
+
+	if (desc->its_vmapti_cmd.db_enabled)
+		db = desc->its_vmapti_cmd.vpe->vpe_db_lpi;
+	else
+		db = 1023;
+
+	its_encode_cmd(cmd, GITS_CMD_VMAPTI);
+	its_encode_devid(cmd, desc->its_vmapti_cmd.dev->device_id);
+	its_encode_vpeid(cmd, desc->its_vmapti_cmd.vpe->vpe_id);
+	its_encode_event_id(cmd, desc->its_vmapti_cmd.event_id);
+	its_encode_db_phys_id(cmd, db);
+	its_encode_virt_id(cmd, desc->its_vmapti_cmd.virt_id);
+
+	its_fixup_cmd(cmd);
+
+	return valid_vpe(its, desc->its_vmapti_cmd.vpe);
+}
+
+static struct its_vpe *its_build_vmovi_cmd(struct its_node *its,
+					   struct its_cmd_block *cmd,
+					   struct its_cmd_desc *desc)
+{
+	u32 db;
+
+	if (desc->its_vmovi_cmd.db_enabled)
+		db = desc->its_vmovi_cmd.vpe->vpe_db_lpi;
+	else
+		db = 1023;
+
+	its_encode_cmd(cmd, GITS_CMD_VMOVI);
+	its_encode_devid(cmd, desc->its_vmovi_cmd.dev->device_id);
+	its_encode_vpeid(cmd, desc->its_vmovi_cmd.vpe->vpe_id);
+	its_encode_event_id(cmd, desc->its_vmovi_cmd.event_id);
+	its_encode_db_phys_id(cmd, db);
+	its_encode_db_valid(cmd, true);
+
+	its_fixup_cmd(cmd);
+
+	return valid_vpe(its, desc->its_vmovi_cmd.vpe);
+}
+
+static struct its_vpe *its_build_vmovp_cmd(struct its_node *its,
+					   struct its_cmd_block *cmd,
+					   struct its_cmd_desc *desc)
+{
+	u64 target;
+
+	target = desc->its_vmovp_cmd.col->target_address + its->vlpi_redist_offset;
+	its_encode_cmd(cmd, GITS_CMD_VMOVP);
+	its_encode_seq_num(cmd, desc->its_vmovp_cmd.seq_num);
+	its_encode_its_list(cmd, desc->its_vmovp_cmd.its_list);
+	its_encode_vpeid(cmd, desc->its_vmovp_cmd.vpe->vpe_id);
+	its_encode_target(cmd, target);
+
+	its_fixup_cmd(cmd);
+
+	return valid_vpe(its, desc->its_vmovp_cmd.vpe);
+}
+
+static u64 its_cmd_ptr_to_offset(struct its_node *its,
+				 struct its_cmd_block *ptr)
+{
+	return (ptr - its->cmd_base) * sizeof(*ptr);
+}
+
+static int its_queue_full(struct its_node *its)
+{
+	int widx;
+	int ridx;
+
+	widx = its->cmd_write - its->cmd_base;
+	ridx = readl_relaxed(its->base + GITS_CREADR) / sizeof(struct its_cmd_block);
+
+	/* This is incredibly unlikely to happen, unless the ITS locks up. */
+	if (((widx + 1) % ITS_CMD_QUEUE_NR_ENTRIES) == ridx)
+		return 1;
+
+	return 0;
+}
+
+static struct its_cmd_block *its_allocate_entry(struct its_node *its)
+{
+	struct its_cmd_block *cmd;
+	u32 count = 1000000;	/* 1s! */
+
+	while (its_queue_full(its)) {
+		count--;
+		if (!count) {
+			pr_err_ratelimited("ITS queue not draining\n");
+			return NULL;
+		}
+		cpu_relax();
+		udelay(1);
+	}
+
+	cmd = its->cmd_write++;
+
+	/* Handle queue wrapping */
+	if (its->cmd_write == (its->cmd_base + ITS_CMD_QUEUE_NR_ENTRIES))
+		its->cmd_write = its->cmd_base;
+
+	/* Clear command  */
+	cmd->raw_cmd[0] = 0;
+	cmd->raw_cmd[1] = 0;
+	cmd->raw_cmd[2] = 0;
+	cmd->raw_cmd[3] = 0;
+
+	return cmd;
+}
+
+static struct its_cmd_block *its_post_commands(struct its_node *its)
+{
+	u64 wr = its_cmd_ptr_to_offset(its, its->cmd_write);
+
+	writel_relaxed(wr, its->base + GITS_CWRITER);
+
+	return its->cmd_write;
+}
+
+static void its_flush_cmd(struct its_node *its, struct its_cmd_block *cmd)
+{
+	/*
+	 * Make sure the commands written to memory are observable by
+	 * the ITS.
+	 */
+	if (its->flags & ITS_FLAGS_CMDQ_NEEDS_FLUSHING)
+		gic_flush_dcache_to_poc(cmd, sizeof(*cmd));
+	else
+		dsb(ishst);
+}
+
+static int its_wait_for_range_completion(struct its_node *its,
+					 struct its_cmd_block *from,
+					 struct its_cmd_block *to)
+{
+	u64 rd_idx, from_idx, to_idx;
+	u32 count = 1000000;	/* 1s! */
+
+	from_idx = its_cmd_ptr_to_offset(its, from);
+	to_idx = its_cmd_ptr_to_offset(its, to);
+
+	while (1) {
+		rd_idx = readl_relaxed(its->base + GITS_CREADR);
+
+		/* Direct case */
+		if (from_idx < to_idx && rd_idx >= to_idx)
+			break;
+
+		/* Wrapped case */
+		if (from_idx >= to_idx && rd_idx >= to_idx && rd_idx < from_idx)
+			break;
+
+		count--;
+		if (!count) {
+			pr_err_ratelimited("ITS queue timeout (%llu %llu %llu)\n",
+					   from_idx, to_idx, rd_idx);
+			return -1;
+		}
+		cpu_relax();
+		udelay(1);
+	}
+
+	return 0;
+}
+
+/* Warning, macro hell follows */
+#define BUILD_SINGLE_CMD_FUNC(name, buildtype, synctype, buildfn)	\
+void name(struct its_node *its,						\
+	  buildtype builder,						\
+	  struct its_cmd_desc *desc)					\
+{									\
+	struct its_cmd_block *cmd, *sync_cmd, *next_cmd;		\
+	synctype *sync_obj;						\
+	unsigned long flags;						\
+									\
+	raw_spin_lock_irqsave(&its->lock, flags);			\
+									\
+	cmd = its_allocate_entry(its);					\
+	if (!cmd) {		/* We're soooooo screewed... */		\
+		raw_spin_unlock_irqrestore(&its->lock, flags);		\
+		return;							\
+	}								\
+	sync_obj = builder(its, cmd, desc);				\
+	its_flush_cmd(its, cmd);					\
+									\
+	if (sync_obj) {							\
+		sync_cmd = its_allocate_entry(its);			\
+		if (!sync_cmd)						\
+			goto post;					\
+									\
+		buildfn(its, sync_cmd, sync_obj);			\
+		its_flush_cmd(its, sync_cmd);				\
+	}								\
+									\
+post:									\
+	next_cmd = its_post_commands(its);				\
+	raw_spin_unlock_irqrestore(&its->lock, flags);			\
+									\
+	if (its_wait_for_range_completion(its, cmd, next_cmd))		\
+		pr_err_ratelimited("ITS cmd %ps failed\n", builder);	\
+}
+
+static void its_build_sync_cmd(struct its_node *its,
+			       struct its_cmd_block *sync_cmd,
+			       struct its_collection *sync_col)
+{
+	its_encode_cmd(sync_cmd, GITS_CMD_SYNC);
+	its_encode_target(sync_cmd, sync_col->target_address);
+
+	its_fixup_cmd(sync_cmd);
+}
+
+static BUILD_SINGLE_CMD_FUNC(its_send_single_command, its_cmd_builder_t,
+			     struct its_collection, its_build_sync_cmd)
+
+static void its_build_vsync_cmd(struct its_node *its,
+				struct its_cmd_block *sync_cmd,
+				struct its_vpe *sync_vpe)
+{
+	its_encode_cmd(sync_cmd, GITS_CMD_VSYNC);
+	its_encode_vpeid(sync_cmd, sync_vpe->vpe_id);
+
+	its_fixup_cmd(sync_cmd);
+}
+
+static BUILD_SINGLE_CMD_FUNC(its_send_single_vcommand, its_cmd_vbuilder_t,
+			     struct its_vpe, its_build_vsync_cmd)
+
+static void its_send_int(struct its_device *dev, u32 event_id)
+{
+	struct its_cmd_desc desc;
+
+	desc.its_int_cmd.dev = dev;
+	desc.its_int_cmd.event_id = event_id;
+
+	its_send_single_command(dev->its, its_build_int_cmd, &desc);
+}
+
+static void its_send_clear(struct its_device *dev, u32 event_id)
+{
+	struct its_cmd_desc desc;
+
+	desc.its_clear_cmd.dev = dev;
+	desc.its_clear_cmd.event_id = event_id;
+
+	its_send_single_command(dev->its, its_build_clear_cmd, &desc);
+}
+
+static void its_send_inv(struct its_device *dev, u32 event_id)
+{
+	struct its_cmd_desc desc;
+
+	desc.its_inv_cmd.dev = dev;
+	desc.its_inv_cmd.event_id = event_id;
+
+	its_send_single_command(dev->its, its_build_inv_cmd, &desc);
+}
+
+static void its_send_mapd(struct its_device *dev, int valid)
+{
+	struct its_cmd_desc desc;
+
+	desc.its_mapd_cmd.dev = dev;
+	desc.its_mapd_cmd.valid = !!valid;
+
+	its_send_single_command(dev->its, its_build_mapd_cmd, &desc);
+}
+
+static void its_send_mapc(struct its_node *its, struct its_collection *col,
+			  int valid)
+{
+	struct its_cmd_desc desc;
+
+	desc.its_mapc_cmd.col = col;
+	desc.its_mapc_cmd.valid = !!valid;
+
+	its_send_single_command(its, its_build_mapc_cmd, &desc);
+}
+
+static void its_send_mapti(struct its_device *dev, u32 irq_id, u32 id)
+{
+	struct its_cmd_desc desc;
+
+	desc.its_mapti_cmd.dev = dev;
+	desc.its_mapti_cmd.phys_id = irq_id;
+	desc.its_mapti_cmd.event_id = id;
+
+	its_send_single_command(dev->its, its_build_mapti_cmd, &desc);
+}
+
+static void its_send_movi(struct its_device *dev,
+			  struct its_collection *col, u32 id)
+{
+	struct its_cmd_desc desc;
+
+	desc.its_movi_cmd.dev = dev;
+	desc.its_movi_cmd.col = col;
+	desc.its_movi_cmd.event_id = id;
+
+	its_send_single_command(dev->its, its_build_movi_cmd, &desc);
+}
+
+static void its_send_discard(struct its_device *dev, u32 id)
+{
+	struct its_cmd_desc desc;
+
+	desc.its_discard_cmd.dev = dev;
+	desc.its_discard_cmd.event_id = id;
+
+	its_send_single_command(dev->its, its_build_discard_cmd, &desc);
+}
+
+static void its_send_invall(struct its_node *its, struct its_collection *col)
+{
+	struct its_cmd_desc desc;
+
+	desc.its_invall_cmd.col = col;
+
+	its_send_single_command(its, its_build_invall_cmd, &desc);
+}
+
+static void its_send_vmapti(struct its_device *dev, u32 id)
+{
+	struct its_vlpi_map *map = &dev->event_map.vlpi_maps[id];
+	struct its_cmd_desc desc;
+
+	desc.its_vmapti_cmd.vpe = map->vpe;
+	desc.its_vmapti_cmd.dev = dev;
+	desc.its_vmapti_cmd.virt_id = map->vintid;
+	desc.its_vmapti_cmd.event_id = id;
+	desc.its_vmapti_cmd.db_enabled = map->db_enabled;
+
+	its_send_single_vcommand(dev->its, its_build_vmapti_cmd, &desc);
+}
+
+static void its_send_vmovi(struct its_device *dev, u32 id)
+{
+	struct its_vlpi_map *map = &dev->event_map.vlpi_maps[id];
+	struct its_cmd_desc desc;
+
+	desc.its_vmovi_cmd.vpe = map->vpe;
+	desc.its_vmovi_cmd.dev = dev;
+	desc.its_vmovi_cmd.event_id = id;
+	desc.its_vmovi_cmd.db_enabled = map->db_enabled;
+
+	its_send_single_vcommand(dev->its, its_build_vmovi_cmd, &desc);
+}
+
+static void its_send_vmapp(struct its_node *its,
+			   struct its_vpe *vpe, bool valid)
+{
+	struct its_cmd_desc desc;
+
+	desc.its_vmapp_cmd.vpe = vpe;
+	desc.its_vmapp_cmd.valid = valid;
+	desc.its_vmapp_cmd.col = &its->collections[vpe->col_idx];
+
+	its_send_single_vcommand(its, its_build_vmapp_cmd, &desc);
+}
+
+static void its_send_vmovp(struct its_vpe *vpe)
+{
+	struct its_cmd_desc desc;
+	struct its_node *its;
+	unsigned long flags;
+	int col_id = vpe->col_idx;
+
+	desc.its_vmovp_cmd.vpe = vpe;
+	desc.its_vmovp_cmd.its_list = (u16)its_list_map;
+
+	if (!its_list_map) {
+		its = list_first_entry(&its_nodes, struct its_node, entry);
+		desc.its_vmovp_cmd.seq_num = 0;
+		desc.its_vmovp_cmd.col = &its->collections[col_id];
+		its_send_single_vcommand(its, its_build_vmovp_cmd, &desc);
+		return;
+	}
+
+	/*
+	 * Yet another marvel of the architecture. If using the
+	 * its_list "feature", we need to make sure that all ITSs
+	 * receive all VMOVP commands in the same order. The only way
+	 * to guarantee this is to make vmovp a serialization point.
+	 *
+	 * Wall <-- Head.
+	 */
+	raw_spin_lock_irqsave(&vmovp_lock, flags);
+
+	desc.its_vmovp_cmd.seq_num = vmovp_seq_num++;
+
+	/* Emit VMOVPs */
+	list_for_each_entry(its, &its_nodes, entry) {
+		if (!its->is_v4)
+			continue;
+
+		if (!vpe->its_vm->vlpi_count[its->list_nr])
+			continue;
+
+		desc.its_vmovp_cmd.col = &its->collections[col_id];
+		its_send_single_vcommand(its, its_build_vmovp_cmd, &desc);
+	}
+
+	raw_spin_unlock_irqrestore(&vmovp_lock, flags);
+}
+
+static void its_send_vinvall(struct its_node *its, struct its_vpe *vpe)
+{
+	struct its_cmd_desc desc;
+
+	desc.its_vinvall_cmd.vpe = vpe;
+	its_send_single_vcommand(its, its_build_vinvall_cmd, &desc);
+}
+
+/*
+ * irqchip functions - assumes MSI, mostly.
+ */
+
+static inline u32 its_get_event_id(struct irq_data *d)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	return d->hwirq - its_dev->event_map.lpi_base;
+}
+
+static void lpi_write_config(struct irq_data *d, u8 clr, u8 set)
+{
+	irq_hw_number_t hwirq;
+	struct page *prop_page;
+	u8 *cfg;
+
+	if (irqd_is_forwarded_to_vcpu(d)) {
+		struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+		u32 event = its_get_event_id(d);
+		struct its_vlpi_map *map;
+
+		prop_page = its_dev->event_map.vm->vprop_page;
+		map = &its_dev->event_map.vlpi_maps[event];
+		hwirq = map->vintid;
+
+		/* Remember the updated property */
+		map->properties &= ~clr;
+		map->properties |= set | LPI_PROP_GROUP1;
+	} else {
+		prop_page = gic_rdists->prop_page;
+		hwirq = d->hwirq;
+	}
+
+	cfg = page_address(prop_page) + hwirq - 8192;
+	*cfg &= ~clr;
+	*cfg |= set | LPI_PROP_GROUP1;
+
+	/*
+	 * Make the above write visible to the redistributors.
+	 * And yes, we're flushing exactly: One. Single. Byte.
+	 * Humpf...
+	 */
+	if (gic_rdists->flags & RDIST_FLAGS_PROPBASE_NEEDS_FLUSHING)
+		gic_flush_dcache_to_poc(cfg, sizeof(*cfg));
+	else
+		dsb(ishst);
+}
+
+static void lpi_update_config(struct irq_data *d, u8 clr, u8 set)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+
+	lpi_write_config(d, clr, set);
+	its_send_inv(its_dev, its_get_event_id(d));
+}
+
+static void its_vlpi_set_doorbell(struct irq_data *d, bool enable)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	u32 event = its_get_event_id(d);
+
+	if (its_dev->event_map.vlpi_maps[event].db_enabled == enable)
+		return;
+
+	its_dev->event_map.vlpi_maps[event].db_enabled = enable;
+
+	/*
+	 * More fun with the architecture:
+	 *
+	 * Ideally, we'd issue a VMAPTI to set the doorbell to its LPI
+	 * value or to 1023, depending on the enable bit. But that
+	 * would be issueing a mapping for an /existing/ DevID+EventID
+	 * pair, which is UNPREDICTABLE. Instead, let's issue a VMOVI
+	 * to the /same/ vPE, using this opportunity to adjust the
+	 * doorbell. Mouahahahaha. We loves it, Precious.
+	 */
+	its_send_vmovi(its_dev, event);
+}
+
+static void its_mask_irq(struct irq_data *d)
+{
+	if (irqd_is_forwarded_to_vcpu(d))
+		its_vlpi_set_doorbell(d, false);
+
+	lpi_update_config(d, LPI_PROP_ENABLED, 0);
+}
+
+static void its_unmask_irq(struct irq_data *d)
+{
+	if (irqd_is_forwarded_to_vcpu(d))
+		its_vlpi_set_doorbell(d, true);
+
+	lpi_update_config(d, 0, LPI_PROP_ENABLED);
+}
+
+#define MAX_MARS3_SKT_COUNT	8
+
+static int its_cpumask_select(struct its_device *its_dev,
+			      const struct cpumask *mask_val,
+			      const struct cpumask *cpu_mask)
+{
+	unsigned int skt, skt_id, i;
+	phys_addr_t its_phys_base;
+	unsigned int cpu, cpus = 0;
+
+	unsigned int skt_cpu_cnt[MAX_MARS3_SKT_COUNT] = {0};
+
+	for (i = 0; i < nr_cpu_ids; i++) {
+		skt = (cpu_logical_map(i) >> 16) & 0xff;
+		if ((skt >= 0) && (skt < MAX_MARS3_SKT_COUNT))
+			skt_cpu_cnt[skt]++;
+		else if (skt != 0xff)
+			pr_err("socket address: %d is out of range.", skt);
+	}
+
+	its_phys_base = its_dev->its->phys_base;
+	skt_id = (its_phys_base >> 41) & 0x7;
+
+	if (0 != skt_id) {
+		for (i = 0; i < skt_id; i++)
+			cpus += skt_cpu_cnt[i];
+	}
+
+	cpu = cpumask_any_and(mask_val, cpu_mask);
+	if ((cpu > cpus) && (cpu < (cpus + skt_cpu_cnt[skt_id])))
+		cpus = cpu;
+
+	return cpus;
+}
+
+static int its_set_affinity(struct irq_data *d, const struct cpumask *mask_val,
+			    bool force)
+{
+	unsigned int cpu;
+	const struct cpumask *cpu_mask = cpu_online_mask;
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	struct its_collection *target_col;
+	u32 id = its_get_event_id(d);
+
+	/* A forwarded interrupt should use irq_set_vcpu_affinity */
+	if (irqd_is_forwarded_to_vcpu(d))
+		return -EINVAL;
+
+       /* lpi cannot be routed to a redistributor that is on a foreign node */
+	if (its_dev->its->flags & ITS_FLAGS_WORKAROUND_CAVIUM_23144) {
+		if (its_dev->its->numa_node >= 0) {
+			cpu_mask = cpumask_of_node(its_dev->its->numa_node);
+			if (!cpumask_intersects(mask_val, cpu_mask))
+				return -EINVAL;
+		}
+	}
+
+	cpu = its_cpumask_select(its_dev, mask_val, cpu_mask);
+
+	if (cpu >= nr_cpu_ids)
+		return -EINVAL;
+
+	/* don't set the affinity when the target cpu is same as current one */
+	if (cpu != its_dev->event_map.col_map[id]) {
+		target_col = &its_dev->its->collections[cpu];
+		its_send_movi(its_dev, target_col, id);
+		its_dev->event_map.col_map[id] = cpu;
+		irq_data_update_effective_affinity(d, cpumask_of(cpu));
+	}
+
+	return IRQ_SET_MASK_OK_DONE;
+}
+
+static u64 its_irq_get_msi_base(struct its_device *its_dev)
+{
+	struct its_node *its = its_dev->its;
+
+	return its->phys_base + GITS_TRANSLATER;
+}
+
+static void its_irq_compose_msi_msg(struct irq_data *d, struct msi_msg *msg)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	struct its_node *its;
+	u64 addr;
+
+	its = its_dev->its;
+	addr = its->get_msi_base(its_dev);
+
+	msg->address_lo		= lower_32_bits(addr);
+	msg->address_hi		= upper_32_bits(addr);
+	msg->data		= its_get_event_id(d);
+}
+
+static int its_irq_set_irqchip_state(struct irq_data *d,
+				     enum irqchip_irq_state which,
+				     bool state)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	u32 event = its_get_event_id(d);
+
+	if (which != IRQCHIP_STATE_PENDING)
+		return -EINVAL;
+
+	if (state)
+		its_send_int(its_dev, event);
+	else
+		its_send_clear(its_dev, event);
+
+	return 0;
+}
+
+static void its_map_vm(struct its_node *its, struct its_vm *vm)
+{
+	unsigned long flags;
+
+	/* Not using the ITS list? Everything is always mapped. */
+	if (!its_list_map)
+		return;
+
+	raw_spin_lock_irqsave(&vmovp_lock, flags);
+
+	/*
+	 * If the VM wasn't mapped yet, iterate over the vpes and get
+	 * them mapped now.
+	 */
+	vm->vlpi_count[its->list_nr]++;
+
+	if (vm->vlpi_count[its->list_nr] == 1) {
+		int i;
+
+		for (i = 0; i < vm->nr_vpes; i++) {
+			struct its_vpe *vpe = vm->vpes[i];
+			struct irq_data *d = irq_get_irq_data(vpe->irq);
+
+			/* Map the VPE to the first possible CPU */
+			vpe->col_idx = cpumask_first(cpu_online_mask);
+			its_send_vmapp(its, vpe, true);
+			its_send_vinvall(its, vpe);
+			irq_data_update_effective_affinity(d, cpumask_of(vpe->col_idx));
+		}
+	}
+
+	raw_spin_unlock_irqrestore(&vmovp_lock, flags);
+}
+
+static void its_unmap_vm(struct its_node *its, struct its_vm *vm)
+{
+	unsigned long flags;
+
+	/* Not using the ITS list? Everything is always mapped. */
+	if (!its_list_map)
+		return;
+
+	raw_spin_lock_irqsave(&vmovp_lock, flags);
+
+	if (!--vm->vlpi_count[its->list_nr]) {
+		int i;
+
+		for (i = 0; i < vm->nr_vpes; i++)
+			its_send_vmapp(its, vm->vpes[i], false);
+	}
+
+	raw_spin_unlock_irqrestore(&vmovp_lock, flags);
+}
+
+static int its_vlpi_map(struct irq_data *d, struct its_cmd_info *info)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	u32 event = its_get_event_id(d);
+	int ret = 0;
+
+	if (!info->map)
+		return -EINVAL;
+
+	mutex_lock(&its_dev->event_map.vlpi_lock);
+
+	if (!its_dev->event_map.vm) {
+		struct its_vlpi_map *maps;
+
+		maps = kcalloc(its_dev->event_map.nr_lpis, sizeof(*maps),
+			       GFP_KERNEL);
+		if (!maps) {
+			ret = -ENOMEM;
+			goto out;
+		}
+
+		its_dev->event_map.vm = info->map->vm;
+		its_dev->event_map.vlpi_maps = maps;
+	} else if (its_dev->event_map.vm != info->map->vm) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	/* Get our private copy of the mapping information */
+	its_dev->event_map.vlpi_maps[event] = *info->map;
+
+	if (irqd_is_forwarded_to_vcpu(d)) {
+		/* Already mapped, move it around */
+		its_send_vmovi(its_dev, event);
+	} else {
+		/* Ensure all the VPEs are mapped on this ITS */
+		its_map_vm(its_dev->its, info->map->vm);
+
+		/*
+		 * Flag the interrupt as forwarded so that we can
+		 * start poking the virtual property table.
+		 */
+		irqd_set_forwarded_to_vcpu(d);
+
+		/* Write out the property to the prop table */
+		lpi_write_config(d, 0xff, info->map->properties);
+
+		/* Drop the physical mapping */
+		its_send_discard(its_dev, event);
+
+		/* and install the virtual one */
+		its_send_vmapti(its_dev, event);
+
+		/* Increment the number of VLPIs */
+		its_dev->event_map.nr_vlpis++;
+	}
+
+out:
+	mutex_unlock(&its_dev->event_map.vlpi_lock);
+	return ret;
+}
+
+static int its_vlpi_get(struct irq_data *d, struct its_cmd_info *info)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	u32 event = its_get_event_id(d);
+	int ret = 0;
+
+	mutex_lock(&its_dev->event_map.vlpi_lock);
+
+	if (!its_dev->event_map.vm ||
+	    !its_dev->event_map.vlpi_maps[event].vm) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	/* Copy our mapping information to the incoming request */
+	*info->map = its_dev->event_map.vlpi_maps[event];
+
+out:
+	mutex_unlock(&its_dev->event_map.vlpi_lock);
+	return ret;
+}
+
+static int its_vlpi_unmap(struct irq_data *d)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	u32 event = its_get_event_id(d);
+	int ret = 0;
+
+	mutex_lock(&its_dev->event_map.vlpi_lock);
+
+	if (!its_dev->event_map.vm || !irqd_is_forwarded_to_vcpu(d)) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	/* Drop the virtual mapping */
+	its_send_discard(its_dev, event);
+
+	/* and restore the physical one */
+	irqd_clr_forwarded_to_vcpu(d);
+	its_send_mapti(its_dev, d->hwirq, event);
+	lpi_update_config(d, 0xff, (LPI_PROP_DEFAULT_PRIO |
+				    LPI_PROP_ENABLED |
+				    LPI_PROP_GROUP1));
+
+	/* Potentially unmap the VM from this ITS */
+	its_unmap_vm(its_dev->its, its_dev->event_map.vm);
+
+	/*
+	 * Drop the refcount and make the device available again if
+	 * this was the last VLPI.
+	 */
+	if (!--its_dev->event_map.nr_vlpis) {
+		its_dev->event_map.vm = NULL;
+		kfree(its_dev->event_map.vlpi_maps);
+	}
+
+out:
+	mutex_unlock(&its_dev->event_map.vlpi_lock);
+	return ret;
+}
+
+static int its_vlpi_prop_update(struct irq_data *d, struct its_cmd_info *info)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+
+	if (!its_dev->event_map.vm || !irqd_is_forwarded_to_vcpu(d))
+		return -EINVAL;
+
+	if (info->cmd_type == PROP_UPDATE_AND_INV_VLPI)
+		lpi_update_config(d, 0xff, info->config);
+	else
+		lpi_write_config(d, 0xff, info->config);
+	its_vlpi_set_doorbell(d, !!(info->config & LPI_PROP_ENABLED));
+
+	return 0;
+}
+
+static int its_irq_set_vcpu_affinity(struct irq_data *d, void *vcpu_info)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	struct its_cmd_info *info = vcpu_info;
+
+	/* Need a v4 ITS */
+	if (!its_dev->its->is_v4)
+		return -EINVAL;
+
+	/* Unmap request? */
+	if (!info)
+		return its_vlpi_unmap(d);
+
+	switch (info->cmd_type) {
+	case MAP_VLPI:
+		return its_vlpi_map(d, info);
+
+	case GET_VLPI:
+		return its_vlpi_get(d, info);
+
+	case PROP_UPDATE_VLPI:
+	case PROP_UPDATE_AND_INV_VLPI:
+		return its_vlpi_prop_update(d, info);
+
+	default:
+		return -EINVAL;
+	}
+}
+
+static struct irq_chip its_irq_chip = {
+	.name			= "ITS",
+	.irq_mask		= its_mask_irq,
+	.irq_unmask		= its_unmask_irq,
+	.irq_eoi		= irq_chip_eoi_parent,
+	.irq_set_affinity	= its_set_affinity,
+	.irq_compose_msi_msg	= its_irq_compose_msi_msg,
+	.irq_set_irqchip_state	= its_irq_set_irqchip_state,
+	.irq_set_vcpu_affinity	= its_irq_set_vcpu_affinity,
+};
+
+
+/*
+ * How we allocate LPIs:
+ *
+ * lpi_range_list contains ranges of LPIs that are to available to
+ * allocate from. To allocate LPIs, just pick the first range that
+ * fits the required allocation, and reduce it by the required
+ * amount. Once empty, remove the range from the list.
+ *
+ * To free a range of LPIs, add a free range to the list, sort it and
+ * merge the result if the new range happens to be adjacent to an
+ * already free block.
+ *
+ * The consequence of the above is that allocation is cost is low, but
+ * freeing is expensive. We assumes that freeing rarely occurs.
+ */
+#define ITS_MAX_LPI_NRBITS	16 /* 64K LPIs */
+
+static DEFINE_MUTEX(lpi_range_lock);
+static LIST_HEAD(lpi_range_list);
+
+struct lpi_range {
+	struct list_head	entry;
+	u32			base_id;
+	u32			span;
+};
+
+static struct lpi_range *mk_lpi_range(u32 base, u32 span)
+{
+	struct lpi_range *range;
+
+	range = kzalloc(sizeof(*range), GFP_KERNEL);
+	if (range) {
+		INIT_LIST_HEAD(&range->entry);
+		range->base_id = base;
+		range->span = span;
+	}
+
+	return range;
+}
+
+static int lpi_range_cmp(void *priv, struct list_head *a, struct list_head *b)
+{
+	struct lpi_range *ra, *rb;
+
+	ra = container_of(a, struct lpi_range, entry);
+	rb = container_of(b, struct lpi_range, entry);
+
+	return rb->base_id - ra->base_id;
+}
+
+static void merge_lpi_ranges(void)
+{
+	struct lpi_range *range, *tmp;
+
+	list_for_each_entry_safe(range, tmp, &lpi_range_list, entry) {
+		if (!list_is_last(&range->entry, &lpi_range_list) &&
+		    (tmp->base_id == (range->base_id + range->span))) {
+			tmp->base_id = range->base_id;
+			tmp->span += range->span;
+			list_del(&range->entry);
+			kfree(range);
+		}
+	}
+}
+
+static int alloc_lpi_range(u32 nr_lpis, u32 *base)
+{
+	struct lpi_range *range, *tmp;
+	int err = -ENOSPC;
+
+	mutex_lock(&lpi_range_lock);
+
+	list_for_each_entry_safe(range, tmp, &lpi_range_list, entry) {
+		if (range->span >= nr_lpis) {
+			*base = range->base_id;
+			range->base_id += nr_lpis;
+			range->span -= nr_lpis;
+
+			if (range->span == 0) {
+				list_del(&range->entry);
+				kfree(range);
+			}
+
+			err = 0;
+			break;
+		}
+	}
+
+	mutex_unlock(&lpi_range_lock);
+
+	pr_debug("ITS: alloc %u:%u\n", *base, nr_lpis);
+	return err;
+}
+
+static int free_lpi_range(u32 base, u32 nr_lpis)
+{
+	struct lpi_range *new;
+	int err = 0;
+
+	mutex_lock(&lpi_range_lock);
+
+	new = mk_lpi_range(base, nr_lpis);
+	if (!new) {
+		err = -ENOMEM;
+		goto out;
+	}
+
+	list_add(&new->entry, &lpi_range_list);
+	list_sort(NULL, &lpi_range_list, lpi_range_cmp);
+	merge_lpi_ranges();
+out:
+	mutex_unlock(&lpi_range_lock);
+	return err;
+}
+
+static int __init its_lpi_init(u32 id_bits)
+{
+	u32 lpis = (1UL << id_bits) - 8192;
+	u32 numlpis;
+	int err;
+
+	numlpis = 1UL << GICD_TYPER_NUM_LPIS(gic_rdists->gicd_typer);
+
+	if (numlpis > 2 && !WARN_ON(numlpis > lpis)) {
+		lpis = numlpis;
+		pr_info("ITS: Using hypervisor restricted LPI range [%u]\n",
+			lpis);
+	}
+
+	/*
+	 * Initializing the allocator is just the same as freeing the
+	 * full range of LPIs.
+	 */
+	err = free_lpi_range(8192, lpis);
+	pr_debug("ITS: Allocator initialized for %u LPIs\n", lpis);
+	return err;
+}
+
+static unsigned long *its_lpi_alloc(int nr_irqs, u32 *base, int *nr_ids)
+{
+	unsigned long *bitmap = NULL;
+	int err = 0;
+
+	do {
+		err = alloc_lpi_range(nr_irqs, base);
+		if (!err)
+			break;
+
+		nr_irqs /= 2;
+	} while (nr_irqs > 0);
+
+	if (err)
+		goto out;
+
+	bitmap = kcalloc(BITS_TO_LONGS(nr_irqs), sizeof (long), GFP_ATOMIC);
+	if (!bitmap)
+		goto out;
+
+	*nr_ids = nr_irqs;
+
+out:
+	if (!bitmap)
+		*base = *nr_ids = 0;
+
+	return bitmap;
+}
+
+static void its_lpi_free(unsigned long *bitmap, u32 base, u32 nr_ids)
+{
+	WARN_ON(free_lpi_range(base, nr_ids));
+	kfree(bitmap);
+}
+
+static struct page *its_allocate_prop_table(gfp_t gfp_flags)
+{
+	struct page *prop_page;
+
+	prop_page = alloc_pages(gfp_flags, get_order(LPI_PROPBASE_SZ));
+	if (!prop_page)
+		return NULL;
+
+	/* Priority 0xa0, Group-1, disabled */
+	memset(page_address(prop_page),
+	       LPI_PROP_DEFAULT_PRIO | LPI_PROP_GROUP1,
+	       LPI_PROPBASE_SZ);
+
+	/* Make sure the GIC will observe the written configuration */
+	gic_flush_dcache_to_poc(page_address(prop_page), LPI_PROPBASE_SZ);
+
+	return prop_page;
+}
+
+static void its_free_prop_table(struct page *prop_page)
+{
+	free_pages((unsigned long)page_address(prop_page),
+		   get_order(LPI_PROPBASE_SZ));
+}
+
+static int __init its_alloc_lpi_tables(void)
+{
+	phys_addr_t paddr;
+
+	lpi_id_bits = min_t(u32, GICD_TYPER_ID_BITS(gic_rdists->gicd_typer),
+				ITS_MAX_LPI_NRBITS);
+	gic_rdists->prop_page = its_allocate_prop_table(GFP_NOWAIT);
+	if (!gic_rdists->prop_page) {
+		pr_err("Failed to allocate PROPBASE\n");
+		return -ENOMEM;
+	}
+
+	paddr = page_to_phys(gic_rdists->prop_page);
+	pr_info("GIC: using LPI property table @%pa\n", &paddr);
+
+	return its_lpi_init(lpi_id_bits);
+}
+
+static const char *its_base_type_string[] = {
+	[GITS_BASER_TYPE_DEVICE]	= "Devices",
+	[GITS_BASER_TYPE_VCPU]		= "Virtual CPUs",
+	[GITS_BASER_TYPE_RESERVED3]	= "Reserved (3)",
+	[GITS_BASER_TYPE_COLLECTION]	= "Interrupt Collections",
+	[GITS_BASER_TYPE_RESERVED5] 	= "Reserved (5)",
+	[GITS_BASER_TYPE_RESERVED6] 	= "Reserved (6)",
+	[GITS_BASER_TYPE_RESERVED7] 	= "Reserved (7)",
+};
+
+static u64 its_read_baser(struct its_node *its, struct its_baser *baser)
+{
+	u32 idx = baser - its->tables;
+
+	return gits_read_baser(its->base + GITS_BASER + (idx << 3));
+}
+
+static void its_write_baser(struct its_node *its, struct its_baser *baser,
+			    u64 val)
+{
+	u32 idx = baser - its->tables;
+
+	gits_write_baser(val, its->base + GITS_BASER + (idx << 3));
+	baser->val = its_read_baser(its, baser);
+}
+
+static int its_setup_baser(struct its_node *its, struct its_baser *baser,
+			   u64 cache, u64 shr, u32 psz, u32 order,
+			   bool indirect)
+{
+	u64 val = its_read_baser(its, baser);
+	u64 esz = GITS_BASER_ENTRY_SIZE(val);
+	u64 type = GITS_BASER_TYPE(val);
+	u64 baser_phys, tmp;
+	u32 alloc_pages;
+	void *base;
+
+retry_alloc_baser:
+	alloc_pages = (PAGE_ORDER_TO_SIZE(order) / psz);
+	if (alloc_pages > GITS_BASER_PAGES_MAX) {
+		pr_warn("ITS@%pa: %s too large, reduce ITS pages %u->%u\n",
+			&its->phys_base, its_base_type_string[type],
+			alloc_pages, GITS_BASER_PAGES_MAX);
+		alloc_pages = GITS_BASER_PAGES_MAX;
+		order = get_order(GITS_BASER_PAGES_MAX * psz);
+	}
+
+	base = (void *)__get_free_pages(GFP_KERNEL | __GFP_ZERO, order);
+	if (!base)
+		return -ENOMEM;
+
+	baser_phys = virt_to_phys(base);
+
+	/* Check if the physical address of the memory is above 48bits */
+	if (IS_ENABLED(CONFIG_ARM64_64K_PAGES) && (baser_phys >> 48)) {
+
+		/* 52bit PA is supported only when PageSize=64K */
+		if (psz != SZ_64K) {
+			pr_err("ITS: no 52bit PA support when psz=%d\n", psz);
+			free_pages((unsigned long)base, order);
+			return -ENXIO;
+		}
+
+		/* Convert 52bit PA to 48bit field */
+		baser_phys = GITS_BASER_PHYS_52_to_48(baser_phys);
+	}
+
+retry_baser:
+	val = (baser_phys					 |
+		(type << GITS_BASER_TYPE_SHIFT)			 |
+		((esz - 1) << GITS_BASER_ENTRY_SIZE_SHIFT)	 |
+		((alloc_pages - 1) << GITS_BASER_PAGES_SHIFT)	 |
+		cache						 |
+		shr						 |
+		GITS_BASER_VALID);
+
+	val |=	indirect ? GITS_BASER_INDIRECT : 0x0;
+
+	switch (psz) {
+	case SZ_4K:
+		val |= GITS_BASER_PAGE_SIZE_4K;
+		break;
+	case SZ_16K:
+		val |= GITS_BASER_PAGE_SIZE_16K;
+		break;
+	case SZ_64K:
+		val |= GITS_BASER_PAGE_SIZE_64K;
+		break;
+	}
+
+	its_write_baser(its, baser, val);
+	tmp = baser->val;
+
+	if ((val ^ tmp) & GITS_BASER_SHAREABILITY_MASK) {
+		/*
+		 * Shareability didn't stick. Just use
+		 * whatever the read reported, which is likely
+		 * to be the only thing this redistributor
+		 * supports. If that's zero, make it
+		 * non-cacheable as well.
+		 */
+		shr = tmp & GITS_BASER_SHAREABILITY_MASK;
+		if (!shr) {
+			cache = GITS_BASER_nC;
+			gic_flush_dcache_to_poc(base, PAGE_ORDER_TO_SIZE(order));
+		}
+		goto retry_baser;
+	}
+
+	if ((val ^ tmp) & GITS_BASER_PAGE_SIZE_MASK) {
+		/*
+		 * Page size didn't stick. Let's try a smaller
+		 * size and retry. If we reach 4K, then
+		 * something is horribly wrong...
+		 */
+		free_pages((unsigned long)base, order);
+		baser->base = NULL;
+
+		switch (psz) {
+		case SZ_16K:
+			psz = SZ_4K;
+			goto retry_alloc_baser;
+		case SZ_64K:
+			psz = SZ_16K;
+			goto retry_alloc_baser;
+		}
+	}
+
+	if (val != tmp) {
+		pr_err("ITS@%pa: %s doesn't stick: %llx %llx\n",
+		       &its->phys_base, its_base_type_string[type],
+		       val, tmp);
+		free_pages((unsigned long)base, order);
+		return -ENXIO;
+	}
+
+	baser->order = order;
+	baser->base = base;
+	baser->psz = psz;
+	tmp = indirect ? GITS_LVL1_ENTRY_SIZE : esz;
+
+	pr_info("ITS@%pa: allocated %d %s @%lx (%s, esz %d, psz %dK, shr %d)\n",
+		&its->phys_base, (int)(PAGE_ORDER_TO_SIZE(order) / (int)tmp),
+		its_base_type_string[type],
+		(unsigned long)virt_to_phys(base),
+		indirect ? "indirect" : "flat", (int)esz,
+		psz / SZ_1K, (int)shr >> GITS_BASER_SHAREABILITY_SHIFT);
+
+	return 0;
+}
+
+static bool its_parse_indirect_baser(struct its_node *its,
+				     struct its_baser *baser,
+				     u32 psz, u32 *order, u32 ids)
+{
+	u64 tmp = its_read_baser(its, baser);
+	u64 type = GITS_BASER_TYPE(tmp);
+	u64 esz = GITS_BASER_ENTRY_SIZE(tmp);
+	u64 val = GITS_BASER_InnerShareable | GITS_BASER_RaWaWb;
+	u32 new_order = *order;
+	bool indirect = false;
+
+	/* No need to enable Indirection if memory requirement < (psz*2)bytes */
+	if ((esz << ids) > (psz * 2)) {
+		/*
+		 * Find out whether hw supports a single or two-level table by
+		 * table by reading bit at offset '62' after writing '1' to it.
+		 */
+		its_write_baser(its, baser, val | GITS_BASER_INDIRECT);
+		indirect = !!(baser->val & GITS_BASER_INDIRECT);
+
+		if (indirect) {
+			/*
+			 * The size of the lvl2 table is equal to ITS page size
+			 * which is 'psz'. For computing lvl1 table size,
+			 * subtract ID bits that sparse lvl2 table from 'ids'
+			 * which is reported by ITS hardware times lvl1 table
+			 * entry size.
+			 */
+			ids -= ilog2(psz / (int)esz);
+			esz = GITS_LVL1_ENTRY_SIZE;
+		}
+	}
+
+	/*
+	 * Allocate as many entries as required to fit the
+	 * range of device IDs that the ITS can grok... The ID
+	 * space being incredibly sparse, this results in a
+	 * massive waste of memory if two-level device table
+	 * feature is not supported by hardware.
+	 */
+	new_order = max_t(u32, get_order(esz << ids), new_order);
+	if (new_order >= MAX_ORDER) {
+		new_order = MAX_ORDER - 1;
+		ids = ilog2(PAGE_ORDER_TO_SIZE(new_order) / (int)esz);
+		pr_warn("ITS@%pa: %s Table too large, reduce ids %u->%u\n",
+			&its->phys_base, its_base_type_string[type],
+			its->device_ids, ids);
+	}
+
+	*order = new_order;
+
+	return indirect;
+}
+
+static void its_free_tables(struct its_node *its)
+{
+	int i;
+
+	for (i = 0; i < GITS_BASER_NR_REGS; i++) {
+		if (its->tables[i].base) {
+			free_pages((unsigned long)its->tables[i].base,
+				   its->tables[i].order);
+			its->tables[i].base = NULL;
+		}
+	}
+}
+
+static int its_alloc_tables(struct its_node *its)
+{
+	u64 shr = GITS_BASER_InnerShareable;
+	u64 cache = GITS_BASER_RaWaWb;
+	u32 psz = SZ_64K;
+	int err, i;
+
+	if (its->flags & ITS_FLAGS_WORKAROUND_CAVIUM_22375)
+		/* erratum 24313: ignore memory access type */
+		cache = GITS_BASER_nCnB;
+
+	for (i = 0; i < GITS_BASER_NR_REGS; i++) {
+		struct its_baser *baser = its->tables + i;
+		u64 val = its_read_baser(its, baser);
+		u64 type = GITS_BASER_TYPE(val);
+		u32 order = get_order(psz);
+		bool indirect = false;
+
+		switch (type) {
+		case GITS_BASER_TYPE_NONE:
+			continue;
+
+		case GITS_BASER_TYPE_DEVICE:
+			indirect = its_parse_indirect_baser(its, baser,
+							    psz, &order,
+							    its->device_ids);
+		case GITS_BASER_TYPE_VCPU:
+			indirect = its_parse_indirect_baser(its, baser,
+							    psz, &order,
+							    ITS_MAX_VPEID_BITS);
+			break;
+		}
+
+		err = its_setup_baser(its, baser, cache, shr, psz, order, indirect);
+		if (err < 0) {
+			its_free_tables(its);
+			return err;
+		}
+
+		/* Update settings which will be used for next BASERn */
+		psz = baser->psz;
+		cache = baser->val & GITS_BASER_CACHEABILITY_MASK;
+		shr = baser->val & GITS_BASER_SHAREABILITY_MASK;
+	}
+
+	return 0;
+}
+
+static int its_alloc_collections(struct its_node *its)
+{
+	int i;
+
+	its->collections = kcalloc(nr_cpu_ids, sizeof(*its->collections),
+				   GFP_KERNEL);
+	if (!its->collections)
+		return -ENOMEM;
+
+	for (i = 0; i < nr_cpu_ids; i++)
+		its->collections[i].target_address = ~0ULL;
+
+	return 0;
+}
+
+static struct page *its_allocate_pending_table(gfp_t gfp_flags)
+{
+	struct page *pend_page;
+	/*
+	 * The pending pages have to be at least 64kB aligned,
+	 * hence the 'max(LPI_PENDBASE_SZ, SZ_64K)' below.
+	 */
+	pend_page = alloc_pages(gfp_flags | __GFP_ZERO,
+				get_order(max_t(u32, LPI_PENDBASE_SZ, SZ_64K)));
+	if (!pend_page)
+		return NULL;
+
+	/* Make sure the GIC will observe the zero-ed page */
+	gic_flush_dcache_to_poc(page_address(pend_page), LPI_PENDBASE_SZ);
+
+	return pend_page;
+}
+
+static void its_free_pending_table(struct page *pt)
+{
+	free_pages((unsigned long)page_address(pt),
+		   get_order(max_t(u32, LPI_PENDBASE_SZ, SZ_64K)));
+}
+
+static void its_cpu_init_lpis(void)
+{
+	void __iomem *rbase = gic_data_rdist_rd_base();
+	struct page *pend_page;
+	u64 val, tmp;
+
+	/* If we didn't allocate the pending table yet, do it now */
+	pend_page = gic_data_rdist()->pend_page;
+	if (!pend_page) {
+		phys_addr_t paddr;
+
+		pend_page = its_allocate_pending_table(GFP_NOWAIT);
+		if (!pend_page) {
+			pr_err("Failed to allocate PENDBASE for CPU%d\n",
+			       smp_processor_id());
+			return;
+		}
+
+		paddr = page_to_phys(pend_page);
+		pr_info("CPU%d: using LPI pending table @%pa\n",
+			smp_processor_id(), &paddr);
+		gic_data_rdist()->pend_page = pend_page;
+	}
+
+	/* set PROPBASE */
+	val = (page_to_phys(gic_rdists->prop_page) |
+	       GICR_PROPBASER_InnerShareable |
+	       GICR_PROPBASER_RaWaWb |
+	       ((LPI_NRBITS - 1) & GICR_PROPBASER_IDBITS_MASK));
+
+	gicr_write_propbaser(val, rbase + GICR_PROPBASER);
+	tmp = gicr_read_propbaser(rbase + GICR_PROPBASER);
+
+	if ((tmp ^ val) & GICR_PROPBASER_SHAREABILITY_MASK) {
+		if (!(tmp & GICR_PROPBASER_SHAREABILITY_MASK)) {
+			/*
+			 * The HW reports non-shareable, we must
+			 * remove the cacheability attributes as
+			 * well.
+			 */
+			val &= ~(GICR_PROPBASER_SHAREABILITY_MASK |
+				 GICR_PROPBASER_CACHEABILITY_MASK);
+			val |= GICR_PROPBASER_nC;
+			gicr_write_propbaser(val, rbase + GICR_PROPBASER);
+		}
+		pr_info_once("GIC: using cache flushing for LPI property table\n");
+		gic_rdists->flags |= RDIST_FLAGS_PROPBASE_NEEDS_FLUSHING;
+	}
+
+	/* set PENDBASE */
+	val = (page_to_phys(pend_page) |
+	       GICR_PENDBASER_InnerShareable |
+	       GICR_PENDBASER_RaWaWb);
+
+	gicr_write_pendbaser(val, rbase + GICR_PENDBASER);
+	tmp = gicr_read_pendbaser(rbase + GICR_PENDBASER);
+
+	if (!(tmp & GICR_PENDBASER_SHAREABILITY_MASK)) {
+		/*
+		 * The HW reports non-shareable, we must remove the
+		 * cacheability attributes as well.
+		 */
+		val &= ~(GICR_PENDBASER_SHAREABILITY_MASK |
+			 GICR_PENDBASER_CACHEABILITY_MASK);
+		val |= GICR_PENDBASER_nC;
+		gicr_write_pendbaser(val, rbase + GICR_PENDBASER);
+	}
+
+	/* Enable LPIs */
+	val = readl_relaxed(rbase + GICR_CTLR);
+	val |= GICR_CTLR_ENABLE_LPIS;
+	writel_relaxed(val, rbase + GICR_CTLR);
+
+	/* Make sure the GIC has seen the above */
+	dsb(sy);
+}
+
+static void its_cpu_init_collection(struct its_node *its)
+{
+	int cpu = smp_processor_id();
+	unsigned long mpid, skt_id;
+	phys_addr_t its_phys_base;
+	u64 target;
+
+	/* avoid cross node collections and its mapping */
+	if (its->flags & ITS_FLAGS_WORKAROUND_CAVIUM_23144) {
+		struct device_node *cpu_node;
+
+		cpu_node = of_get_cpu_node(cpu, NULL);
+		if (its->numa_node != NUMA_NO_NODE &&
+			its->numa_node != of_node_to_nid(cpu_node))
+			return;
+	}
+
+	mpid = cpu_logical_map(cpu);
+	its_phys_base = its->phys_base;
+	skt_id = (its_phys_base >> 41) & 0x7;
+
+	/*
+	 * We now have to bind each collection to its target
+	 * redistributor.
+	 */
+	if (gic_read_typer(its->base + GITS_TYPER) & GITS_TYPER_PTA) {
+		/*
+		 * This ITS wants the physical address of the
+		 * redistributor.
+		 */
+		target = gic_data_rdist()->phys_base;
+	} else {
+		/* This ITS wants a linear CPU number. */
+		target = gic_read_typer(gic_data_rdist_rd_base() + GICR_TYPER);
+		target = GICR_TYPER_CPU_NUMBER(target) << 16;
+	}
+
+	/* Perform collection mapping */
+	its->collections[cpu].target_address = target;
+	its->collections[cpu].col_id = cpu;
+
+	its_send_mapc(its, &its->collections[cpu], 1);
+	its_send_invall(its, &its->collections[cpu]);
+}
+
+static void its_cpu_init_collections(void)
+{
+	struct its_node *its;
+
+	raw_spin_lock(&its_lock);
+
+	list_for_each_entry(its, &its_nodes, entry)
+		its_cpu_init_collection(its);
+
+	raw_spin_unlock(&its_lock);
+}
+
+static struct its_device *its_find_device(struct its_node *its, u32 dev_id)
+{
+	struct its_device *its_dev = NULL, *tmp;
+	unsigned long flags;
+
+	raw_spin_lock_irqsave(&its->lock, flags);
+
+	list_for_each_entry(tmp, &its->its_device_list, entry) {
+		if (tmp->device_id == dev_id) {
+			its_dev = tmp;
+			break;
+		}
+	}
+
+	raw_spin_unlock_irqrestore(&its->lock, flags);
+
+	return its_dev;
+}
+
+static struct its_baser *its_get_baser(struct its_node *its, u32 type)
+{
+	int i;
+
+	for (i = 0; i < GITS_BASER_NR_REGS; i++) {
+		if (GITS_BASER_TYPE(its->tables[i].val) == type)
+			return &its->tables[i];
+	}
+
+	return NULL;
+}
+
+static bool its_alloc_table_entry(struct its_baser *baser, u32 id)
+{
+	struct page *page;
+	u32 esz, idx;
+	__le64 *table;
+
+	/* Don't allow device id that exceeds single, flat table limit */
+	esz = GITS_BASER_ENTRY_SIZE(baser->val);
+	if (!(baser->val & GITS_BASER_INDIRECT))
+		return (id < (PAGE_ORDER_TO_SIZE(baser->order) / esz));
+
+	/* Compute 1st level table index & check if that exceeds table limit */
+	idx = id >> ilog2(baser->psz / esz);
+	if (idx >= (PAGE_ORDER_TO_SIZE(baser->order) / GITS_LVL1_ENTRY_SIZE))
+		return false;
+
+	table = baser->base;
+
+	/* Allocate memory for 2nd level table */
+	if (!table[idx]) {
+		page = alloc_pages(GFP_KERNEL | __GFP_ZERO, get_order(baser->psz));
+		if (!page)
+			return false;
+
+		/* Flush Lvl2 table to PoC if hw doesn't support coherency */
+		if (!(baser->val & GITS_BASER_SHAREABILITY_MASK))
+			gic_flush_dcache_to_poc(page_address(page), baser->psz);
+
+		table[idx] = cpu_to_le64(page_to_phys(page) | GITS_BASER_VALID);
+
+		/* Flush Lvl1 entry to PoC if hw doesn't support coherency */
+		if (!(baser->val & GITS_BASER_SHAREABILITY_MASK))
+			gic_flush_dcache_to_poc(table + idx, GITS_LVL1_ENTRY_SIZE);
+
+		/* Ensure updated table contents are visible to ITS hardware */
+		dsb(sy);
+	}
+
+	return true;
+}
+
+static bool its_alloc_device_table(struct its_node *its, u32 dev_id)
+{
+	struct its_baser *baser;
+
+	baser = its_get_baser(its, GITS_BASER_TYPE_DEVICE);
+
+	/* Don't allow device id that exceeds ITS hardware limit */
+	if (!baser)
+		return (ilog2(dev_id) < its->device_ids);
+
+	return its_alloc_table_entry(baser, dev_id);
+}
+
+static bool its_alloc_vpe_table(u32 vpe_id)
+{
+	struct its_node *its;
+
+	/*
+	 * Make sure the L2 tables are allocated on *all* v4 ITSs. We
+	 * could try and only do it on ITSs corresponding to devices
+	 * that have interrupts targeted at this VPE, but the
+	 * complexity becomes crazy (and you have tons of memory
+	 * anyway, right?).
+	 */
+	list_for_each_entry(its, &its_nodes, entry) {
+		struct its_baser *baser;
+
+		if (!its->is_v4)
+			continue;
+
+		baser = its_get_baser(its, GITS_BASER_TYPE_VCPU);
+		if (!baser)
+			return false;
+
+		if (!its_alloc_table_entry(baser, vpe_id))
+			return false;
+	}
+
+	return true;
+}
+
+static struct its_device *its_create_device(struct its_node *its, u32 dev_id,
+					    int nvecs, bool alloc_lpis)
+{
+	struct its_device *dev;
+	unsigned long *lpi_map = NULL;
+	unsigned long flags;
+	u16 *col_map = NULL;
+	void *itt;
+	int lpi_base;
+	int nr_lpis;
+	int nr_ites;
+	int sz;
+
+	if (!its_alloc_device_table(its, dev_id))
+		return NULL;
+
+	if (WARN_ON(!is_power_of_2(nvecs)))
+		nvecs = roundup_pow_of_two(nvecs);
+
+	dev = kzalloc(sizeof(*dev), GFP_KERNEL);
+	/*
+	 * Even if the device wants a single LPI, the ITT must be
+	 * sized as a power of two (and you need at least one bit...).
+	 */
+	nr_ites = max(2, nvecs);
+	sz = nr_ites * its->ite_size;
+	sz = max(sz, ITS_ITT_ALIGN) + ITS_ITT_ALIGN - 1;
+	itt = kzalloc(sz, GFP_KERNEL);
+	if (alloc_lpis) {
+		lpi_map = its_lpi_alloc(nvecs, &lpi_base, &nr_lpis);
+		if (lpi_map)
+			col_map = kcalloc(nr_lpis, sizeof(*col_map),
+					  GFP_KERNEL);
+	} else {
+		col_map = kcalloc(nr_ites, sizeof(*col_map), GFP_KERNEL);
+		nr_lpis = 0;
+		lpi_base = 0;
+	}
+
+	if (!dev || !itt ||  !col_map || (!lpi_map && alloc_lpis)) {
+		kfree(dev);
+		kfree(itt);
+		kfree(lpi_map);
+		kfree(col_map);
+		return NULL;
+	}
+
+	gic_flush_dcache_to_poc(itt, sz);
+
+	dev->its = its;
+	dev->itt = itt;
+	dev->nr_ites = nr_ites;
+	dev->event_map.lpi_map = lpi_map;
+	dev->event_map.col_map = col_map;
+	dev->event_map.lpi_base = lpi_base;
+	dev->event_map.nr_lpis = nr_lpis;
+	mutex_init(&dev->event_map.vlpi_lock);
+	dev->device_id = dev_id;
+	INIT_LIST_HEAD(&dev->entry);
+
+	raw_spin_lock_irqsave(&its->lock, flags);
+	list_add(&dev->entry, &its->its_device_list);
+	raw_spin_unlock_irqrestore(&its->lock, flags);
+
+	/* Map device to its ITT */
+	its_send_mapd(dev, 1);
+
+	return dev;
+}
+
+static void its_free_device(struct its_device *its_dev)
+{
+	unsigned long flags;
+
+	raw_spin_lock_irqsave(&its_dev->its->lock, flags);
+	list_del(&its_dev->entry);
+	raw_spin_unlock_irqrestore(&its_dev->its->lock, flags);
+	kfree(its_dev->itt);
+	kfree(its_dev);
+}
+
+static int its_alloc_device_irq(struct its_device *dev, irq_hw_number_t *hwirq)
+{
+	int idx;
+
+	idx = find_first_zero_bit(dev->event_map.lpi_map,
+				  dev->event_map.nr_lpis);
+	if (idx == dev->event_map.nr_lpis)
+		return -ENOSPC;
+
+	*hwirq = dev->event_map.lpi_base + idx;
+	set_bit(idx, dev->event_map.lpi_map);
+
+	return 0;
+}
+
+static int its_msi_prepare(struct irq_domain *domain, struct device *dev,
+			   int nvec, msi_alloc_info_t *info)
+{
+	struct its_node *its;
+	struct its_device *its_dev;
+	struct msi_domain_info *msi_info;
+	u32 dev_id;
+
+	/*
+	 * We ignore "dev" entierely, and rely on the dev_id that has
+	 * been passed via the scratchpad. This limits this domain's
+	 * usefulness to upper layers that definitely know that they
+	 * are built on top of the ITS.
+	 */
+	dev_id = info->scratchpad[0].ul;
+
+	msi_info = msi_get_domain_info(domain);
+	its = msi_info->data;
+
+	if (!gic_rdists->has_direct_lpi &&
+	    vpe_proxy.dev &&
+	    vpe_proxy.dev->its == its &&
+	    dev_id == vpe_proxy.dev->device_id) {
+		/* Bad luck. Get yourself a better implementation */
+		WARN_ONCE(1, "DevId %x clashes with GICv4 VPE proxy device\n",
+			  dev_id);
+		return -EINVAL;
+	}
+
+	its_dev = its_find_device(its, dev_id);
+	if (its_dev) {
+		/*
+		 * We already have seen this ID, probably through
+		 * another alias (PCI bridge of some sort). No need to
+		 * create the device.
+		 */
+		pr_debug("Reusing ITT for devID %x\n", dev_id);
+		goto out;
+	}
+
+	its_dev = its_create_device(its, dev_id, nvec, true);
+	if (!its_dev)
+		return -ENOMEM;
+
+	pr_debug("ITT %d entries, %d bits\n", nvec, ilog2(nvec));
+out:
+	info->scratchpad[0].ptr = its_dev;
+	return 0;
+}
+
+static struct msi_domain_ops its_msi_domain_ops = {
+	.msi_prepare	= its_msi_prepare,
+};
+
+static int its_irq_gic_domain_alloc(struct irq_domain *domain,
+				    unsigned int virq,
+				    irq_hw_number_t hwirq)
+{
+	struct irq_fwspec fwspec;
+
+	if (irq_domain_get_of_node(domain->parent)) {
+		fwspec.fwnode = domain->parent->fwnode;
+		fwspec.param_count = 3;
+		fwspec.param[0] = GIC_IRQ_TYPE_LPI;
+		fwspec.param[1] = hwirq;
+		fwspec.param[2] = IRQ_TYPE_EDGE_RISING;
+	} else if (is_fwnode_irqchip(domain->parent->fwnode)) {
+		fwspec.fwnode = domain->parent->fwnode;
+		fwspec.param_count = 2;
+		fwspec.param[0] = hwirq;
+		fwspec.param[1] = IRQ_TYPE_EDGE_RISING;
+	} else {
+		return -EINVAL;
+	}
+
+	return irq_domain_alloc_irqs_parent(domain, virq, 1, &fwspec);
+}
+
+static int its_irq_domain_alloc(struct irq_domain *domain, unsigned int virq,
+				unsigned int nr_irqs, void *args)
+{
+	msi_alloc_info_t *info = args;
+	struct its_device *its_dev = info->scratchpad[0].ptr;
+	irq_hw_number_t hwirq;
+	int err;
+	int i;
+
+	for (i = 0; i < nr_irqs; i++) {
+		err = its_alloc_device_irq(its_dev, &hwirq);
+		if (err)
+			return err;
+
+		err = its_irq_gic_domain_alloc(domain, virq + i, hwirq);
+		if (err)
+			return err;
+
+		irq_domain_set_hwirq_and_chip(domain, virq + i,
+					      hwirq, &its_irq_chip, its_dev);
+		irqd_set_single_target(irq_desc_get_irq_data(irq_to_desc(virq + i)));
+		pr_debug("ID:%d pID:%d vID:%d\n",
+			 (int)(hwirq - its_dev->event_map.lpi_base),
+			 (int) hwirq, virq + i);
+	}
+
+	return 0;
+}
+
+static int its_cpumask_first(struct its_device *its_dev,
+			     const struct cpumask *cpu_mask)
+{
+	unsigned int skt, skt_id, i;
+	phys_addr_t its_phys_base;
+	unsigned int cpu, cpus = 0;
+	unsigned int skt_cpu_cnt[MAX_MARS3_SKT_COUNT] = {0};
+
+	for (i = 0; i < nr_cpu_ids; i++) {
+		skt = (cpu_logical_map(i) >> 16) & 0xff;
+		if ((skt >= 0) && (skt < MAX_MARS3_SKT_COUNT))
+			skt_cpu_cnt[skt]++;
+		else if (0xff != skt )
+			pr_err("socket address: %d is out of range.", skt);
+	}
+
+	its_phys_base = its_dev->its->phys_base;
+	skt_id = (its_phys_base >> 41) & 0x7;
+
+	if (0 != skt_id) {
+		for (i = 0; i < skt_id; i++)
+			cpus += skt_cpu_cnt[i];
+	}
+
+	cpu = cpumask_first(cpu_mask);
+	if ((cpu > cpus) && (cpu < (cpus + skt_cpu_cnt[skt_id])))
+		cpus = cpu;
+
+	return cpus;
+}
+
+static int its_irq_domain_activate(struct irq_domain *domain,
+				   struct irq_data *d, bool reserve)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	u32 event = its_get_event_id(d);
+	const struct cpumask *cpu_mask = cpu_online_mask;
+	int cpu;
+
+	/* get the cpu_mask of local node */
+	if (its_dev->its->numa_node >= 0)
+		cpu_mask = cpumask_of_node(its_dev->its->numa_node);
+
+	/* Bind the LPI to the first possible CPU */
+	cpu = its_cpumask_first(its_dev, cpu_mask);
+	printk("its_irq_domain_activate: MAPTI irq %d hwirq %ld on cpu %d\n",
+	       d->irq, d->hwirq, cpu);
+
+	its_dev->event_map.col_map[event] = cpu;
+	irq_data_update_effective_affinity(d, cpumask_of(cpu));
+
+	/* Map the GIC IRQ and event to the device */
+	its_send_mapti(its_dev, d->hwirq, event);
+	return 0;
+}
+
+static void its_irq_domain_deactivate(struct irq_domain *domain,
+				      struct irq_data *d)
+{
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	u32 event = its_get_event_id(d);
+
+	/* Stop the delivery of interrupts */
+	its_send_discard(its_dev, event);
+}
+
+static void its_irq_domain_free(struct irq_domain *domain, unsigned int virq,
+				unsigned int nr_irqs)
+{
+	struct irq_data *d = irq_domain_get_irq_data(domain, virq);
+	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
+	int i;
+
+	for (i = 0; i < nr_irqs; i++) {
+		struct irq_data *data = irq_domain_get_irq_data(domain,
+								virq + i);
+		u32 event = its_get_event_id(data);
+
+		/* Mark interrupt index as unused */
+		clear_bit(event, its_dev->event_map.lpi_map);
+
+		/* Nuke the entry in the domain */
+		irq_domain_reset_irq_data(data);
+	}
+
+	/* If all interrupts have been freed, start mopping the floor */
+	if (bitmap_empty(its_dev->event_map.lpi_map,
+			 its_dev->event_map.nr_lpis)) {
+		its_lpi_free(its_dev->event_map.lpi_map,
+			     its_dev->event_map.lpi_base,
+			     its_dev->event_map.nr_lpis);
+		kfree(its_dev->event_map.col_map);
+
+		/* Unmap device/itt */
+		its_send_mapd(its_dev, 0);
+		its_free_device(its_dev);
+	}
+
+	irq_domain_free_irqs_parent(domain, virq, nr_irqs);
+}
+
+static const struct irq_domain_ops its_domain_ops = {
+	.alloc			= its_irq_domain_alloc,
+	.free			= its_irq_domain_free,
+	.activate		= its_irq_domain_activate,
+	.deactivate		= its_irq_domain_deactivate,
+};
+
+/*
+ * This is insane.
+ *
+ * If a GICv4 doesn't implement Direct LPIs (which is extremely
+ * likely), the only way to perform an invalidate is to use a fake
+ * device to issue an INV command, implying that the LPI has first
+ * been mapped to some event on that device. Since this is not exactly
+ * cheap, we try to keep that mapping around as long as possible, and
+ * only issue an UNMAP if we're short on available slots.
+ *
+ * Broken by design(tm).
+ */
+static void its_vpe_db_proxy_unmap_locked(struct its_vpe *vpe)
+{
+	/* Already unmapped? */
+	if (vpe->vpe_proxy_event == -1)
+		return;
+
+	its_send_discard(vpe_proxy.dev, vpe->vpe_proxy_event);
+	vpe_proxy.vpes[vpe->vpe_proxy_event] = NULL;
+
+	/*
+	 * We don't track empty slots at all, so let's move the
+	 * next_victim pointer if we can quickly reuse that slot
+	 * instead of nuking an existing entry. Not clear that this is
+	 * always a win though, and this might just generate a ripple
+	 * effect... Let's just hope VPEs don't migrate too often.
+	 */
+	if (vpe_proxy.vpes[vpe_proxy.next_victim])
+		vpe_proxy.next_victim = vpe->vpe_proxy_event;
+
+	vpe->vpe_proxy_event = -1;
+}
+
+static void its_vpe_db_proxy_unmap(struct its_vpe *vpe)
+{
+	if (!gic_rdists->has_direct_lpi) {
+		unsigned long flags;
+
+		raw_spin_lock_irqsave(&vpe_proxy.lock, flags);
+		its_vpe_db_proxy_unmap_locked(vpe);
+		raw_spin_unlock_irqrestore(&vpe_proxy.lock, flags);
+	}
+}
+
+static void its_vpe_db_proxy_map_locked(struct its_vpe *vpe)
+{
+	/* Already mapped? */
+	if (vpe->vpe_proxy_event != -1)
+		return;
+
+	/* This slot was already allocated. Kick the other VPE out. */
+	if (vpe_proxy.vpes[vpe_proxy.next_victim])
+		its_vpe_db_proxy_unmap_locked(vpe_proxy.vpes[vpe_proxy.next_victim]);
+
+	/* Map the new VPE instead */
+	vpe_proxy.vpes[vpe_proxy.next_victim] = vpe;
+	vpe->vpe_proxy_event = vpe_proxy.next_victim;
+	vpe_proxy.next_victim = (vpe_proxy.next_victim + 1) % vpe_proxy.dev->nr_ites;
+
+	vpe_proxy.dev->event_map.col_map[vpe->vpe_proxy_event] = vpe->col_idx;
+	its_send_mapti(vpe_proxy.dev, vpe->vpe_db_lpi, vpe->vpe_proxy_event);
+}
+
+static void its_vpe_db_proxy_move(struct its_vpe *vpe, int from, int to)
+{
+	unsigned long flags;
+	struct its_collection *target_col;
+
+	if (gic_rdists->has_direct_lpi) {
+		void __iomem *rdbase;
+
+		rdbase = per_cpu_ptr(gic_rdists->rdist, from)->rd_base;
+		gic_write_lpir(vpe->vpe_db_lpi, rdbase + GICR_CLRLPIR);
+		while (gic_read_lpir(rdbase + GICR_SYNCR) & 1)
+			cpu_relax();
+
+		return;
+	}
+
+	raw_spin_lock_irqsave(&vpe_proxy.lock, flags);
+
+	its_vpe_db_proxy_map_locked(vpe);
+
+	target_col = &vpe_proxy.dev->its->collections[to];
+	its_send_movi(vpe_proxy.dev, target_col, vpe->vpe_proxy_event);
+	vpe_proxy.dev->event_map.col_map[vpe->vpe_proxy_event] = to;
+
+	raw_spin_unlock_irqrestore(&vpe_proxy.lock, flags);
+}
+
+static int its_vpe_set_affinity(struct irq_data *d,
+				const struct cpumask *mask_val,
+				bool force)
+{
+	struct its_vpe *vpe = irq_data_get_irq_chip_data(d);
+	int cpu = cpumask_first(mask_val);
+
+	/*
+	 * Changing affinity is mega expensive, so let's be as lazy as
+	 * we can and only do it if we really have to. Also, if mapped
+	 * into the proxy device, we need to move the doorbell
+	 * interrupt to its new location.
+	 */
+	if (vpe->col_idx != cpu) {
+		int from = vpe->col_idx;
+
+		vpe->col_idx = cpu;
+		its_send_vmovp(vpe);
+		its_vpe_db_proxy_move(vpe, from, cpu);
+	}
+
+	irq_data_update_effective_affinity(d, cpumask_of(cpu));
+
+	return IRQ_SET_MASK_OK_DONE;
+}
+
+static void its_vpe_schedule(struct its_vpe *vpe)
+{
+	void __iomem *vlpi_base = gic_data_rdist_vlpi_base();
+	u64 val;
+
+	/* Schedule the VPE */
+	val  = virt_to_phys(page_address(vpe->its_vm->vprop_page)) &
+		GENMASK_ULL(51, 12);
+	val |= (LPI_NRBITS - 1) & GICR_VPROPBASER_IDBITS_MASK;
+	val |= GICR_VPROPBASER_RaWb;
+	val |= GICR_VPROPBASER_InnerShareable;
+	gits_write_vpropbaser(val, vlpi_base + GICR_VPROPBASER);
+
+	val  = virt_to_phys(page_address(vpe->vpt_page)) &
+		GENMASK_ULL(51, 16);
+	val |= GICR_VPENDBASER_RaWaWb;
+	val |= GICR_VPENDBASER_NonShareable;
+	/*
+	 * There is no good way of finding out if the pending table is
+	 * empty as we can race against the doorbell interrupt very
+	 * easily. So in the end, vpe->pending_last is only an
+	 * indication that the vcpu has something pending, not one
+	 * that the pending table is empty. A good implementation
+	 * would be able to read its coarse map pretty quickly anyway,
+	 * making this a tolerable issue.
+	 */
+	val |= GICR_VPENDBASER_PendingLast;
+	val |= vpe->idai ? GICR_VPENDBASER_IDAI : 0;
+	val |= GICR_VPENDBASER_Valid;
+	gits_write_vpendbaser(val, vlpi_base + GICR_VPENDBASER);
+}
+
+static void its_vpe_deschedule(struct its_vpe *vpe)
+{
+	void __iomem *vlpi_base = gic_data_rdist_vlpi_base();
+	u32 count = 1000000;	/* 1s! */
+	bool clean;
+	u64 val;
+
+	/* We're being scheduled out */
+	val = gits_read_vpendbaser(vlpi_base + GICR_VPENDBASER);
+	val &= ~GICR_VPENDBASER_Valid;
+	gits_write_vpendbaser(val, vlpi_base + GICR_VPENDBASER);
+
+	do {
+		val = gits_read_vpendbaser(vlpi_base + GICR_VPENDBASER);
+		clean = !(val & GICR_VPENDBASER_Dirty);
+		if (!clean) {
+			count--;
+			cpu_relax();
+			udelay(1);
+		}
+	} while (!clean && count);
+
+	if (unlikely(!clean && !count)) {
+		pr_err_ratelimited("ITS virtual pending table not cleaning\n");
+		vpe->idai = false;
+		vpe->pending_last = true;
+	} else {
+		vpe->idai = !!(val & GICR_VPENDBASER_IDAI);
+		vpe->pending_last = !!(val & GICR_VPENDBASER_PendingLast);
+	}
+}
+
+static void its_vpe_invall(struct its_vpe *vpe)
+{
+	struct its_node *its;
+
+	list_for_each_entry(its, &its_nodes, entry) {
+		if (!its->is_v4)
+			continue;
+
+		if (its_list_map && !vpe->its_vm->vlpi_count[its->list_nr])
+			continue;
+
+		/*
+		 * Sending a VINVALL to a single ITS is enough, as all
+		 * we need is to reach the redistributors.
+		 */
+		its_send_vinvall(its, vpe);
+		return;
+	}
+}
+
+static int its_vpe_set_vcpu_affinity(struct irq_data *d, void *vcpu_info)
+{
+	struct its_vpe *vpe = irq_data_get_irq_chip_data(d);
+	struct its_cmd_info *info = vcpu_info;
+
+	switch (info->cmd_type) {
+	case SCHEDULE_VPE:
+		its_vpe_schedule(vpe);
+		return 0;
+
+	case DESCHEDULE_VPE:
+		its_vpe_deschedule(vpe);
+		return 0;
+
+	case INVALL_VPE:
+		its_vpe_invall(vpe);
+		return 0;
+
+	default:
+		return -EINVAL;
+	}
+}
+
+static void its_vpe_send_cmd(struct its_vpe *vpe,
+			     void (*cmd)(struct its_device *, u32))
+{
+	unsigned long flags;
+
+	raw_spin_lock_irqsave(&vpe_proxy.lock, flags);
+
+	its_vpe_db_proxy_map_locked(vpe);
+	cmd(vpe_proxy.dev, vpe->vpe_proxy_event);
+
+	raw_spin_unlock_irqrestore(&vpe_proxy.lock, flags);
+}
+
+static void its_vpe_send_inv(struct irq_data *d)
+{
+	struct its_vpe *vpe = irq_data_get_irq_chip_data(d);
+
+	if (gic_rdists->has_direct_lpi) {
+		void __iomem *rdbase;
+
+		rdbase = per_cpu_ptr(gic_rdists->rdist, vpe->col_idx)->rd_base;
+		gic_write_lpir(vpe->vpe_db_lpi, rdbase + GICR_INVLPIR);
+		while (gic_read_lpir(rdbase + GICR_SYNCR) & 1)
+			cpu_relax();
+	} else {
+		its_vpe_send_cmd(vpe, its_send_inv);
+	}
+}
+
+static void its_vpe_mask_irq(struct irq_data *d)
+{
+	/*
+	 * We need to unmask the LPI, which is described by the parent
+	 * irq_data. Instead of calling into the parent (which won't
+	 * exactly do the right thing, let's simply use the
+	 * parent_data pointer. Yes, I'm naughty.
+	 */
+	lpi_write_config(d->parent_data, LPI_PROP_ENABLED, 0);
+	its_vpe_send_inv(d);
+}
+
+static void its_vpe_unmask_irq(struct irq_data *d)
+{
+	/* Same hack as above... */
+	lpi_write_config(d->parent_data, 0, LPI_PROP_ENABLED);
+	its_vpe_send_inv(d);
+}
+
+static int its_vpe_set_irqchip_state(struct irq_data *d,
+				     enum irqchip_irq_state which,
+				     bool state)
+{
+	struct its_vpe *vpe = irq_data_get_irq_chip_data(d);
+
+	if (which != IRQCHIP_STATE_PENDING)
+		return -EINVAL;
+
+	if (gic_rdists->has_direct_lpi) {
+		void __iomem *rdbase;
+
+		rdbase = per_cpu_ptr(gic_rdists->rdist, vpe->col_idx)->rd_base;
+		if (state) {
+			gic_write_lpir(vpe->vpe_db_lpi, rdbase + GICR_SETLPIR);
+		} else {
+			gic_write_lpir(vpe->vpe_db_lpi, rdbase + GICR_CLRLPIR);
+			while (gic_read_lpir(rdbase + GICR_SYNCR) & 1)
+				cpu_relax();
+		}
+	} else {
+		if (state)
+			its_vpe_send_cmd(vpe, its_send_int);
+		else
+			its_vpe_send_cmd(vpe, its_send_clear);
+	}
+
+	return 0;
+}
+
+static struct irq_chip its_vpe_irq_chip = {
+	.name			= "GICv4-vpe",
+	.irq_mask		= its_vpe_mask_irq,
+	.irq_unmask		= its_vpe_unmask_irq,
+	.irq_eoi		= irq_chip_eoi_parent,
+	.irq_set_affinity	= its_vpe_set_affinity,
+	.irq_set_irqchip_state	= its_vpe_set_irqchip_state,
+	.irq_set_vcpu_affinity	= its_vpe_set_vcpu_affinity,
+};
+
+static int its_vpe_id_alloc(void)
+{
+	return ida_simple_get(&its_vpeid_ida, 0, ITS_MAX_VPEID, GFP_KERNEL);
+}
+
+static void its_vpe_id_free(u16 id)
+{
+	ida_simple_remove(&its_vpeid_ida, id);
+}
+
+static int its_vpe_init(struct its_vpe *vpe)
+{
+	struct page *vpt_page;
+	int vpe_id;
+
+	/* Allocate vpe_id */
+	vpe_id = its_vpe_id_alloc();
+	if (vpe_id < 0)
+		return vpe_id;
+
+	/* Allocate VPT */
+	vpt_page = its_allocate_pending_table(GFP_KERNEL);
+	if (!vpt_page) {
+		its_vpe_id_free(vpe_id);
+		return -ENOMEM;
+	}
+
+	if (!its_alloc_vpe_table(vpe_id)) {
+		its_vpe_id_free(vpe_id);
+		its_free_pending_table(vpe->vpt_page);
+		return -ENOMEM;
+	}
+
+	vpe->vpe_id = vpe_id;
+	vpe->vpt_page = vpt_page;
+	vpe->vpe_proxy_event = -1;
+
+	return 0;
+}
+
+static void its_vpe_teardown(struct its_vpe *vpe)
+{
+	its_vpe_db_proxy_unmap(vpe);
+	its_vpe_id_free(vpe->vpe_id);
+	its_free_pending_table(vpe->vpt_page);
+}
+
+static void its_vpe_irq_domain_free(struct irq_domain *domain,
+				    unsigned int virq,
+				    unsigned int nr_irqs)
+{
+	struct its_vm *vm = domain->host_data;
+	int i;
+
+	irq_domain_free_irqs_parent(domain, virq, nr_irqs);
+
+	for (i = 0; i < nr_irqs; i++) {
+		struct irq_data *data = irq_domain_get_irq_data(domain,
+								virq + i);
+		struct its_vpe *vpe = irq_data_get_irq_chip_data(data);
+
+		BUG_ON(vm != vpe->its_vm);
+
+		clear_bit(data->hwirq, vm->db_bitmap);
+		its_vpe_teardown(vpe);
+		irq_domain_reset_irq_data(data);
+	}
+
+	if (bitmap_empty(vm->db_bitmap, vm->nr_db_lpis)) {
+		its_lpi_free(vm->db_bitmap, vm->db_lpi_base, vm->nr_db_lpis);
+		its_free_prop_table(vm->vprop_page);
+	}
+}
+
+static int its_vpe_irq_domain_alloc(struct irq_domain *domain, unsigned int virq,
+				    unsigned int nr_irqs, void *args)
+{
+	struct its_vm *vm = args;
+	unsigned long *bitmap;
+	struct page *vprop_page;
+	int base, nr_ids, i, err = 0;
+
+	BUG_ON(!vm);
+
+	bitmap = its_lpi_alloc(roundup_pow_of_two(nr_irqs), &base, &nr_ids);
+	if (!bitmap)
+		return -ENOMEM;
+
+	if (nr_ids < nr_irqs) {
+		its_lpi_free(bitmap, base, nr_ids);
+		return -ENOMEM;
+	}
+
+	vprop_page = its_allocate_prop_table(GFP_KERNEL);
+	if (!vprop_page) {
+		its_lpi_free(bitmap, base, nr_ids);
+		return -ENOMEM;
+	}
+
+	vm->db_bitmap = bitmap;
+	vm->db_lpi_base = base;
+	vm->nr_db_lpis = nr_ids;
+	vm->vprop_page = vprop_page;
+
+	for (i = 0; i < nr_irqs; i++) {
+		vm->vpes[i]->vpe_db_lpi = base + i;
+		err = its_vpe_init(vm->vpes[i]);
+		if (err)
+			break;
+		err = its_irq_gic_domain_alloc(domain, virq + i,
+					       vm->vpes[i]->vpe_db_lpi);
+		if (err)
+			break;
+		irq_domain_set_hwirq_and_chip(domain, virq + i, i,
+					      &its_vpe_irq_chip, vm->vpes[i]);
+		set_bit(i, bitmap);
+	}
+
+	if (err) {
+		if (i > 0)
+			its_vpe_irq_domain_free(domain, virq, i - 1);
+
+		its_lpi_free(bitmap, base, nr_ids);
+		its_free_prop_table(vprop_page);
+	}
+
+	return err;
+}
+
+static int its_vpe_irq_domain_activate(struct irq_domain *domain,
+				       struct irq_data *d, bool reserve)
+{
+	struct its_vpe *vpe = irq_data_get_irq_chip_data(d);
+	struct its_node *its;
+
+	/* If we use the list map, we issue VMAPP on demand... */
+	if (its_list_map)
+		return 0;
+
+	/* Map the VPE to the first possible CPU */
+	vpe->col_idx = cpumask_first(cpu_online_mask);
+
+	list_for_each_entry(its, &its_nodes, entry) {
+		if (!its->is_v4)
+			continue;
+
+		its_send_vmapp(its, vpe, true);
+		its_send_vinvall(its, vpe);
+	}
+
+	irq_data_update_effective_affinity(d, cpumask_of(vpe->col_idx));
+
+	return 0;
+}
+
+static void its_vpe_irq_domain_deactivate(struct irq_domain *domain,
+					  struct irq_data *d)
+{
+	struct its_vpe *vpe = irq_data_get_irq_chip_data(d);
+	struct its_node *its;
+
+	/*
+	 * If we use the list map, we unmap the VPE once no VLPIs are
+	 * associated with the VM.
+	 */
+	if (its_list_map)
+		return;
+
+	list_for_each_entry(its, &its_nodes, entry) {
+		if (!its->is_v4)
+			continue;
+
+		its_send_vmapp(its, vpe, false);
+	}
+}
+
+static const struct irq_domain_ops its_vpe_domain_ops = {
+	.alloc			= its_vpe_irq_domain_alloc,
+	.free			= its_vpe_irq_domain_free,
+	.activate		= its_vpe_irq_domain_activate,
+	.deactivate		= its_vpe_irq_domain_deactivate,
+};
+
+static int its_force_quiescent(void __iomem *base)
+{
+	u32 count = 1000000;	/* 1s */
+	u32 val;
+
+	val = readl_relaxed(base + GITS_CTLR);
+	/*
+	 * GIC architecture specification requires the ITS to be both
+	 * disabled and quiescent for writes to GITS_BASER<n> or
+	 * GITS_CBASER to not have UNPREDICTABLE results.
+	 */
+	if ((val & GITS_CTLR_QUIESCENT) && !(val & GITS_CTLR_ENABLE))
+		return 0;
+
+	/* Disable the generation of all interrupts to this ITS */
+	val &= ~(GITS_CTLR_ENABLE | GITS_CTLR_ImDe);
+	writel_relaxed(val, base + GITS_CTLR);
+
+	/* Poll GITS_CTLR and wait until ITS becomes quiescent */
+	while (1) {
+		val = readl_relaxed(base + GITS_CTLR);
+		if (val & GITS_CTLR_QUIESCENT)
+			return 0;
+
+		count--;
+		if (!count)
+			return -EBUSY;
+
+		cpu_relax();
+		udelay(1);
+	}
+}
+
+static bool __maybe_unused its_enable_quirk_cavium_22375(void *data)
+{
+	struct its_node *its = data;
+
+	/* erratum 22375: only alloc 8MB table size */
+	its->device_ids = 0x14;		/* 20 bits, 8MB */
+	its->flags |= ITS_FLAGS_WORKAROUND_CAVIUM_22375;
+
+	return true;
+}
+
+static bool __maybe_unused its_enable_quirk_cavium_23144(void *data)
+{
+	struct its_node *its = data;
+
+	its->flags |= ITS_FLAGS_WORKAROUND_CAVIUM_23144;
+
+	return true;
+}
+
+static bool __maybe_unused its_enable_quirk_qdf2400_e0065(void *data)
+{
+	struct its_node *its = data;
+
+	/* On QDF2400, the size of the ITE is 16Bytes */
+	its->ite_size = 16;
+
+	return true;
+}
+
+static u64 its_irq_get_msi_base_pre_its(struct its_device *its_dev)
+{
+	struct its_node *its = its_dev->its;
+
+	/*
+	 * The Socionext Synquacer SoC has a so-called 'pre-ITS',
+	 * which maps 32-bit writes targeted at a separate window of
+	 * size '4 << device_id_bits' onto writes to GITS_TRANSLATER
+	 * with device ID taken from bits [device_id_bits + 1:2] of
+	 * the window offset.
+	 */
+	return its->pre_its_base + (its_dev->device_id << 2);
+}
+
+static bool __maybe_unused its_enable_quirk_socionext_synquacer(void *data)
+{
+	struct its_node *its = data;
+	u32 pre_its_window[2];
+	u32 ids;
+
+	if (!fwnode_property_read_u32_array(its->fwnode_handle,
+					   "socionext,synquacer-pre-its",
+					   pre_its_window,
+					   ARRAY_SIZE(pre_its_window))) {
+
+		its->pre_its_base = pre_its_window[0];
+		its->get_msi_base = its_irq_get_msi_base_pre_its;
+
+		ids = ilog2(pre_its_window[1]) - 2;
+		if (its->device_ids > ids)
+			its->device_ids = ids;
+
+		/* the pre-ITS breaks isolation, so disable MSI remapping */
+		its->msi_domain_flags &= ~IRQ_DOMAIN_FLAG_MSI_REMAP;
+		return true;
+	}
+	return false;
+}
+
+static bool __maybe_unused its_enable_quirk_hip07_161600802(void *data)
+{
+	struct its_node *its = data;
+
+	/*
+	 * Hip07 insists on using the wrong address for the VLPI
+	 * page. Trick it into doing the right thing...
+	 */
+	its->vlpi_redist_offset = SZ_128K;
+	return true;
+}
+
+static const struct gic_quirk its_quirks[] = {
+#ifdef CONFIG_CAVIUM_ERRATUM_22375
+	{
+		.desc	= "ITS: Cavium errata 22375, 24313",
+		.iidr	= 0xa100034c,	/* ThunderX pass 1.x */
+		.mask	= 0xffff0fff,
+		.init	= its_enable_quirk_cavium_22375,
+	},
+#endif
+#ifdef CONFIG_CAVIUM_ERRATUM_23144
+	{
+		.desc	= "ITS: Cavium erratum 23144",
+		.iidr	= 0xa100034c,	/* ThunderX pass 1.x */
+		.mask	= 0xffff0fff,
+		.init	= its_enable_quirk_cavium_23144,
+	},
+#endif
+#ifdef CONFIG_QCOM_QDF2400_ERRATUM_0065
+	{
+		.desc	= "ITS: QDF2400 erratum 0065",
+		.iidr	= 0x00001070, /* QDF2400 ITS rev 1.x */
+		.mask	= 0xffffffff,
+		.init	= its_enable_quirk_qdf2400_e0065,
+	},
+#endif
+#ifdef CONFIG_SOCIONEXT_SYNQUACER_PREITS
+	{
+		/*
+		 * The Socionext Synquacer SoC incorporates ARM's own GIC-500
+		 * implementation, but with a 'pre-ITS' added that requires
+		 * special handling in software.
+		 */
+		.desc	= "ITS: Socionext Synquacer pre-ITS",
+		.iidr	= 0x0001143b,
+		.mask	= 0xffffffff,
+		.init	= its_enable_quirk_socionext_synquacer,
+	},
+#endif
+#ifdef CONFIG_HISILICON_ERRATUM_161600802
+	{
+		.desc	= "ITS: Hip07 erratum 161600802",
+		.iidr	= 0x00000004,
+		.mask	= 0xffffffff,
+		.init	= its_enable_quirk_hip07_161600802,
+	},
+#endif
+	{
+	}
+};
+
+static void its_enable_quirks(struct its_node *its)
+{
+	u32 iidr = readl_relaxed(its->base + GITS_IIDR);
+
+	gic_enable_quirks(iidr, its_quirks, its);
+}
+
+static int its_save_disable(void)
+{
+	struct its_node *its;
+	int err = 0;
+
+	raw_spin_lock(&its_lock);
+	list_for_each_entry(its, &its_nodes, entry) {
+		void __iomem *base;
+
+		if (!(its->flags & ITS_FLAGS_SAVE_SUSPEND_STATE))
+			continue;
+
+		base = its->base;
+		its->ctlr_save = readl_relaxed(base + GITS_CTLR);
+		err = its_force_quiescent(base);
+		if (err) {
+			pr_err("ITS@%pa: failed to quiesce: %d\n",
+			       &its->phys_base, err);
+			writel_relaxed(its->ctlr_save, base + GITS_CTLR);
+			goto err;
+		}
+
+		its->cbaser_save = gits_read_cbaser(base + GITS_CBASER);
+	}
+
+err:
+	if (err) {
+		list_for_each_entry_continue_reverse(its, &its_nodes, entry) {
+			void __iomem *base;
+
+			if (!(its->flags & ITS_FLAGS_SAVE_SUSPEND_STATE))
+				continue;
+
+			base = its->base;
+			writel_relaxed(its->ctlr_save, base + GITS_CTLR);
+		}
+	}
+	raw_spin_unlock(&its_lock);
+
+	return err;
+}
+
+static void its_restore_enable(void)
+{
+	struct its_node *its;
+	int ret;
+
+	raw_spin_lock(&its_lock);
+	list_for_each_entry(its, &its_nodes, entry) {
+		void __iomem *base;
+		int i;
+
+		if (!(its->flags & ITS_FLAGS_SAVE_SUSPEND_STATE))
+			continue;
+
+		base = its->base;
+
+		/*
+		 * Make sure that the ITS is disabled. If it fails to quiesce,
+		 * don't restore it since writing to CBASER or BASER<n>
+		 * registers is undefined according to the GIC v3 ITS
+		 * Specification.
+		 */
+		ret = its_force_quiescent(base);
+		if (ret) {
+			pr_err("ITS@%pa: failed to quiesce on resume: %d\n",
+			       &its->phys_base, ret);
+			continue;
+		}
+
+		gits_write_cbaser(its->cbaser_save, base + GITS_CBASER);
+
+		/*
+		 * Writing CBASER resets CREADR to 0, so make CWRITER and
+		 * cmd_write line up with it.
+		 */
+		its->cmd_write = its->cmd_base;
+		gits_write_cwriter(0, base + GITS_CWRITER);
+
+		/* Restore GITS_BASER from the value cache. */
+		for (i = 0; i < GITS_BASER_NR_REGS; i++) {
+			struct its_baser *baser = &its->tables[i];
+
+			if (!(baser->val & GITS_BASER_VALID))
+				continue;
+
+			its_write_baser(its, baser, baser->val);
+		}
+		writel_relaxed(its->ctlr_save, base + GITS_CTLR);
+
+		/*
+		 * Reinit the collection if it's stored in the ITS. This is
+		 * indicated by the col_id being less than the HCC field.
+		 * CID < HCC as specified in the GIC v3 Documentation.
+		 */
+		if (its->collections[smp_processor_id()].col_id <
+		    GITS_TYPER_HCC(gic_read_typer(base + GITS_TYPER)))
+			its_cpu_init_collection(its);
+	}
+	raw_spin_unlock(&its_lock);
+}
+
+static struct syscore_ops its_syscore_ops = {
+	.suspend = its_save_disable,
+	.resume = its_restore_enable,
+};
+
+static int its_init_domain(struct fwnode_handle *handle, struct its_node *its)
+{
+	struct irq_domain *inner_domain;
+	struct msi_domain_info *info;
+
+	info = kzalloc(sizeof(*info), GFP_KERNEL);
+	if (!info)
+		return -ENOMEM;
+
+	inner_domain = irq_domain_create_tree(handle, &its_domain_ops, its);
+	if (!inner_domain) {
+		kfree(info);
+		return -ENOMEM;
+	}
+
+	inner_domain->parent = its_parent;
+	irq_domain_update_bus_token(inner_domain, DOMAIN_BUS_NEXUS);
+	inner_domain->flags |= its->msi_domain_flags;
+	info->ops = &its_msi_domain_ops;
+	info->data = its;
+	inner_domain->host_data = info;
+
+	return 0;
+}
+
+static int its_init_vpe_domain(void)
+{
+	struct its_node *its;
+	u32 devid;
+	int entries;
+
+	if (gic_rdists->has_direct_lpi) {
+		pr_info("ITS: Using DirectLPI for VPE invalidation\n");
+		return 0;
+	}
+
+	/* Any ITS will do, even if not v4 */
+	its = list_first_entry(&its_nodes, struct its_node, entry);
+
+	entries = roundup_pow_of_two(nr_cpu_ids);
+	vpe_proxy.vpes = kcalloc(entries, sizeof(*vpe_proxy.vpes),
+				 GFP_KERNEL);
+	if (!vpe_proxy.vpes) {
+		pr_err("ITS: Can't allocate GICv4 proxy device array\n");
+		return -ENOMEM;
+	}
+
+	/* Use the last possible DevID */
+	devid = GENMASK(its->device_ids - 1, 0);
+	vpe_proxy.dev = its_create_device(its, devid, entries, false);
+	if (!vpe_proxy.dev) {
+		kfree(vpe_proxy.vpes);
+		pr_err("ITS: Can't allocate GICv4 proxy device\n");
+		return -ENOMEM;
+	}
+
+	BUG_ON(entries > vpe_proxy.dev->nr_ites);
+
+	raw_spin_lock_init(&vpe_proxy.lock);
+	vpe_proxy.next_victim = 0;
+	pr_info("ITS: Allocated DevID %x as GICv4 proxy device (%d slots)\n",
+		devid, vpe_proxy.dev->nr_ites);
+
+	return 0;
+}
+
+static int __init its_compute_its_list_map(struct resource *res,
+					   void __iomem *its_base)
+{
+	int its_number;
+	u32 ctlr;
+
+	/*
+	 * This is assumed to be done early enough that we're
+	 * guaranteed to be single-threaded, hence no
+	 * locking. Should this change, we should address
+	 * this.
+	 */
+	its_number = find_first_zero_bit(&its_list_map, GICv4_ITS_LIST_MAX);
+	if (its_number >= GICv4_ITS_LIST_MAX) {
+		pr_err("ITS@%pa: No ITSList entry available!\n",
+		       &res->start);
+		return -EINVAL;
+	}
+
+	ctlr = readl_relaxed(its_base + GITS_CTLR);
+	ctlr &= ~GITS_CTLR_ITS_NUMBER;
+	ctlr |= its_number << GITS_CTLR_ITS_NUMBER_SHIFT;
+	writel_relaxed(ctlr, its_base + GITS_CTLR);
+	ctlr = readl_relaxed(its_base + GITS_CTLR);
+	if ((ctlr & GITS_CTLR_ITS_NUMBER) != (its_number << GITS_CTLR_ITS_NUMBER_SHIFT)) {
+		its_number = ctlr & GITS_CTLR_ITS_NUMBER;
+		its_number >>= GITS_CTLR_ITS_NUMBER_SHIFT;
+	}
+
+	if (test_and_set_bit(its_number, &its_list_map)) {
+		pr_err("ITS@%pa: Duplicate ITSList entry %d\n",
+		       &res->start, its_number);
+		return -EINVAL;
+	}
+
+	return its_number;
+}
+
+static int __init its_probe_one(struct resource *res,
+				struct fwnode_handle *handle, int numa_node)
+{
+	struct its_node *its;
+	void __iomem *its_base;
+	u32 val, ctlr;
+	u64 baser, tmp, typer;
+	int err;
+
+	its_base = ioremap(res->start, resource_size(res));
+	if (!its_base) {
+		pr_warn("ITS@%pa: Unable to map ITS registers\n", &res->start);
+		return -ENOMEM;
+	}
+
+	val = readl_relaxed(its_base + GITS_PIDR2) & GIC_PIDR2_ARCH_MASK;
+	if (val != 0x30 && val != 0x40) {
+		pr_warn("ITS@%pa: No ITS detected, giving up\n", &res->start);
+		err = -ENODEV;
+		goto out_unmap;
+	}
+
+	err = its_force_quiescent(its_base);
+	if (err) {
+		pr_warn("ITS@%pa: Failed to quiesce, giving up\n", &res->start);
+		goto out_unmap;
+	}
+
+	pr_info("ITS %pR\n", res);
+
+	its = kzalloc(sizeof(*its), GFP_KERNEL);
+	if (!its) {
+		err = -ENOMEM;
+		goto out_unmap;
+	}
+
+	raw_spin_lock_init(&its->lock);
+	INIT_LIST_HEAD(&its->entry);
+	INIT_LIST_HEAD(&its->its_device_list);
+	typer = gic_read_typer(its_base + GITS_TYPER);
+	its->base = its_base;
+	its->phys_base = res->start;
+	its->ite_size = GITS_TYPER_ITT_ENTRY_SIZE(typer);
+	its->device_ids = GITS_TYPER_DEVBITS(typer);
+	its->is_v4 = !!(typer & GITS_TYPER_VLPIS);
+	if (its->is_v4) {
+		if (!(typer & GITS_TYPER_VMOVP)) {
+			err = its_compute_its_list_map(res, its_base);
+			if (err < 0)
+				goto out_free_its;
+
+			its->list_nr = err;
+
+			pr_info("ITS@%pa: Using ITS number %d\n",
+				&res->start, err);
+		} else {
+			pr_info("ITS@%pa: Single VMOVP capable\n", &res->start);
+		}
+	}
+
+	its->numa_node = numa_node;
+
+	its->cmd_base = (void *)__get_free_pages(GFP_KERNEL | __GFP_ZERO,
+						get_order(ITS_CMD_QUEUE_SZ));
+	if (!its->cmd_base) {
+		err = -ENOMEM;
+		goto out_free_its;
+	}
+	its->cmd_write = its->cmd_base;
+	its->fwnode_handle = handle;
+	its->get_msi_base = its_irq_get_msi_base;
+	its->msi_domain_flags = IRQ_DOMAIN_FLAG_MSI_REMAP;
+
+	its_enable_quirks(its);
+
+	err = its_alloc_tables(its);
+	if (err)
+		goto out_free_cmd;
+
+	err = its_alloc_collections(its);
+	if (err)
+		goto out_free_tables;
+
+	baser = (virt_to_phys(its->cmd_base)	|
+		 GITS_CBASER_RaWaWb		|
+		 GITS_CBASER_InnerShareable	|
+		 (ITS_CMD_QUEUE_SZ / SZ_4K - 1)	|
+		 GITS_CBASER_VALID);
+
+	gits_write_cbaser(baser, its->base + GITS_CBASER);
+	tmp = gits_read_cbaser(its->base + GITS_CBASER);
+
+	if ((tmp ^ baser) & GITS_CBASER_SHAREABILITY_MASK) {
+		if (!(tmp & GITS_CBASER_SHAREABILITY_MASK)) {
+			/*
+			 * The HW reports non-shareable, we must
+			 * remove the cacheability attributes as
+			 * well.
+			 */
+			baser &= ~(GITS_CBASER_SHAREABILITY_MASK |
+				   GITS_CBASER_CACHEABILITY_MASK);
+			baser |= GITS_CBASER_nC;
+			gits_write_cbaser(baser, its->base + GITS_CBASER);
+		}
+		pr_info("ITS: using cache flushing for cmd queue\n");
+		its->flags |= ITS_FLAGS_CMDQ_NEEDS_FLUSHING;
+	}
+
+	gits_write_cwriter(0, its->base + GITS_CWRITER);
+	ctlr = readl_relaxed(its->base + GITS_CTLR);
+	ctlr |= GITS_CTLR_ENABLE;
+	if (its->is_v4)
+		ctlr |= GITS_CTLR_ImDe;
+	writel_relaxed(ctlr, its->base + GITS_CTLR);
+
+	if (GITS_TYPER_HCC(typer))
+		its->flags |= ITS_FLAGS_SAVE_SUSPEND_STATE;
+
+	err = its_init_domain(handle, its);
+	if (err)
+		goto out_free_tables;
+
+	raw_spin_lock(&its_lock);
+	list_add(&its->entry, &its_nodes);
+	raw_spin_unlock(&its_lock);
+
+	return 0;
+
+out_free_tables:
+	its_free_tables(its);
+out_free_cmd:
+	free_pages((unsigned long)its->cmd_base, get_order(ITS_CMD_QUEUE_SZ));
+out_free_its:
+	kfree(its);
+out_unmap:
+	iounmap(its_base);
+	pr_err("ITS@%pa: failed probing (%d)\n", &res->start, err);
+	return err;
+}
+
+static bool gic_rdists_supports_plpis(void)
+{
+	return !!(gic_read_typer(gic_data_rdist_rd_base() + GICR_TYPER) & GICR_TYPER_PLPIS);
+}
+
+static int redist_disable_lpis(void)
+{
+	void __iomem *rbase = gic_data_rdist_rd_base();
+	u64 timeout = USEC_PER_SEC;
+	u64 val;
+
+	/*
+	 * If coming via a CPU hotplug event, we don't need to disable
+	 * LPIs before trying to re-enable them. They are already
+	 * configured and all is well in the world. Detect this case
+	 * by checking the allocation of the pending table for the
+	 * current CPU.
+	 */
+	if (gic_data_rdist()->pend_page)
+		return 0;
+
+	if (!gic_rdists_supports_plpis()) {
+		pr_info("CPU%d: LPIs not supported\n", smp_processor_id());
+		return -ENXIO;
+	}
+
+	val = readl_relaxed(rbase + GICR_CTLR);
+	if (!(val & GICR_CTLR_ENABLE_LPIS))
+		return 0;
+
+	pr_warn("CPU%d: Booted with LPIs enabled, memory probably corrupted\n",
+		smp_processor_id());
+	add_taint(TAINT_CRAP, LOCKDEP_STILL_OK);
+
+	/* Disable LPIs */
+	val &= ~GICR_CTLR_ENABLE_LPIS;
+	writel_relaxed(val, rbase + GICR_CTLR);
+
+	/* Make sure any change to GICR_CTLR is observable by the GIC */
+	dsb(sy);
+
+	/*
+	 * Software must observe RWP==0 after clearing GICR_CTLR.EnableLPIs
+	 * from 1 to 0 before programming GICR_PEND{PROP}BASER registers.
+	 * Error out if we time out waiting for RWP to clear.
+	 */
+	while (readl_relaxed(rbase + GICR_CTLR) & GICR_CTLR_RWP) {
+		if (!timeout) {
+			pr_err("CPU%d: Timeout while disabling LPIs\n",
+			       smp_processor_id());
+			return -ETIMEDOUT;
+		}
+		udelay(1);
+		timeout--;
+	}
+
+	/*
+	 * After it has been written to 1, it is IMPLEMENTATION
+	 * DEFINED whether GICR_CTLR.EnableLPI becomes RES1 or can be
+	 * cleared to 0. Error out if clearing the bit failed.
+	 */
+	if (readl_relaxed(rbase + GICR_CTLR) & GICR_CTLR_ENABLE_LPIS) {
+		pr_err("CPU%d: Failed to disable LPIs\n", smp_processor_id());
+		return -EBUSY;
+	}
+
+	return 0;
+}
+
+int phytium_its_cpu_init(void)
+{
+	if (!list_empty(&its_nodes)) {
+		int ret;
+
+		ret = redist_disable_lpis();
+		if (ret)
+			return ret;
+
+		its_cpu_init_lpis();
+		its_cpu_init_collections();
+	}
+
+	return 0;
+}
+
+static const struct of_device_id its_device_id[] = {
+	{	.compatible	= "arm,gic-v3-its",	},
+	{},
+};
+
+static int __init its_of_probe(struct device_node *node)
+{
+	struct device_node *np;
+	struct resource res;
+
+	for (np = of_find_matching_node(node, its_device_id); np;
+	     np = of_find_matching_node(np, its_device_id)) {
+		if (!of_device_is_available(np))
+			continue;
+		if (!of_property_read_bool(np, "msi-controller")) {
+			pr_warn("%pOF: no msi-controller property, ITS ignored\n",
+				np);
+			continue;
+		}
+
+		if (of_address_to_resource(np, 0, &res)) {
+			pr_warn("%pOF: no regs?\n", np);
+			continue;
+		}
+
+		its_probe_one(&res, &np->fwnode, of_node_to_nid(np));
+	}
+	return 0;
+}
+
+#ifdef CONFIG_ACPI
+
+#define ACPI_GICV3_ITS_MEM_SIZE (SZ_128K)
+
+#ifdef CONFIG_ACPI_NUMA
+struct its_srat_map {
+	/* numa node id */
+	u32	numa_node;
+	/* GIC ITS ID */
+	u32	its_id;
+};
+
+static struct its_srat_map *its_srat_maps __initdata;
+static int its_in_srat __initdata;
+
+static int __init acpi_get_its_numa_node(u32 its_id)
+{
+	int i;
+
+	for (i = 0; i < its_in_srat; i++) {
+		if (its_id == its_srat_maps[i].its_id)
+			return its_srat_maps[i].numa_node;
+	}
+	return NUMA_NO_NODE;
+}
+
+static int __init gic_acpi_match_srat_its(struct acpi_subtable_header *header,
+					  const unsigned long end)
+{
+	return 0;
+}
+
+static int __init gic_acpi_parse_srat_its(struct acpi_subtable_header *header,
+			 const unsigned long end)
+{
+	int node;
+	struct acpi_srat_gic_its_affinity *its_affinity;
+
+	its_affinity = (struct acpi_srat_gic_its_affinity *)header;
+	if (!its_affinity)
+		return -EINVAL;
+
+	if (its_affinity->header.length < sizeof(*its_affinity)) {
+		pr_err("SRAT: Invalid header length %d in ITS affinity\n",
+			its_affinity->header.length);
+		return -EINVAL;
+	}
+
+	node = acpi_map_pxm_to_node(its_affinity->proximity_domain);
+
+	if (node == NUMA_NO_NODE || node >= MAX_NUMNODES) {
+		pr_err("SRAT: Invalid NUMA node %d in ITS affinity\n", node);
+		return 0;
+	}
+
+	its_srat_maps[its_in_srat].numa_node = node;
+	its_srat_maps[its_in_srat].its_id = its_affinity->its_id;
+	its_in_srat++;
+	pr_info("SRAT: PXM %d -> ITS %d -> Node %d\n",
+		its_affinity->proximity_domain, its_affinity->its_id, node);
+
+	return 0;
+}
+
+static void __init acpi_table_parse_srat_its(void)
+{
+	int count;
+
+	count = acpi_table_parse_entries(ACPI_SIG_SRAT,
+			sizeof(struct acpi_table_srat),
+			ACPI_SRAT_TYPE_GIC_ITS_AFFINITY,
+			gic_acpi_match_srat_its, 0);
+	if (count <= 0)
+		return;
+
+	its_srat_maps = kmalloc_array(count, sizeof(struct its_srat_map),
+				      GFP_KERNEL);
+	if (!its_srat_maps) {
+		pr_warn("SRAT: Failed to allocate memory for its_srat_maps!\n");
+		return;
+	}
+
+	acpi_table_parse_entries(ACPI_SIG_SRAT,
+			sizeof(struct acpi_table_srat),
+			ACPI_SRAT_TYPE_GIC_ITS_AFFINITY,
+			gic_acpi_parse_srat_its, 0);
+}
+
+/* free the its_srat_maps after ITS probing */
+static void __init acpi_its_srat_maps_free(void)
+{
+	kfree(its_srat_maps);
+}
+#else
+static void __init acpi_table_parse_srat_its(void)	{ }
+static int __init acpi_get_its_numa_node(u32 its_id) { return NUMA_NO_NODE; }
+static void __init acpi_its_srat_maps_free(void) { }
+#endif
+
+static int __init gic_acpi_parse_madt_its(struct acpi_subtable_header *header,
+					  const unsigned long end)
+{
+	struct acpi_madt_generic_translator *its_entry;
+	struct fwnode_handle *dom_handle;
+	struct resource res;
+	int err;
+
+	its_entry = (struct acpi_madt_generic_translator *)header;
+	memset(&res, 0, sizeof(res));
+	res.start = its_entry->base_address;
+	res.end = its_entry->base_address + ACPI_GICV3_ITS_MEM_SIZE - 1;
+	res.flags = IORESOURCE_MEM;
+
+	dom_handle = irq_domain_alloc_fwnode((void *)its_entry->base_address);
+	if (!dom_handle) {
+		pr_err("ITS@%pa: Unable to allocate GIC-Phytium-2500 ITS domain token\n",
+		       &res.start);
+		return -ENOMEM;
+	}
+
+	err = iort_register_domain_token(its_entry->translation_id, res.start,
+					 dom_handle);
+	if (err) {
+		pr_err("ITS@%pa: Unable to register GIC-Phytium-2500 ITS domain token (ITS ID %d) to IORT\n",
+		       &res.start, its_entry->translation_id);
+		goto dom_err;
+	}
+
+	err = its_probe_one(&res, dom_handle,
+			acpi_get_its_numa_node(its_entry->translation_id));
+	if (!err)
+		return 0;
+
+	iort_deregister_domain_token(its_entry->translation_id);
+dom_err:
+	irq_domain_free_fwnode(dom_handle);
+	return err;
+}
+
+static void __init its_acpi_probe(void)
+{
+	acpi_table_parse_srat_its();
+	acpi_table_parse_madt(ACPI_MADT_TYPE_GENERIC_TRANSLATOR,
+			      gic_acpi_parse_madt_its, 0);
+	acpi_its_srat_maps_free();
+}
+#else
+static void __init its_acpi_probe(void) { }
+#endif
+
+int __init phytium_its_init(struct fwnode_handle *handle, struct rdists *rdists,
+		    struct irq_domain *parent_domain)
+{
+	struct device_node *of_node;
+	struct its_node *its;
+	bool has_v4 = false;
+	int err;
+
+	its_parent = parent_domain;
+	of_node = to_of_node(handle);
+	if (of_node)
+		its_of_probe(of_node);
+	else
+		its_acpi_probe();
+
+	if (list_empty(&its_nodes)) {
+		pr_warn("ITS: No ITS available, not enabling LPIs\n");
+		return -ENXIO;
+	}
+
+	gic_rdists = rdists;
+	err = its_alloc_lpi_tables();
+	if (err)
+		return err;
+
+	list_for_each_entry(its, &its_nodes, entry)
+		has_v4 |= its->is_v4;
+
+	if (has_v4 & rdists->has_vlpis) {
+		if (its_init_vpe_domain() ||
+		    its_init_v4(parent_domain, &its_vpe_domain_ops)) {
+			rdists->has_vlpis = false;
+			pr_err("ITS: Disabling GICv4 support\n");
+		}
+	}
+
+	register_syscore_ops(&its_syscore_ops);
+
+	return 0;
+}
diff --git a/drivers/irqchip/irq-gic-phytium-2500.c b/drivers/irqchip/irq-gic-phytium-2500.c
new file mode 100644
index 000000000000..197a739089bd
--- /dev/null
+++ b/drivers/irqchip/irq-gic-phytium-2500.c
@@ -0,0 +1,1864 @@
+/*
+ * Copyright (C) 2020 Phytium Corporation.
+ * Author: Wang Yinfeng <wangyinfeng@phytium.com.cn>
+ *         Chen Baozi <chenbaozi@phytium.com.cn>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#define pr_fmt(fmt)	"GIC-2500: " fmt
+
+#include <linux/acpi.h>
+#include <linux/cpu.h>
+#include <linux/cpu_pm.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/irqdomain.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/percpu.h>
+#include <linux/slab.h>
+
+#include <linux/irqchip.h>
+#include <linux/irqchip/arm-gic-common.h>
+#include <linux/irqchip/arm-gic-phytium-2500.h>
+#include <linux/irqchip/irq-partition-percpu.h>
+
+#include <asm/cputype.h>
+#include <asm/exception.h>
+#include <asm/smp_plat.h>
+#include <asm/virt.h>
+
+#include "irq-gic-common.h"
+
+#define MAX_MARS3_SOC_COUNT	8
+#define MARS3_ADDR_SKTID_SHIFT	41
+
+struct gic_dist_desc {
+	void __iomem		*dist_base;
+	phys_addr_t		phys_base;
+	unsigned long		size;
+};
+
+struct redist_region {
+	void __iomem		*redist_base;
+	phys_addr_t		phys_base;
+	bool			single_redist;
+};
+
+static struct gic_dist_desc mars3_gic_dists[MAX_MARS3_SOC_COUNT] __read_mostly;
+
+static unsigned int mars3_sockets_bitmap = 0x1;
+
+#define mars3_irq_to_skt(hwirq)	(((hwirq) - 32) % 8)
+
+struct gic_chip_data {
+	struct fwnode_handle	*fwnode;
+	void __iomem		*dist_base;
+	struct redist_region	*redist_regions;
+	struct rdists		rdists;
+	struct irq_domain	*domain;
+	u64			redist_stride;
+	u32			nr_redist_regions;
+	bool			has_rss;
+	unsigned int		irq_nr;
+	struct partition_desc	*ppi_descs[16];
+};
+
+static struct gic_chip_data gic_data __read_mostly;
+static DEFINE_STATIC_KEY_TRUE(supports_deactivate_key);
+
+static struct gic_kvm_info gic_v3_kvm_info;
+static DEFINE_PER_CPU(bool, has_rss);
+
+#define MPIDR_RS(mpidr)			(((mpidr) & 0xF0UL) >> 4)
+#define gic_data_rdist()		(this_cpu_ptr(gic_data.rdists.rdist))
+#define gic_data_rdist_rd_base()	(gic_data_rdist()->rd_base)
+#define gic_data_rdist_sgi_base()	(gic_data_rdist_rd_base() + SZ_64K)
+
+/* Our default, arbitrary priority value. Linux only uses one anyway. */
+#define DEFAULT_PMR_VALUE	0xf0
+
+static inline unsigned int gic_irq(struct irq_data *d)
+{
+	return d->hwirq;
+}
+
+static inline int gic_irq_in_rdist(struct irq_data *d)
+{
+	return gic_irq(d) < 32;
+}
+
+static inline void __iomem *gic_dist_base(struct irq_data *d)
+{
+	if (gic_irq_in_rdist(d))	/* SGI+PPI -> SGI_base for this CPU */
+		return gic_data_rdist_sgi_base();
+
+	if (d->hwirq <= 1023)		/* SPI -> dist_base */
+		return gic_data.dist_base;
+
+	return NULL;
+}
+
+static void gic_do_wait_for_rwp(void __iomem *base)
+{
+	u32 count = 1000000;	/* 1s! */
+
+	while (readl_relaxed(base + GICD_CTLR) & GICD_CTLR_RWP) {
+		count--;
+		if (!count) {
+			pr_err_ratelimited("RWP timeout, gone fishing\n");
+			return;
+		}
+		cpu_relax();
+		udelay(1);
+	};
+}
+
+/* Wait for completion of a distributor change */
+static void gic_dist_wait_for_rwp(void)
+{
+	gic_do_wait_for_rwp(gic_data.dist_base);
+}
+
+/* Wait for completion of a redistributor change */
+static void gic_redist_wait_for_rwp(void)
+{
+	gic_do_wait_for_rwp(gic_data_rdist_rd_base());
+}
+
+#ifdef CONFIG_ARM64
+
+static u64 __maybe_unused gic_read_iar(void)
+{
+	if (cpus_have_const_cap(ARM64_WORKAROUND_CAVIUM_23154))
+		return gic_read_iar_cavium_thunderx();
+	else
+		return gic_read_iar_common();
+}
+#endif
+
+static void gic_enable_redist(bool enable)
+{
+	void __iomem *rbase;
+	u32 count = 1000000;	/* 1s! */
+	u32 val;
+	unsigned long mpidr;
+	int i;
+
+	rbase = gic_data_rdist_rd_base();
+
+	val = readl_relaxed(rbase + GICR_WAKER);
+	if (enable)
+		/* Wake up this CPU redistributor */
+		val &= ~GICR_WAKER_ProcessorSleep;
+	else
+		val |= GICR_WAKER_ProcessorSleep;
+	writel_relaxed(val, rbase + GICR_WAKER);
+
+	if (!enable) {		/* Check that GICR_WAKER is writeable */
+		val = readl_relaxed(rbase + GICR_WAKER);
+		if (!(val & GICR_WAKER_ProcessorSleep))
+			return;	/* No PM support in this redistributor */
+	}
+
+	while (--count) {
+		val = readl_relaxed(rbase + GICR_WAKER);
+		if (enable ^ (bool)(val & GICR_WAKER_ChildrenAsleep))
+			break;
+		cpu_relax();
+		udelay(1);
+	};
+	if (!count)
+		pr_err_ratelimited("redistributor failed to %s...\n",
+				   enable ? "wakeup" : "sleep");
+
+	mpidr = (unsigned long)cpu_logical_map(smp_processor_id());
+
+	/* Either Aff0 or Aff1 is not zero */
+	if (mpidr & 0xffff)
+		return;
+
+	/* Skip 64 Redistributors */
+	rbase = rbase + 64 * SZ_128K;
+
+	for (i = 0; i < 4; i++) {
+		val = readl_relaxed(rbase + GICR_WAKER);
+		if (enable)
+			val &= ~GICR_WAKER_ProcessorSleep;
+		else
+			val |= GICR_WAKER_ProcessorSleep;
+		writel_relaxed(val, rbase + GICR_WAKER);
+
+		if (!enable) {
+			val = readl_relaxed(rbase + GICR_WAKER);
+			if (!(val & GICR_WAKER_ProcessorSleep))
+				return;
+		}
+
+		count = 1000000;    /* 1s! */
+		while (--count) {
+			val = readl_relaxed(rbase + GICR_WAKER);
+			if (enable ^ (bool)(val & GICR_WAKER_ChildrenAsleep))
+				break;
+			cpu_relax();
+			udelay(1);
+		};
+
+		if (!count)
+			pr_err_ratelimited("CPU MPIDR 0x%lx: redistributor %d failed to %s...\n",
+					   mpidr, 64 + i, enable ? "wakeup" : "sleep");
+
+		rbase = rbase + SZ_128K;
+	}
+}
+
+/*
+ * Routines to disable, enable, EOI and route interrupts
+ */
+static int gic_peek_irq(struct irq_data *d, u32 offset)
+{
+	u32 mask = 1 << (gic_irq(d) % 32);
+	void __iomem *base;
+	unsigned int skt;
+
+	if (gic_irq_in_rdist(d))
+		base = gic_data_rdist_sgi_base();
+	else {
+		skt = mars3_irq_to_skt(gic_irq(d));
+		base = mars3_gic_dists[skt].dist_base;
+	}
+
+	return !!(readl_relaxed(base + offset + (gic_irq(d) / 32) * 4) & mask);
+}
+
+static void gic_poke_irq(struct irq_data *d, u32 offset)
+{
+	u32 mask = 1 << (gic_irq(d) % 32);
+	void __iomem *base;
+	unsigned long mpidr;
+	void __iomem *rbase;
+	int i;
+	unsigned int skt;
+
+	if (gic_irq_in_rdist(d)) {
+		base = gic_data_rdist_sgi_base();
+
+		writel_relaxed(mask, base + offset + (gic_irq(d) / 32) * 4);
+		gic_redist_wait_for_rwp();
+
+		mpidr = (unsigned long)cpu_logical_map(smp_processor_id());
+
+		if ((mpidr & 0xffff) == 0) {
+			rbase = base + 64*SZ_128K;
+
+			for (i = 0; i < 4; i++) {
+				writel_relaxed(mask, rbase + offset + (gic_irq(d) / 32) * 4);
+				gic_do_wait_for_rwp(rbase - SZ_64K);
+				rbase = rbase + SZ_128K;
+			}
+		}
+	} else {
+		skt = mars3_irq_to_skt(gic_irq(d));
+		base = mars3_gic_dists[skt].dist_base;
+		writel_relaxed(mask, base + offset + (gic_irq(d) / 32) * 4);
+		gic_do_wait_for_rwp(base);
+	}
+}
+
+static void gic_mask_irq(struct irq_data *d)
+{
+	gic_poke_irq(d, GICD_ICENABLER);
+}
+
+static void gic_eoimode1_mask_irq(struct irq_data *d)
+{
+	gic_mask_irq(d);
+	/*
+	 * When masking a forwarded interrupt, make sure it is
+	 * deactivated as well.
+	 *
+	 * This ensures that an interrupt that is getting
+	 * disabled/masked will not get "stuck", because there is
+	 * noone to deactivate it (guest is being terminated).
+	 */
+	if (irqd_is_forwarded_to_vcpu(d))
+		gic_poke_irq(d, GICD_ICACTIVER);
+}
+
+static void gic_unmask_irq(struct irq_data *d)
+{
+	gic_poke_irq(d, GICD_ISENABLER);
+}
+
+static int gic_irq_set_irqchip_state(struct irq_data *d,
+				     enum irqchip_irq_state which, bool val)
+{
+	u32 reg;
+
+	if (d->hwirq >= gic_data.irq_nr) /* PPI/SPI only */
+		return -EINVAL;
+
+	switch (which) {
+	case IRQCHIP_STATE_PENDING:
+		reg = val ? GICD_ISPENDR : GICD_ICPENDR;
+		break;
+
+	case IRQCHIP_STATE_ACTIVE:
+		reg = val ? GICD_ISACTIVER : GICD_ICACTIVER;
+		break;
+
+	case IRQCHIP_STATE_MASKED:
+		reg = val ? GICD_ICENABLER : GICD_ISENABLER;
+		break;
+
+	default:
+		return -EINVAL;
+	}
+
+	gic_poke_irq(d, reg);
+	return 0;
+}
+
+static int gic_irq_get_irqchip_state(struct irq_data *d,
+				     enum irqchip_irq_state which, bool *val)
+{
+	if (d->hwirq >= gic_data.irq_nr) /* PPI/SPI only */
+		return -EINVAL;
+
+	switch (which) {
+	case IRQCHIP_STATE_PENDING:
+		*val = gic_peek_irq(d, GICD_ISPENDR);
+		break;
+
+	case IRQCHIP_STATE_ACTIVE:
+		*val = gic_peek_irq(d, GICD_ISACTIVER);
+		break;
+
+	case IRQCHIP_STATE_MASKED:
+		*val = !gic_peek_irq(d, GICD_ISENABLER);
+		break;
+
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static void gic_eoi_irq(struct irq_data *d)
+{
+	gic_write_eoir(gic_irq(d));
+}
+
+static void gic_eoimode1_eoi_irq(struct irq_data *d)
+{
+	/*
+	 * No need to deactivate an LPI, or an interrupt that
+	 * is is getting forwarded to a vcpu.
+	 */
+	if (gic_irq(d) >= 8192 || irqd_is_forwarded_to_vcpu(d))
+		return;
+	gic_write_dir(gic_irq(d));
+}
+
+static int gic_set_type(struct irq_data *d, unsigned int type)
+{
+	unsigned int irq = gic_irq(d);
+	unsigned long mpidr;
+	int i;
+	void __iomem *base;
+	void __iomem *rbase;
+	unsigned int skt;
+	int ret;
+
+	/* Interrupt configuration for SGIs can't be changed */
+	if (irq < 16)
+		return -EINVAL;
+
+	/* SPIs have restrictions on the supported types */
+	if (irq >= 32 && type != IRQ_TYPE_LEVEL_HIGH &&
+	    type != IRQ_TYPE_EDGE_RISING)
+		return -EINVAL;
+
+	if (gic_irq_in_rdist(d)) {
+		base = gic_data_rdist_sgi_base();
+		ret = gic_configure_irq(irq, type, base, gic_redist_wait_for_rwp);
+
+		mpidr = (unsigned long)cpu_logical_map(smp_processor_id());
+
+		if ((mpidr & 0xffff) == 0) {
+			rbase = base + 64*SZ_128K;
+
+			for (i = 0; i < 4; i++) {
+				ret = gic_configure_irq(irq, type, rbase, NULL);
+				gic_do_wait_for_rwp(rbase - SZ_64K);
+				rbase = rbase + SZ_128K;
+			}
+		}
+	} else {
+		skt = mars3_irq_to_skt(gic_irq(d));
+		base = mars3_gic_dists[skt].dist_base;
+		ret = gic_configure_irq(irq, type, base, NULL);
+		gic_do_wait_for_rwp(base);
+	}
+
+	return ret;
+}
+
+static int gic_irq_set_vcpu_affinity(struct irq_data *d, void *vcpu)
+{
+	if (vcpu)
+		irqd_set_forwarded_to_vcpu(d);
+	else
+		irqd_clr_forwarded_to_vcpu(d);
+	return 0;
+}
+
+static u64 gic_mpidr_to_affinity(unsigned long mpidr)
+{
+	u64 aff;
+
+	aff = ((u64)MPIDR_AFFINITY_LEVEL(mpidr, 3) << 32 |
+	       MPIDR_AFFINITY_LEVEL(mpidr, 2) << 16 |
+	       MPIDR_AFFINITY_LEVEL(mpidr, 1) << 8  |
+	       MPIDR_AFFINITY_LEVEL(mpidr, 0));
+
+	return aff;
+}
+
+static asmlinkage void __exception_irq_entry gic_handle_irq(struct pt_regs *regs)
+{
+	u32 irqnr;
+
+	do {
+		irqnr = gic_read_iar();
+
+		if (likely(irqnr > 15 && irqnr < 1020) || irqnr >= 8192) {
+			int err;
+
+			if (static_branch_likely(&supports_deactivate_key))
+				gic_write_eoir(irqnr);
+			else
+				isb();
+
+			err = handle_domain_irq(gic_data.domain, irqnr, regs);
+			if (err) {
+				WARN_ONCE(true, "Unexpected interrupt received!\n");
+				if (static_branch_likely(&supports_deactivate_key)) {
+					if (irqnr < 8192)
+						gic_write_dir(irqnr);
+				} else {
+					gic_write_eoir(irqnr);
+				}
+			}
+			continue;
+		}
+		if (irqnr < 16) {
+			gic_write_eoir(irqnr);
+			if (static_branch_likely(&supports_deactivate_key))
+				gic_write_dir(irqnr);
+#ifdef CONFIG_SMP
+			/*
+			 * Unlike GICv2, we don't need an smp_rmb() here.
+			 * The control dependency from gic_read_iar to
+			 * the ISB in gic_write_eoir is enough to ensure
+			 * that any shared data read by handle_IPI will
+			 * be read after the ACK.
+			 */
+			handle_IPI(irqnr, regs);
+#else
+			WARN_ONCE(true, "Unexpected SGI received!\n");
+#endif
+			continue;
+		}
+	} while (irqnr != ICC_IAR1_EL1_SPURIOUS);
+}
+
+static void __init gic_dist_init(void)
+{
+	unsigned int i;
+	u64 affinity;
+	void __iomem *base;
+	unsigned int skt;
+
+	for (skt = 0; skt < MAX_MARS3_SOC_COUNT; skt++) {
+		if ((((unsigned int)1 << skt) & mars3_sockets_bitmap) == 0)
+			continue;
+
+		base = mars3_gic_dists[skt].dist_base;
+
+		/* Disable the distributor */
+		writel_relaxed(0, base + GICD_CTLR);
+		gic_do_wait_for_rwp(base);
+
+		/*
+		 * Configure SPIs as non-secure Group-1. This will only matter
+		 * if the GIC only has a single security state. This will not
+		 * do the right thing if the kernel is running in secure mode,
+		 * but that's not the intended use case anyway.
+		 */
+		for (i = 32; i < gic_data.irq_nr; i += 32)
+			writel_relaxed(~0, base + GICD_IGROUPR + i / 8);
+
+		gic_dist_config(base, gic_data.irq_nr, NULL);
+		gic_do_wait_for_rwp(base);
+
+		/* Enable distributor with ARE, Group1 */
+		writel_relaxed(GICD_CTLR_ARE_NS | GICD_CTLR_ENABLE_G1A | GICD_CTLR_ENABLE_G1,
+			       base + GICD_CTLR);
+
+		/*
+		 * Set all global interrupts to the boot CPU only. ARE must be
+		 * enabled.
+		 */
+		affinity = gic_mpidr_to_affinity(cpu_logical_map(smp_processor_id()));
+		for (i = 32; i < gic_data.irq_nr; i++)
+			gic_write_irouter(affinity, base + GICD_IROUTER + i * 8);
+	}
+}
+
+static int gic_iterate_rdists(int (*fn)(struct redist_region *, void __iomem *))
+{
+	int ret = -ENODEV;
+	int i;
+
+	for (i = 0; i < gic_data.nr_redist_regions; i++) {
+		void __iomem *ptr = gic_data.redist_regions[i].redist_base;
+		u64 typer;
+		u32 reg;
+
+		reg = readl_relaxed(ptr + GICR_PIDR2) & GIC_PIDR2_ARCH_MASK;
+		if (reg != GIC_PIDR2_ARCH_GICv3 &&
+		    reg != GIC_PIDR2_ARCH_GICv4) { /* We're in trouble... */
+			pr_warn("No redistributor present @%p\n", ptr);
+			break;
+		}
+
+		do {
+			typer = gic_read_typer(ptr + GICR_TYPER);
+			ret = fn(gic_data.redist_regions + i, ptr);
+			if (!ret)
+				return 0;
+
+			if (gic_data.redist_regions[i].single_redist)
+				break;
+
+			if (gic_data.redist_stride) {
+				ptr += gic_data.redist_stride;
+			} else {
+				ptr += SZ_64K * 2; /* Skip RD_base + SGI_base */
+				if (typer & GICR_TYPER_VLPIS)
+					ptr += SZ_64K * 2; /* Skip VLPI_base + reserved page */
+			}
+		} while (!(typer & GICR_TYPER_LAST));
+	}
+
+	return ret ? -ENODEV : 0;
+}
+
+static int __gic_populate_rdist(struct redist_region *region, void __iomem *ptr)
+{
+	unsigned long mpidr = cpu_logical_map(smp_processor_id());
+	u64 typer;
+	u32 aff, aff2_skt, rdist_skt;
+
+	/*
+	 * Convert affinity to a 32bit value that can be matched to
+	 * GICR_TYPER bits [63:32].
+	 */
+	aff = (MPIDR_AFFINITY_LEVEL(mpidr, 1) << 8 |
+	      MPIDR_AFFINITY_LEVEL(mpidr, 0));
+
+	aff2_skt = MPIDR_AFFINITY_LEVEL(mpidr, 2) & 0x7;
+	rdist_skt = (((u64)region->phys_base >> MARS3_ADDR_SKTID_SHIFT) & 0x7);
+
+	if (aff2_skt != rdist_skt)
+		return 1;
+
+	typer = gic_read_typer(ptr + GICR_TYPER);
+	if ((typer >> 32) == aff) {
+		u64 offset = ptr - region->redist_base;
+		gic_data_rdist_rd_base() = ptr;
+		gic_data_rdist()->phys_base = region->phys_base + offset;
+
+		pr_info("CPU%d: found redistributor %lx region %d:%pa\n",
+			smp_processor_id(), mpidr,
+			(int)(region - gic_data.redist_regions),
+			&gic_data_rdist()->phys_base);
+		return 0;
+	}
+
+	/* Try next one */
+	return 1;
+}
+
+static int gic_populate_rdist(void)
+{
+	if (gic_iterate_rdists(__gic_populate_rdist) == 0)
+		return 0;
+
+	/* We couldn't even deal with ourselves... */
+	WARN(true, "CPU%d: mpidr %lx has no re-distributor!\n",
+	     smp_processor_id(),
+	     (unsigned long)cpu_logical_map(smp_processor_id()));
+	return -ENODEV;
+}
+
+static int __gic_update_vlpi_properties(struct redist_region *region,
+					void __iomem *ptr)
+{
+	u64 typer = gic_read_typer(ptr + GICR_TYPER);
+	gic_data.rdists.has_vlpis &= !!(typer & GICR_TYPER_VLPIS);
+	gic_data.rdists.has_direct_lpi &= !!(typer & GICR_TYPER_DirectLPIS);
+
+	return 1;
+}
+
+static void gic_update_vlpi_properties(void)
+{
+	gic_iterate_rdists(__gic_update_vlpi_properties);
+	pr_info("%sVLPI support, %sdirect LPI support\n",
+		!gic_data.rdists.has_vlpis ? "no " : "",
+		!gic_data.rdists.has_direct_lpi ? "no " : "");
+}
+
+static void gic_cpu_sys_reg_init(void)
+{
+	int i, cpu = smp_processor_id();
+	u64 mpidr = cpu_logical_map(cpu);
+	u64 need_rss = MPIDR_RS(mpidr);
+	bool group0;
+	u32 val, pribits;
+
+	/*
+	 * Need to check that the SRE bit has actually been set. If
+	 * not, it means that SRE is disabled at EL2. We're going to
+	 * die painfully, and there is nothing we can do about it.
+	 *
+	 * Kindly inform the luser.
+	 */
+	if (!gic_enable_sre())
+		pr_err("GIC: unable to set SRE (disabled at EL2), panic ahead\n");
+
+	pribits = gic_read_ctlr();
+	pribits &= ICC_CTLR_EL1_PRI_BITS_MASK;
+	pribits >>= ICC_CTLR_EL1_PRI_BITS_SHIFT;
+	pribits++;
+
+	/*
+	 * Let's find out if Group0 is under control of EL3 or not by
+	 * setting the highest possible, non-zero priority in PMR.
+	 *
+	 * If SCR_EL3.FIQ is set, the priority gets shifted down in
+	 * order for the CPU interface to set bit 7, and keep the
+	 * actual priority in the non-secure range. In the process, it
+	 * looses the least significant bit and the actual priority
+	 * becomes 0x80. Reading it back returns 0, indicating that
+	 * we're don't have access to Group0.
+	 */
+	write_gicreg(BIT(8 - pribits), ICC_PMR_EL1);
+	val = read_gicreg(ICC_PMR_EL1);
+	group0 = val != 0;
+
+	/* Set priority mask register */
+	write_gicreg(DEFAULT_PMR_VALUE, ICC_PMR_EL1);
+
+	/*
+	 * Some firmwares hand over to the kernel with the BPR changed from
+	 * its reset value (and with a value large enough to prevent
+	 * any pre-emptive interrupts from working at all). Writing a zero
+	 * to BPR restores is reset value.
+	 */
+	gic_write_bpr1(0);
+
+	if (static_branch_likely(&supports_deactivate_key)) {
+		/* EOI drops priority only (mode 1) */
+		gic_write_ctlr(ICC_CTLR_EL1_EOImode_drop);
+	} else {
+		/* EOI deactivates interrupt too (mode 0) */
+		gic_write_ctlr(ICC_CTLR_EL1_EOImode_drop_dir);
+	}
+
+	/* Always whack Group0 before Group1 */
+	if (group0) {
+		switch(pribits) {
+		case 8:
+		case 7:
+			write_gicreg(0, ICC_AP0R3_EL1);
+			write_gicreg(0, ICC_AP0R2_EL1);
+		case 6:
+			write_gicreg(0, ICC_AP0R1_EL1);
+		case 5:
+		case 4:
+			write_gicreg(0, ICC_AP0R0_EL1);
+		}
+
+		isb();
+	}
+
+	switch(pribits) {
+	case 8:
+	case 7:
+		write_gicreg(0, ICC_AP1R3_EL1);
+		write_gicreg(0, ICC_AP1R2_EL1);
+	case 6:
+		write_gicreg(0, ICC_AP1R1_EL1);
+	case 5:
+	case 4:
+		write_gicreg(0, ICC_AP1R0_EL1);
+	}
+
+	isb();
+
+	/* ... and let's hit the road... */
+	gic_write_grpen1(1);
+
+	/* Keep the RSS capability status in per_cpu variable */
+	per_cpu(has_rss, cpu) = !!(gic_read_ctlr() & ICC_CTLR_EL1_RSS);
+
+	/* Check all the CPUs have capable of sending SGIs to other CPUs */
+	for_each_online_cpu(i) {
+		bool have_rss = per_cpu(has_rss, i) && per_cpu(has_rss, cpu);
+
+		need_rss |= MPIDR_RS(cpu_logical_map(i));
+		if (need_rss && (!have_rss))
+			pr_crit("CPU%d (%lx) can't SGI CPU%d (%lx), no RSS\n",
+				cpu, (unsigned long)mpidr,
+				i, (unsigned long)cpu_logical_map(i));
+	}
+
+	/**
+	 * GIC spec says, when ICC_CTLR_EL1.RSS==1 and GICD_TYPER.RSS==0,
+	 * writing ICC_ASGI1R_EL1 register with RS != 0 is a CONSTRAINED
+	 * UNPREDICTABLE choice of :
+	 *   - The write is ignored.
+	 *   - The RS field is treated as 0.
+	 */
+	if (need_rss && (!gic_data.has_rss))
+		pr_crit_once("RSS is required but GICD doesn't support it\n");
+}
+
+static bool gicv3_nolpi;
+
+static int __init gicv3_nolpi_cfg(char *buf)
+{
+	return strtobool(buf, &gicv3_nolpi);
+}
+early_param("irqchip.gicv3_nolpi", gicv3_nolpi_cfg);
+
+static int gic_dist_supports_lpis(void)
+{
+	return !!(readl_relaxed(gic_data.dist_base + GICD_TYPER) & GICD_TYPER_LPIS) && !gicv3_nolpi;
+}
+
+static void gic_cpu_init(void)
+{
+	void __iomem *rbase;
+	unsigned long mpidr;
+	int i;
+
+	/* Register ourselves with the rest of the world */
+	if (gic_populate_rdist())
+		return;
+
+	gic_enable_redist(true);
+
+	rbase = gic_data_rdist_sgi_base();
+
+	/* Configure SGIs/PPIs as non-secure Group-1 */
+	writel_relaxed(~0, rbase + GICR_IGROUPR0);
+
+	gic_cpu_config(rbase, gic_redist_wait_for_rwp);
+
+	mpidr = (unsigned long)cpu_logical_map(smp_processor_id());
+
+	if ((mpidr & 0xFFFF) == 0) {
+		rbase = rbase + 64*SZ_128K;
+
+		for (i = 0; i < 4; i++) {
+			/* Configure SGIs/PPIs as non-secure Group-1 */
+			writel_relaxed(~0, rbase + GICR_IGROUPR0);
+
+			gic_cpu_config(rbase, NULL);
+			gic_do_wait_for_rwp(rbase - SZ_64K);
+
+			rbase = rbase + SZ_128K;
+		}
+	}
+
+	/* Give LPIs a spin */
+	if (gic_dist_supports_lpis())
+		phytium_its_cpu_init();
+
+	/* initialise system registers */
+	gic_cpu_sys_reg_init();
+}
+
+#ifdef CONFIG_SMP
+
+#define MPIDR_TO_SGI_RS(mpidr)	(MPIDR_RS(mpidr) << ICC_SGI1R_RS_SHIFT)
+#define MPIDR_TO_SGI_CLUSTER_ID(mpidr)	((mpidr) & ~0xFUL)
+
+static int gic_starting_cpu(unsigned int cpu)
+{
+	gic_cpu_init();
+	return 0;
+}
+
+static u16 gic_compute_target_list(int *base_cpu, const struct cpumask *mask,
+				   unsigned long cluster_id)
+{
+	int next_cpu, cpu = *base_cpu;
+	unsigned long mpidr = cpu_logical_map(cpu);
+	u16 tlist = 0;
+
+	while (cpu < nr_cpu_ids) {
+		tlist |= 1 << (mpidr & 0xf);
+
+		next_cpu = cpumask_next(cpu, mask);
+		if (next_cpu >= nr_cpu_ids)
+			goto out;
+		cpu = next_cpu;
+
+		mpidr = cpu_logical_map(cpu);
+
+		if (cluster_id != MPIDR_TO_SGI_CLUSTER_ID(mpidr)) {
+			cpu--;
+			goto out;
+		}
+	}
+out:
+	*base_cpu = cpu;
+	return tlist;
+}
+
+#define MPIDR_TO_SGI_AFFINITY(cluster_id, level) \
+	(MPIDR_AFFINITY_LEVEL(cluster_id, level) \
+		<< ICC_SGI1R_AFFINITY_## level ##_SHIFT)
+
+static void gic_send_sgi(u64 cluster_id, u16 tlist, unsigned int irq)
+{
+	u64 val;
+
+	val = (MPIDR_TO_SGI_AFFINITY(cluster_id, 3)	|
+	       MPIDR_TO_SGI_AFFINITY(cluster_id, 2)	|
+	       irq << ICC_SGI1R_SGI_ID_SHIFT		|
+	       MPIDR_TO_SGI_AFFINITY(cluster_id, 1)	|
+	       MPIDR_TO_SGI_RS(cluster_id)		|
+	       tlist << ICC_SGI1R_TARGET_LIST_SHIFT);
+
+	pr_devel("CPU%d: ICC_SGI1R_EL1 %llx\n", smp_processor_id(), val);
+	gic_write_sgi1r(val);
+}
+
+static void gic_raise_softirq(const struct cpumask *mask, unsigned int irq)
+{
+	int cpu;
+
+	if (WARN_ON(irq >= 16))
+		return;
+
+	/*
+	 * Ensure that stores to Normal memory are visible to the
+	 * other CPUs before issuing the IPI.
+	 */
+	wmb();
+
+	for_each_cpu(cpu, mask) {
+		u64 cluster_id = MPIDR_TO_SGI_CLUSTER_ID(cpu_logical_map(cpu));
+		u16 tlist;
+
+		tlist = gic_compute_target_list(&cpu, mask, cluster_id);
+		gic_send_sgi(cluster_id, tlist, irq);
+	}
+
+	/* Force the above writes to ICC_SGI1R_EL1 to be executed */
+	isb();
+}
+
+static void gic_smp_init(void)
+{
+	set_smp_cross_call(gic_raise_softirq);
+	cpuhp_setup_state_nocalls(CPUHP_AP_IRQ_GIC_STARTING,
+				  "irqchip/arm/gic_phytium_2500:starting",
+				  gic_starting_cpu, NULL);
+}
+
+static int gic_cpumask_select(struct irq_data *d, const struct cpumask *mask_val)
+{
+	unsigned int skt, irq_skt, i;
+	unsigned int cpu, cpus = 0;
+	unsigned int skt_cpu_cnt[MAX_MARS3_SOC_COUNT] = {0};
+
+	for (i = 0; i < nr_cpu_ids; i++) {
+		skt = (cpu_logical_map(i) >> 16) & 0xff;
+		if ((skt >= 0) && (skt < MAX_MARS3_SOC_COUNT))
+			skt_cpu_cnt[skt]++;
+		else if (skt != 0xff)
+			pr_err("socket address: %d is out of range.", skt);
+	}
+
+	irq_skt = mars3_irq_to_skt(gic_irq(d));
+
+	if (0 != irq_skt) {
+		for (i = 0; i < irq_skt; i++)
+			cpus += skt_cpu_cnt[i];
+	}
+
+	cpu = cpumask_any_and(mask_val, cpu_online_mask);
+	if ((cpu > cpus) && (cpu < (cpus + skt_cpu_cnt[irq_skt])))
+		cpus = cpu;
+
+	return cpus;
+}
+
+static int gic_set_affinity(struct irq_data *d, const struct cpumask *mask_val,
+			    bool force)
+{
+	unsigned int cpu, skt;
+	void __iomem *reg;
+	int enabled;
+	u64 val;
+
+	if (force)
+		cpu = cpumask_first(mask_val);
+	else
+		cpu = gic_cpumask_select(d, mask_val);
+
+	if (cpu >= nr_cpu_ids)
+		return -EINVAL;
+
+	if (gic_irq_in_rdist(d))
+		return -EINVAL;
+
+	/* If interrupt was enabled, disable it first */
+	enabled = gic_peek_irq(d, GICD_ISENABLER);
+	if (enabled)
+		gic_mask_irq(d);
+
+	skt = mars3_irq_to_skt(gic_irq(d));
+	reg = mars3_gic_dists[skt].dist_base + GICD_IROUTER + (gic_irq(d) * 8);
+	val = gic_mpidr_to_affinity(cpu_logical_map(cpu));
+
+	gic_write_irouter(val, reg);
+
+	/*
+	 * If the interrupt was enabled, enabled it again. Otherwise,
+	 * just wait for the distributor to have digested our changes.
+	 */
+	if (enabled)
+		gic_unmask_irq(d);
+	else
+		gic_dist_wait_for_rwp();
+
+	irq_data_update_effective_affinity(d, cpumask_of(cpu));
+
+	return IRQ_SET_MASK_OK_DONE;
+}
+#else
+#define gic_set_affinity	NULL
+#define gic_smp_init()		do { } while(0)
+#endif
+
+#ifdef CONFIG_CPU_PM
+/* Check whether it's single security state view */
+static bool gic_dist_security_disabled(void)
+{
+	return readl_relaxed(gic_data.dist_base + GICD_CTLR) & GICD_CTLR_DS;
+}
+
+static int gic_cpu_pm_notifier(struct notifier_block *self,
+			       unsigned long cmd, void *v)
+{
+	if (cmd == CPU_PM_EXIT) {
+		if (gic_dist_security_disabled())
+			gic_enable_redist(true);
+		gic_cpu_sys_reg_init();
+	} else if (cmd == CPU_PM_ENTER && gic_dist_security_disabled()) {
+		gic_write_grpen1(0);
+		gic_enable_redist(false);
+	}
+	return NOTIFY_OK;
+}
+
+static struct notifier_block gic_cpu_pm_notifier_block = {
+	.notifier_call = gic_cpu_pm_notifier,
+};
+
+static void gic_cpu_pm_init(void)
+{
+	cpu_pm_register_notifier(&gic_cpu_pm_notifier_block);
+}
+
+#else
+static inline void gic_cpu_pm_init(void) { }
+#endif /* CONFIG_CPU_PM */
+
+static struct irq_chip gic_chip = {
+	.name			= "GIC-Phytium-2500",
+	.irq_mask		= gic_mask_irq,
+	.irq_unmask		= gic_unmask_irq,
+	.irq_eoi		= gic_eoi_irq,
+	.irq_set_type		= gic_set_type,
+	.irq_set_affinity	= gic_set_affinity,
+	.irq_get_irqchip_state	= gic_irq_get_irqchip_state,
+	.irq_set_irqchip_state	= gic_irq_set_irqchip_state,
+	.flags			= IRQCHIP_SET_TYPE_MASKED |
+				  IRQCHIP_SKIP_SET_WAKE |
+				  IRQCHIP_MASK_ON_SUSPEND,
+};
+
+static struct irq_chip gic_eoimode1_chip = {
+	.name			= "GIC-Phytium-2500",
+	.irq_mask		= gic_eoimode1_mask_irq,
+	.irq_unmask		= gic_unmask_irq,
+	.irq_eoi		= gic_eoimode1_eoi_irq,
+	.irq_set_type		= gic_set_type,
+	.irq_set_affinity	= gic_set_affinity,
+	.irq_get_irqchip_state	= gic_irq_get_irqchip_state,
+	.irq_set_irqchip_state	= gic_irq_set_irqchip_state,
+	.irq_set_vcpu_affinity	= gic_irq_set_vcpu_affinity,
+	.flags			= IRQCHIP_SET_TYPE_MASKED |
+				  IRQCHIP_SKIP_SET_WAKE |
+				  IRQCHIP_MASK_ON_SUSPEND,
+};
+
+#define GIC_ID_NR	(1U << GICD_TYPER_ID_BITS(gic_data.rdists.gicd_typer))
+
+static int gic_irq_domain_map(struct irq_domain *d, unsigned int irq,
+			      irq_hw_number_t hw)
+{
+	struct irq_chip *chip = &gic_chip;
+
+	if (static_branch_likely(&supports_deactivate_key))
+		chip = &gic_eoimode1_chip;
+
+	/* SGIs are private to the core kernel */
+	if (hw < 16)
+		return -EPERM;
+	/* Nothing here */
+	if (hw >= gic_data.irq_nr && hw < 8192)
+		return -EPERM;
+	/* Off limits */
+	if (hw >= GIC_ID_NR)
+		return -EPERM;
+
+	/* PPIs */
+	if (hw < 32) {
+		irq_set_percpu_devid(irq);
+		irq_domain_set_info(d, irq, hw, chip, d->host_data,
+				    handle_percpu_devid_irq, NULL, NULL);
+		irq_set_status_flags(irq, IRQ_NOAUTOEN);
+	}
+	/* SPIs */
+	if (hw >= 32 && hw < gic_data.irq_nr) {
+		irq_domain_set_info(d, irq, hw, chip, d->host_data,
+				    handle_fasteoi_irq, NULL, NULL);
+		irq_set_probe(irq);
+		irqd_set_single_target(irq_desc_get_irq_data(irq_to_desc(irq)));
+	}
+	/* LPIs */
+	if (hw >= 8192 && hw < GIC_ID_NR) {
+		if (!gic_dist_supports_lpis())
+			return -EPERM;
+		irq_domain_set_info(d, irq, hw, chip, d->host_data,
+				    handle_fasteoi_irq, NULL, NULL);
+	}
+
+	return 0;
+}
+
+#define GIC_IRQ_TYPE_PARTITION	(GIC_IRQ_TYPE_LPI + 1)
+
+static int gic_irq_domain_translate(struct irq_domain *d,
+				    struct irq_fwspec *fwspec,
+				    unsigned long *hwirq,
+				    unsigned int *type)
+{
+	if (is_of_node(fwspec->fwnode)) {
+		if (fwspec->param_count < 3)
+			return -EINVAL;
+
+		switch (fwspec->param[0]) {
+		case 0:			/* SPI */
+			*hwirq = fwspec->param[1] + 32;
+			break;
+		case 1:			/* PPI */
+		case GIC_IRQ_TYPE_PARTITION:
+			*hwirq = fwspec->param[1] + 16;
+			break;
+		case GIC_IRQ_TYPE_LPI:	/* LPI */
+			*hwirq = fwspec->param[1];
+			break;
+		default:
+			return -EINVAL;
+		}
+
+		*type = fwspec->param[2] & IRQ_TYPE_SENSE_MASK;
+
+		/*
+		 * Make it clear that broken DTs are... broken.
+		 * Partitionned PPIs are an unfortunate exception.
+		 */
+		WARN_ON(*type == IRQ_TYPE_NONE &&
+			fwspec->param[0] != GIC_IRQ_TYPE_PARTITION);
+		return 0;
+	}
+
+	if (is_fwnode_irqchip(fwspec->fwnode)) {
+		if (fwspec->param_count != 2)
+			return -EINVAL;
+
+		*hwirq = fwspec->param[0];
+		*type = fwspec->param[1];
+
+		WARN_ON(*type == IRQ_TYPE_NONE);
+		return 0;
+	}
+
+	return -EINVAL;
+}
+
+static int gic_irq_domain_alloc(struct irq_domain *domain, unsigned int virq,
+				unsigned int nr_irqs, void *arg)
+{
+	int i, ret;
+	irq_hw_number_t hwirq;
+	unsigned int type = IRQ_TYPE_NONE;
+	struct irq_fwspec *fwspec = arg;
+
+	ret = gic_irq_domain_translate(domain, fwspec, &hwirq, &type);
+	if (ret)
+		return ret;
+
+	for (i = 0; i < nr_irqs; i++) {
+		ret = gic_irq_domain_map(domain, virq + i, hwirq + i);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+static void gic_irq_domain_free(struct irq_domain *domain, unsigned int virq,
+				unsigned int nr_irqs)
+{
+	int i;
+
+	for (i = 0; i < nr_irqs; i++) {
+		struct irq_data *d = irq_domain_get_irq_data(domain, virq + i);
+		irq_set_handler(virq + i, NULL);
+		irq_domain_reset_irq_data(d);
+	}
+}
+
+static int gic_irq_domain_select(struct irq_domain *d,
+				 struct irq_fwspec *fwspec,
+				 enum irq_domain_bus_token bus_token)
+{
+	/* Not for us */
+        if (fwspec->fwnode != d->fwnode)
+		return 0;
+
+	/* If this is not DT, then we have a single domain */
+	if (!is_of_node(fwspec->fwnode))
+		return 1;
+
+	/*
+	 * If this is a PPI and we have a 4th (non-null) parameter,
+	 * then we need to match the partition domain.
+	 */
+	if (fwspec->param_count >= 4 &&
+	    fwspec->param[0] == 1 && fwspec->param[3] != 0)
+		return d == partition_get_domain(gic_data.ppi_descs[fwspec->param[1]]);
+
+	return d == gic_data.domain;
+}
+
+static const struct irq_domain_ops gic_irq_domain_ops = {
+	.translate = gic_irq_domain_translate,
+	.alloc = gic_irq_domain_alloc,
+	.free = gic_irq_domain_free,
+	.select = gic_irq_domain_select,
+};
+
+static int partition_domain_translate(struct irq_domain *d,
+				      struct irq_fwspec *fwspec,
+				      unsigned long *hwirq,
+				      unsigned int *type)
+{
+	struct device_node *np;
+	int ret;
+
+	np = of_find_node_by_phandle(fwspec->param[3]);
+	if (WARN_ON(!np))
+		return -EINVAL;
+
+	ret = partition_translate_id(gic_data.ppi_descs[fwspec->param[1]],
+				     of_node_to_fwnode(np));
+	if (ret < 0)
+		return ret;
+
+	*hwirq = ret;
+	*type = fwspec->param[2] & IRQ_TYPE_SENSE_MASK;
+
+	return 0;
+}
+
+static const struct irq_domain_ops partition_domain_ops = {
+	.translate = partition_domain_translate,
+	.select = gic_irq_domain_select,
+};
+
+static int __init gic_init_bases(void __iomem *dist_base,
+				 struct redist_region *rdist_regs,
+				 u32 nr_redist_regions,
+				 u64 redist_stride,
+				 struct fwnode_handle *handle)
+{
+	u32 typer;
+	int gic_irqs;
+	int err;
+
+	if (!is_hyp_mode_available())
+		static_branch_disable(&supports_deactivate_key);
+
+	if (static_branch_likely(&supports_deactivate_key))
+		pr_info("GIC: Using split EOI/Deactivate mode\n");
+
+	gic_data.fwnode = handle;
+	gic_data.dist_base = dist_base;
+	gic_data.redist_regions = rdist_regs;
+	gic_data.nr_redist_regions = nr_redist_regions;
+	gic_data.redist_stride = redist_stride;
+
+	/*
+	 * Find out how many interrupts are supported.
+	 * The GIC only supports up to 1020 interrupt sources (SGI+PPI+SPI)
+	 */
+	typer = readl_relaxed(gic_data.dist_base + GICD_TYPER);
+	gic_data.rdists.gicd_typer = typer;
+	gic_irqs = GICD_TYPER_IRQS(typer);
+	if (gic_irqs > 1020)
+		gic_irqs = 1020;
+	gic_data.irq_nr = gic_irqs;
+
+	gic_data.domain = irq_domain_create_tree(handle, &gic_irq_domain_ops,
+						 &gic_data);
+	irq_domain_update_bus_token(gic_data.domain, DOMAIN_BUS_WIRED);
+	gic_data.rdists.rdist = alloc_percpu(typeof(*gic_data.rdists.rdist));
+	gic_data.rdists.has_vlpis = true;
+	gic_data.rdists.has_direct_lpi = true;
+
+	if (WARN_ON(!gic_data.domain) || WARN_ON(!gic_data.rdists.rdist)) {
+		err = -ENOMEM;
+		goto out_free;
+	}
+
+	gic_data.has_rss = !!(typer & GICD_TYPER_RSS);
+	pr_info("Distributor has %sRange Selector support\n",
+		gic_data.has_rss ? "" : "no ");
+
+	set_handle_irq(gic_handle_irq);
+
+	gic_update_vlpi_properties();
+
+	if (gic_dist_supports_lpis())
+		phytium_its_init(handle, &gic_data.rdists, gic_data.domain);
+
+	gic_smp_init();
+	gic_dist_init();
+	gic_cpu_init();
+	gic_cpu_pm_init();
+
+	return 0;
+
+out_free:
+	if (gic_data.domain)
+		irq_domain_remove(gic_data.domain);
+	free_percpu(gic_data.rdists.rdist);
+	return err;
+}
+
+static int __init gic_validate_dist_version(void __iomem *dist_base)
+{
+	u32 reg = readl_relaxed(dist_base + GICD_PIDR2) & GIC_PIDR2_ARCH_MASK;
+
+	if (reg != GIC_PIDR2_ARCH_GICv3 && reg != GIC_PIDR2_ARCH_GICv4)
+		return -ENODEV;
+
+	return 0;
+}
+
+/* Create all possible partitions at boot time */
+static void __init gic_populate_ppi_partitions(struct device_node *gic_node)
+{
+	struct device_node *parts_node, *child_part;
+	int part_idx = 0, i;
+	int nr_parts;
+	struct partition_affinity *parts;
+
+	parts_node = of_get_child_by_name(gic_node, "ppi-partitions");
+	if (!parts_node)
+		return;
+
+	nr_parts = of_get_child_count(parts_node);
+
+	if (!nr_parts)
+		goto out_put_node;
+
+	parts = kcalloc(nr_parts, sizeof(*parts), GFP_KERNEL);
+	if (WARN_ON(!parts))
+		goto out_put_node;
+
+	for_each_child_of_node(parts_node, child_part) {
+		struct partition_affinity *part;
+		int n;
+
+		part = &parts[part_idx];
+
+		part->partition_id = of_node_to_fwnode(child_part);
+
+		pr_info("GIC: PPI partition %s[%d] { ",
+			child_part->name, part_idx);
+
+		n = of_property_count_elems_of_size(child_part, "affinity",
+						    sizeof(u32));
+		WARN_ON(n <= 0);
+
+		for (i = 0; i < n; i++) {
+			int err, cpu;
+			u32 cpu_phandle;
+			struct device_node *cpu_node;
+
+			err = of_property_read_u32_index(child_part, "affinity",
+							 i, &cpu_phandle);
+			if (WARN_ON(err))
+				continue;
+
+			cpu_node = of_find_node_by_phandle(cpu_phandle);
+			if (WARN_ON(!cpu_node))
+				continue;
+
+			cpu = of_cpu_node_to_id(cpu_node);
+			if (WARN_ON(cpu < 0))
+				continue;
+
+			pr_cont("%pOF[%d] ", cpu_node, cpu);
+
+			cpumask_set_cpu(cpu, &part->mask);
+		}
+
+		pr_cont("}\n");
+		part_idx++;
+	}
+
+	for (i = 0; i < 16; i++) {
+		unsigned int irq;
+		struct partition_desc *desc;
+		struct irq_fwspec ppi_fwspec = {
+			.fwnode		= gic_data.fwnode,
+			.param_count	= 3,
+			.param		= {
+				[0]	= GIC_IRQ_TYPE_PARTITION,
+				[1]	= i,
+				[2]	= IRQ_TYPE_NONE,
+			},
+		};
+
+		irq = irq_create_fwspec_mapping(&ppi_fwspec);
+		if (WARN_ON(!irq))
+			continue;
+		desc = partition_create_desc(gic_data.fwnode, parts, nr_parts,
+					     irq, &partition_domain_ops);
+		if (WARN_ON(!desc))
+			continue;
+
+		gic_data.ppi_descs[i] = desc;
+	}
+
+out_put_node:
+	of_node_put(parts_node);
+}
+
+static void __init gic_of_setup_kvm_info(struct device_node *node)
+{
+	int ret;
+	struct resource r;
+	u32 gicv_idx;
+
+	gic_v3_kvm_info.type = GIC_V3;
+
+	gic_v3_kvm_info.maint_irq = irq_of_parse_and_map(node, 0);
+	if (!gic_v3_kvm_info.maint_irq)
+		return;
+
+	if (of_property_read_u32(node, "#redistributor-regions",
+				 &gicv_idx))
+		gicv_idx = 1;
+
+	gicv_idx += 3;	/* Also skip GICD, GICC, GICH */
+	ret = of_address_to_resource(node, gicv_idx, &r);
+	if (!ret)
+		gic_v3_kvm_info.vcpu = r;
+
+	gic_v3_kvm_info.has_v4 = gic_data.rdists.has_vlpis;
+	gic_set_kvm_info(&gic_v3_kvm_info);
+}
+
+static int __init gic_of_init(struct device_node *node, struct device_node *parent)
+{
+	void __iomem *dist_base;
+	struct redist_region *rdist_regs;
+	u64 redist_stride;
+	u32 nr_redist_regions;
+	int err, i, skt;
+	struct resource res;
+
+	dist_base = of_iomap(node, 0);
+	if (!dist_base) {
+		pr_err("%pOF: unable to map gic dist registers\n", node);
+		return -ENXIO;
+	}
+
+	err = gic_validate_dist_version(dist_base);
+	if (err) {
+		pr_err("%pOF: no distributor detected, giving up\n", node);
+		goto out_unmap_dist;
+	}
+
+	if (of_address_to_resource(node, 0, &res)) {
+		printk("Error: No GIC Distributor in FDT\n");
+		goto out_unmap_dist;
+	}
+
+	mars3_gic_dists[0].phys_base = res.start;
+	mars3_gic_dists[0].size =  resource_size(&res);
+	mars3_gic_dists[0].dist_base = dist_base;
+
+	if (of_property_read_u32(node, "#mars3-soc-bitmap", &mars3_sockets_bitmap))
+		mars3_sockets_bitmap = 0x1;
+
+	for (skt = 1; skt < MAX_MARS3_SOC_COUNT; skt++) {
+		if ((((unsigned int)1 << skt) & mars3_sockets_bitmap) == 0)
+			continue;
+
+		mars3_gic_dists[skt].phys_base = ((unsigned long)skt << MARS3_ADDR_SKTID_SHIFT) |
+						 mars3_gic_dists[0].phys_base;
+		mars3_gic_dists[skt].size =  mars3_gic_dists[0].size;
+		mars3_gic_dists[skt].dist_base = ioremap(mars3_gic_dists[skt].phys_base,
+							 mars3_gic_dists[skt].size);
+	}
+
+	if (of_property_read_u32(node, "#redistributor-regions", &nr_redist_regions))
+		nr_redist_regions = 1;
+
+	rdist_regs = kcalloc(nr_redist_regions, sizeof(*rdist_regs),
+			     GFP_KERNEL);
+	if (!rdist_regs) {
+		err = -ENOMEM;
+		goto out_unmap_dist;
+	}
+
+	for (i = 0; i < nr_redist_regions; i++) {
+		struct resource res;
+		int ret;
+
+		ret = of_address_to_resource(node, 1 + i, &res);
+		rdist_regs[i].redist_base = of_iomap(node, 1 + i);
+		if (ret || !rdist_regs[i].redist_base) {
+			pr_err("%pOF: couldn't map region %d\n", node, i);
+			err = -ENODEV;
+			goto out_unmap_rdist;
+		}
+		rdist_regs[i].phys_base = res.start;
+	}
+
+	if (of_property_read_u64(node, "redistributor-stride", &redist_stride))
+		redist_stride = 0;
+
+	err = gic_init_bases(dist_base, rdist_regs, nr_redist_regions,
+			     redist_stride, &node->fwnode);
+	if (err)
+		goto out_unmap_rdist;
+
+	gic_populate_ppi_partitions(node);
+
+	if (static_branch_likely(&supports_deactivate_key))
+		gic_of_setup_kvm_info(node);
+	return 0;
+
+out_unmap_rdist:
+	for (i = 0; i < nr_redist_regions; i++)
+		if (rdist_regs[i].redist_base)
+			iounmap(rdist_regs[i].redist_base);
+	kfree(rdist_regs);
+out_unmap_dist:
+	iounmap(dist_base);
+	return err;
+}
+
+IRQCHIP_DECLARE(gic_phyt_2500, "arm,gic-phytium-2500", gic_of_init);
+
+#ifdef CONFIG_ACPI
+static struct
+{
+	void __iomem *dist_base;
+	struct redist_region *redist_regs;
+	u32 nr_redist_regions;
+	bool single_redist;
+	u32 maint_irq;
+	int maint_irq_mode;
+	phys_addr_t vcpu_base;
+} acpi_data __initdata;
+
+static int gic_mars3_sockets_bitmap(void)
+{
+	unsigned int skt, i;
+	int skt_bitmap = 0;
+	unsigned int skt_cpu_cnt[MAX_MARS3_SOC_COUNT] = {0};
+
+	for (i = 0; i < nr_cpu_ids; i++) {
+		skt = (cpu_logical_map(i) >> 16) & 0xff;
+		if ((skt >= 0) && (skt < MAX_MARS3_SOC_COUNT))
+			skt_cpu_cnt[skt]++;
+		else if (skt != 0xff)
+			pr_err("socket address: %d is out of range.", skt);
+	}
+
+	for (i = 0; i < MAX_MARS3_SOC_COUNT; i++) {
+		if (skt_cpu_cnt[i] > 0)
+			skt_bitmap |= (1 << i);
+	}
+
+	return skt_bitmap;
+}
+
+static void __init
+gic_acpi_register_redist(phys_addr_t phys_base, void __iomem *redist_base)
+{
+	static int count = 0;
+
+	acpi_data.redist_regs[count].phys_base = phys_base;
+	acpi_data.redist_regs[count].redist_base = redist_base;
+	acpi_data.redist_regs[count].single_redist = acpi_data.single_redist;
+	count++;
+}
+
+static int __init
+gic_acpi_parse_madt_redist(struct acpi_subtable_header *header,
+			   const unsigned long end)
+{
+	struct acpi_madt_generic_redistributor *redist =
+			(struct acpi_madt_generic_redistributor *)header;
+	void __iomem *redist_base;
+
+	redist_base = ioremap(redist->base_address, redist->length);
+	if (!redist_base) {
+		pr_err("Couldn't map GICR region @%llx\n", redist->base_address);
+		return -ENOMEM;
+	}
+
+	gic_acpi_register_redist(redist->base_address, redist_base);
+	return 0;
+}
+
+static int __init
+gic_acpi_parse_madt_gicc(struct acpi_subtable_header *header,
+			 const unsigned long end)
+{
+	struct acpi_madt_generic_interrupt *gicc =
+				(struct acpi_madt_generic_interrupt *)header;
+	u32 reg = readl_relaxed(acpi_data.dist_base + GICD_PIDR2) & GIC_PIDR2_ARCH_MASK;
+	u32 size = reg == GIC_PIDR2_ARCH_GICv4 ? SZ_64K * 4 : SZ_64K * 2;
+	void __iomem *redist_base;
+
+	/* GICC entry which has !ACPI_MADT_ENABLED is not unusable so skip */
+	if (!(gicc->flags & ACPI_MADT_ENABLED))
+		return 0;
+
+	redist_base = ioremap(gicc->gicr_base_address, size);
+	if (!redist_base)
+		return -ENOMEM;
+
+	gic_acpi_register_redist(gicc->gicr_base_address, redist_base);
+	return 0;
+}
+
+static int __init gic_acpi_collect_gicr_base(void)
+{
+	acpi_tbl_entry_handler redist_parser;
+	enum acpi_madt_type type;
+
+	if (acpi_data.single_redist) {
+		type = ACPI_MADT_TYPE_GENERIC_INTERRUPT;
+		redist_parser = gic_acpi_parse_madt_gicc;
+	} else {
+		type = ACPI_MADT_TYPE_GENERIC_REDISTRIBUTOR;
+		redist_parser = gic_acpi_parse_madt_redist;
+	}
+
+	/* Collect redistributor base addresses in GICR entries */
+	if (acpi_table_parse_madt(type, redist_parser, 0) > 0)
+		return 0;
+
+	pr_info("No valid GICR entries exist\n");
+	return -ENODEV;
+}
+
+static int __init gic_acpi_match_gicr(struct acpi_subtable_header *header,
+				  const unsigned long end)
+{
+	/* Subtable presence means that redist exists, that's it */
+	return 0;
+}
+
+static int __init gic_acpi_match_gicc(struct acpi_subtable_header *header,
+				      const unsigned long end)
+{
+	struct acpi_madt_generic_interrupt *gicc =
+				(struct acpi_madt_generic_interrupt *)header;
+
+	/*
+	 * If GICC is enabled and has valid gicr base address, then it means
+	 * GICR base is presented via GICC
+	 */
+	if ((gicc->flags & ACPI_MADT_ENABLED) && gicc->gicr_base_address)
+		return 0;
+
+	/*
+	 * It's perfectly valid firmware can pass disabled GICC entry, driver
+	 * should not treat as errors, skip the entry instead of probe fail.
+	 */
+	if (!(gicc->flags & ACPI_MADT_ENABLED))
+		return 0;
+
+	return -ENODEV;
+}
+
+static int __init gic_acpi_count_gicr_regions(void)
+{
+	int count;
+
+	/*
+	 * Count how many redistributor regions we have. It is not allowed
+	 * to mix redistributor description, GICR and GICC subtables have to be
+	 * mutually exclusive.
+	 */
+	count = acpi_table_parse_madt(ACPI_MADT_TYPE_GENERIC_REDISTRIBUTOR,
+				      gic_acpi_match_gicr, 0);
+	if (count > 0) {
+		acpi_data.single_redist = false;
+		return count;
+	}
+
+	count = acpi_table_parse_madt(ACPI_MADT_TYPE_GENERIC_INTERRUPT,
+				      gic_acpi_match_gicc, 0);
+	if (count > 0)
+		acpi_data.single_redist = true;
+
+	return count;
+}
+
+static bool __init acpi_validate_gic_table(struct acpi_subtable_header *header,
+					   struct acpi_probe_entry *ape)
+{
+	struct acpi_madt_generic_distributor *dist;
+	int count;
+
+	dist = (struct acpi_madt_generic_distributor *)header;
+	if (dist->version != ape->driver_data)
+		return false;
+
+	/* We need to do that exercise anyway, the sooner the better */
+	count = gic_acpi_count_gicr_regions();
+	if (count <= 0)
+		return false;
+
+	acpi_data.nr_redist_regions = count;
+	return true;
+}
+
+static int __init gic_acpi_parse_virt_madt_gicc(struct acpi_subtable_header *header,
+						const unsigned long end)
+{
+	struct acpi_madt_generic_interrupt *gicc =
+		(struct acpi_madt_generic_interrupt *)header;
+	int maint_irq_mode;
+	static int first_madt = true;
+
+	/* Skip unusable CPUs */
+	if (!(gicc->flags & ACPI_MADT_ENABLED))
+		return 0;
+
+	maint_irq_mode = (gicc->flags & ACPI_MADT_VGIC_IRQ_MODE) ?
+		ACPI_EDGE_SENSITIVE : ACPI_LEVEL_SENSITIVE;
+
+	if (first_madt) {
+		first_madt = false;
+
+		acpi_data.maint_irq = gicc->vgic_interrupt;
+		acpi_data.maint_irq_mode = maint_irq_mode;
+		acpi_data.vcpu_base = gicc->gicv_base_address;
+
+		return 0;
+	}
+
+	/*
+	 * The maintenance interrupt and GICV should be the same for every CPU
+	 */
+	if ((acpi_data.maint_irq != gicc->vgic_interrupt) ||
+	    (acpi_data.maint_irq_mode != maint_irq_mode) ||
+	    (acpi_data.vcpu_base != gicc->gicv_base_address))
+		return -EINVAL;
+
+	return 0;
+}
+
+static bool __init gic_acpi_collect_virt_info(void)
+{
+	int count;
+
+	count = acpi_table_parse_madt(ACPI_MADT_TYPE_GENERIC_INTERRUPT,
+				      gic_acpi_parse_virt_madt_gicc, 0);
+
+	return (count > 0);
+}
+
+#define ACPI_GICV3_DIST_MEM_SIZE (SZ_64K)
+#define ACPI_GICV2_VCTRL_MEM_SIZE	(SZ_4K)
+#define ACPI_GICV2_VCPU_MEM_SIZE	(SZ_8K)
+
+static void __init gic_acpi_setup_kvm_info(void)
+{
+	int irq;
+
+	if (!gic_acpi_collect_virt_info()) {
+		pr_warn("Unable to get hardware information used for virtualization\n");
+		return;
+	}
+
+	gic_v3_kvm_info.type = GIC_V3;
+
+	irq = acpi_register_gsi(NULL, acpi_data.maint_irq,
+				acpi_data.maint_irq_mode,
+				ACPI_ACTIVE_HIGH);
+	if (irq <= 0)
+		return;
+
+	gic_v3_kvm_info.maint_irq = irq;
+
+	if (acpi_data.vcpu_base) {
+		struct resource *vcpu = &gic_v3_kvm_info.vcpu;
+
+		vcpu->flags = IORESOURCE_MEM;
+		vcpu->start = acpi_data.vcpu_base;
+		vcpu->end = vcpu->start + ACPI_GICV2_VCPU_MEM_SIZE - 1;
+	}
+
+	gic_v3_kvm_info.has_v4 = gic_data.rdists.has_vlpis;
+	gic_set_kvm_info(&gic_v3_kvm_info);
+}
+
+static int __init
+gic_acpi_init(struct acpi_subtable_header *header, const unsigned long end)
+{
+	struct acpi_madt_generic_distributor *dist;
+	struct fwnode_handle *domain_handle;
+	size_t size;
+	int i, err, skt;
+
+	/* Get distributor base address */
+	dist = (struct acpi_madt_generic_distributor *)header;
+	acpi_data.dist_base = ioremap(dist->base_address,
+				      ACPI_GICV3_DIST_MEM_SIZE);
+	if (!acpi_data.dist_base) {
+		pr_err("Unable to map GICD registers\n");
+		return -ENOMEM;
+	}
+
+	err = gic_validate_dist_version(acpi_data.dist_base);
+	if (err) {
+		pr_err("No distributor detected at @%p, giving up\n",
+		       acpi_data.dist_base);
+		goto out_dist_unmap;
+	}
+
+	mars3_gic_dists[0].phys_base = dist->base_address;
+	mars3_gic_dists[0].size =  ACPI_GICV3_DIST_MEM_SIZE;
+	mars3_gic_dists[0].dist_base = acpi_data.dist_base;
+
+	mars3_sockets_bitmap = gic_mars3_sockets_bitmap();
+	if (mars3_sockets_bitmap == 0) {
+		mars3_sockets_bitmap = 0x1;
+		pr_err("No socket, please check cpus MPIDR_AFFINITY_LEVEL!");
+	} else
+		pr_info("mars3_sockets_bitmap = 0x%x\n", mars3_sockets_bitmap);
+
+	for (skt = 1; skt < MAX_MARS3_SOC_COUNT; skt++) {
+		if ((((unsigned int)1 << skt) & mars3_sockets_bitmap) == 0)
+			continue;
+
+		mars3_gic_dists[skt].phys_base = ((unsigned long)skt << MARS3_ADDR_SKTID_SHIFT) |
+						 mars3_gic_dists[0].phys_base;
+		mars3_gic_dists[skt].size =  mars3_gic_dists[0].size;
+		mars3_gic_dists[skt].dist_base = ioremap(mars3_gic_dists[skt].phys_base,
+							 mars3_gic_dists[skt].size);
+	}
+
+	size = sizeof(*acpi_data.redist_regs) * acpi_data.nr_redist_regions;
+	acpi_data.redist_regs = kzalloc(size, GFP_KERNEL);
+	if (!acpi_data.redist_regs) {
+		err = -ENOMEM;
+		goto out_dist_unmap;
+	}
+
+	err = gic_acpi_collect_gicr_base();
+	if (err)
+		goto out_redist_unmap;
+
+	domain_handle = irq_domain_alloc_fwnode(acpi_data.dist_base);
+	if (!domain_handle) {
+		err = -ENOMEM;
+		goto out_redist_unmap;
+	}
+
+	err = gic_init_bases(acpi_data.dist_base, acpi_data.redist_regs,
+			     acpi_data.nr_redist_regions, 0, domain_handle);
+	if (err)
+		goto out_fwhandle_free;
+
+	acpi_set_irq_model(ACPI_IRQ_MODEL_GIC, domain_handle);
+
+	if (static_branch_likely(&supports_deactivate_key))
+		gic_acpi_setup_kvm_info();
+
+	return 0;
+
+out_fwhandle_free:
+	irq_domain_free_fwnode(domain_handle);
+out_redist_unmap:
+	for (i = 0; i < acpi_data.nr_redist_regions; i++)
+		if (acpi_data.redist_regs[i].redist_base)
+			iounmap(acpi_data.redist_regs[i].redist_base);
+	kfree(acpi_data.redist_regs);
+out_dist_unmap:
+	iounmap(acpi_data.dist_base);
+	return err;
+}
+IRQCHIP_ACPI_DECLARE(gic_phyt_2500, ACPI_MADT_TYPE_PHYTIUM_2500,
+		     acpi_validate_gic_table, ACPI_MADT_GIC_VERSION_V3,
+		     gic_acpi_init);
+#endif
diff --git a/drivers/mmc/host/Kconfig b/drivers/mmc/host/Kconfig
index 694d0828215d..e119a89279d8 100644
--- a/drivers/mmc/host/Kconfig
+++ b/drivers/mmc/host/Kconfig
@@ -943,3 +943,9 @@ config MMC_SDHCI_OMAP
 	  If you have a controller with this interface, say Y or M here.
 
 	  If unsure, say N.
+
+config MMC_PHYTIUM_SDCI
+        tristate "Phytium FT SD Host Controller support"
+        depends on ARM64
+        help
+            This selects support for the Phytium FT4C SD Host Controller
diff --git a/drivers/mmc/host/Makefile b/drivers/mmc/host/Makefile
index ce8398e6f2c0..d5ef01778b0b 100644
--- a/drivers/mmc/host/Makefile
+++ b/drivers/mmc/host/Makefile
@@ -69,6 +69,7 @@ obj-$(CONFIG_MMC_SUNXI)		+= sunxi-mmc.o
 obj-$(CONFIG_MMC_USDHI6ROL0)	+= usdhi6rol0.o
 obj-$(CONFIG_MMC_TOSHIBA_PCI)	+= toshsd.o
 obj-$(CONFIG_MMC_BCM2835)	+= bcm2835.o
+obj-$(CONFIG_MMC_PHYTIUM_SDCI)	+= phytium-sdci.o
 
 obj-$(CONFIG_MMC_REALTEK_PCI)	+= rtsx_pci_sdmmc.o
 obj-$(CONFIG_MMC_REALTEK_USB)	+= rtsx_usb_sdmmc.o
diff --git a/drivers/mmc/host/phytium-sdci.c b/drivers/mmc/host/phytium-sdci.c
new file mode 100644
index 000000000000..cd6c17912050
--- /dev/null
+++ b/drivers/mmc/host/phytium-sdci.c
@@ -0,0 +1,1364 @@
+/*
+ * File Name: phytium_sdci.c - Phytium FT SDCI dirver
+ *
+ * Copyright (C) 2019 Phytium Technology Co.,Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#include <linux/module.h>
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/ioport.h>
+#include <linux/irq.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/of_gpio.h>
+#include <linux/pinctrl/consumer.h>
+#include <linux/platform_device.h>
+#include <linux/pm.h>
+#include <linux/pm_runtime.h>
+#include <linux/regulator/consumer.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/interrupt.h>
+#include <linux/acpi.h>
+#include <linux/timer.h>
+
+#include <linux/mmc/card.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/host.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+
+#include "phytium-sdci.h"
+
+static const u32 cmd_ints_mask = SDCI_SDCI_NORMAL_ISER_ECC_EN;
+static const u32 data_ints_mask = SDCI_BD_ISER_ETRS_EN;
+static const u32 err_ints_mask = SDCI_ERROR_ISER_ECTE_EN;
+static const u32 caps = MMC_CAP_ERASE | MMC_CAP_WAIT_WHILE_BUSY;
+
+static void hotplug_timer_func(struct timer_list *t);
+static bool phytium_sdci_private_send_cmd(struct phytium_sdci_host *host,
+					  u32 cmd, u32 resp_type, u32 arg);
+static bool phytium_sdci_cmd_done(struct phytium_sdci_host *host, int events,
+				  struct mmc_request *mrq,
+				  struct mmc_command *cmd);
+static bool phytium_sdci_data_xfer_done(struct phytium_sdci_host *host,
+					u32 events, struct mmc_request *mrq,
+					struct mmc_data *data);
+static void phytium_sdci_cmd_next(struct phytium_sdci_host *host,
+				  struct mmc_request *mrq,
+				  struct mmc_command *cmd);
+
+static int phytium_sd_error(struct phytium_sdci_host *host)
+{
+	int temp;
+	temp = readl(host->base + SDCI_NORMAL_ISR);
+	dev_err(host->dev, "[%s %d]SDCI_NORMAL_ISR:%x \n", __func__, __LINE__, temp);
+	temp = readl(host->base + SDCI_BD_ISR);
+	temp = readl(host->base + SDCI_ERROR_ISR);
+	dev_err(host->dev, "[%s %d]SDCI_ERROR_ISR:%x \n", __func__, __LINE__, temp);
+	temp = readl(host->base + SDCI_BD_ISR);
+	dev_err(host->dev, "[%s %d]SDCI_BD_ISR:%x \n", __func__, __LINE__, temp);
+	temp = readl(host->base + SDCI_RESP0);
+	dev_err(host->dev, "[%s %d]SDCI_RESP0:%x \n", __func__, __LINE__, temp);
+
+	return 0;
+}
+
+static void sdr_set_bits(void __iomem *reg, u32 bs)
+{
+	u32 val;
+
+	val = readl(reg);
+	val |= bs;
+
+	writel(val, reg);
+}
+
+static void sdr_clr_bits(void __iomem *reg, u32 bs)
+{
+	u32 val;
+
+	val = readl(reg);
+	val &= ~bs;
+
+	writel(val, reg);
+}
+
+static void phytium_sdci_reset_hw(struct phytium_sdci_host *host)
+{
+	sdr_set_bits(host->base + SDCI_SOFTWARE,
+		     SDCI_SOFTWARE_SRST);
+	udelay(1);
+	sdr_clr_bits(host->base + SDCI_SOFTWARE,
+		     SDCI_SOFTWARE_SRST);
+
+	while (!(readl(host->base + SDCI_STATUS) & SDCI_STATUS_IDIE))
+		cpu_relax();
+}
+
+static void phytium_sdci_prepare_data(struct phytium_sdci_host *host,
+				      struct mmc_request *mrq)
+{
+	struct mmc_data *data = mrq->data;
+	bool read;
+
+	read = (data->flags & MMC_DATA_READ) != 0;
+	data->sg_count = dma_map_sg(host->dev, data->sg, data->sg_len,
+				    read ? DMA_FROM_DEVICE : DMA_TO_DEVICE);
+}
+
+static void phytium_sdci_unprepare_data(struct phytium_sdci_host *host,
+					struct mmc_request *mrq)
+{
+	bool read;
+	struct mmc_data *data = mrq->data;
+
+	read = (data->flags & MMC_DATA_READ) != 0;
+	dma_unmap_sg(host->dev, data->sg, data->sg_len,
+		     read ? DMA_FROM_DEVICE : DMA_TO_DEVICE);
+}
+
+static void phytium_sdci_set_clk(struct phytium_sdci_host *host,
+				 struct mmc_ios *ios)
+{
+	unsigned long clk_rate;
+	u32 div = 0xffffffff;
+
+	if (ios->clock) {
+		clk_rate = host->clk_rate;
+		div = ((clk_rate / (2 * ios->clock)) - 1);
+		writel(div, host->base + SDCI_CLOCK_D);
+		writel(SDCI_SD_DRV_VALUE, host->base + SDCI_SD_DRV);
+
+		if (ios->clock > SDCI_F_MIN) {
+			writel(SDCI_SD_SAMP_VALUE_MIN, host->base + SDCI_SD_SAMP);
+		} else {
+			writel(SDCI_SD_SAMP_VALUE_MAX, host->base + SDCI_SD_SAMP);
+		}
+
+		dev_dbg(host->dev, "host->clk_rate: %ld, ios->clock: %d\n",
+			host->clk_rate, ios->clock);
+	}
+}
+
+
+static inline u32 phytium_sdci_cmd_find_resp(struct phytium_sdci_host *host,
+					     struct mmc_request *mrq,
+					     struct mmc_command *cmd)
+{
+	u32 resp;
+
+	switch (mmc_resp_type(cmd)) {
+	case MMC_RSP_R1:
+		resp = 0x2;
+		break;
+	case MMC_RSP_R1B:
+		resp = 0x2;
+		break;
+	case MMC_RSP_R2:
+		resp = 0x1;
+		break;
+	case MMC_RSP_R3:
+		resp = 0x3;
+		break;
+	case MMC_RSP_NONE:
+	default:
+		resp = 0x0;
+		break;
+	}
+
+	return resp;
+}
+
+static inline u32 phytium_sdci_cmd_prepare_raw_cmd(struct phytium_sdci_host *host,
+		struct mmc_request *mrq, struct mmc_command *cmd)
+{
+	/*
+	 * rawcmd :
+	 *   trty << 14 | opcode << 8 | cmdw << 6 | cice << 4 | crce << 3 | resp
+	 */
+	u32 resp, rawcmd;
+	u32 opcode = cmd->opcode;
+
+	resp = phytium_sdci_cmd_find_resp(host, mrq, cmd);
+	rawcmd = ((opcode << 8) | resp);
+
+	if ((cmd->flags & MMC_CMD_MASK) == MMC_CMD_ADTC) {
+		rawcmd = (rawcmd | (SDCI_CMD_TYPE_ADTC << 14));
+	}
+
+	return rawcmd;
+}
+
+static bool phytium_sdci_start_data(struct phytium_sdci_host *host, struct mmc_request *mrq,
+			    struct mmc_command *cmd, struct mmc_data *data)
+{
+	bool read, res;
+	u32 sg_dma_addrh, sg_dma_addrl;
+	u32 sd_block_addrh, sd_block_addrl;
+	u32 temp, timeout;
+	u32 block_cnt = 0;
+	u32 sd_block_addr = cmd->arg;
+	u32 private_cmd, resp_type, arg;
+	u32 j, dma_len;
+	unsigned long deadline_time, flags;
+	dma_addr_t dma_address;
+	struct scatterlist *sg;
+
+	WARN_ON(host->cmd);
+	host->cmd = cmd;
+
+	WARN_ON(host->data);
+	host->data = data;
+	read = data->flags & MMC_DATA_READ;
+
+	for_each_sg(data->sg, sg, data->sg_count, j) {
+		writel(0, host->base + SDCI_COMMAND);
+
+		dma_address = sg_dma_address(sg);
+		sg_dma_addrh = (u32) (dma_address >> 32);
+		sg_dma_addrl = (u32) dma_address;
+
+		dma_len = sg_dma_len(sg);
+		block_cnt = (dma_len / SD_BLOCK_SIZE);
+
+		sd_block_addrh = 0;
+		sd_block_addrl = sd_block_addr;
+
+		sdr_set_bits(host->base + SDCI_SOFTWARE, SDCI_SOFTWARE_BDRST);
+		sdr_clr_bits(host->base + SDCI_SOFTWARE, SDCI_SOFTWARE_BDRST);
+		writel(block_cnt, host->base + SDCI_BLK_CNT);
+
+		if ((mrq->data->flags & MMC_DATA_READ) == MMC_DATA_READ) {
+			writel(sg_dma_addrl, host->base + SDCI_BD_RX);
+			writel(sg_dma_addrh, host->base + SDCI_BD_RX);
+			writel(sd_block_addrl, host->base + SDCI_BD_RX);
+			writel(sd_block_addrh, host->base + SDCI_BD_RX);
+			timeout = 100 * block_cnt;
+		} else {
+			timeout = 250 * block_cnt;
+			deadline_time = jiffies + msecs_to_jiffies(timeout);
+			temp = 0xc00;
+			while (((temp >> 8) & 0x1f) != 0x9) {
+				private_cmd = MMC_SEND_STATUS;
+				resp_type = 0x2;
+				arg = host->current_rca;
+
+				res = phytium_sdci_private_send_cmd(host,
+								    private_cmd,
+								    resp_type,
+								    arg);
+				if (!res) {
+					spin_lock_irqsave(&host->lock, flags);
+					host->mrq = NULL;
+					spin_unlock_irqrestore(&host->lock, flags);
+
+					mrq->cmd->error = -ETIMEDOUT;
+					mmc_request_done(host->mmc, mrq);
+
+					dev_err(host->dev,
+						"[%s]cmd(%d) response timeout\n",
+						__func__, private_cmd);
+					phytium_sd_error(host);
+
+					return false;
+				}
+
+				temp = readl(host->base + SDCI_RESP0);
+
+				if (time_after(jiffies, deadline_time)) {
+					dev_err(host->dev,
+						"SD card not ready state timeout \n");
+					phytium_sd_error(host);
+					data->error = -ETIMEDOUT;
+
+					phytium_sdci_cmd_done(host,
+							      SDCI_NORMAL_ISR_CC,
+							      mrq, cmd);
+					phytium_sdci_data_xfer_done(host,
+								    SDCI_BD_ISR_EDTE,
+								    mrq, data);
+
+					return false;
+				}
+				mdelay(1);
+			}
+			writel(sg_dma_addrl, host->base + SDCI_BD_TX);
+			writel(sg_dma_addrh, host->base + SDCI_BD_TX);
+			writel(sd_block_addrl, host->base + SDCI_BD_TX);
+			writel(sd_block_addrh, host->base + SDCI_BD_TX);
+		}
+
+		deadline_time = jiffies + msecs_to_jiffies(1);
+		temp = readl(host->base + SDCI_NORMAL_ISR);
+		while ((temp & SDCI_NORMAL_ISR_CC) != SDCI_NORMAL_ISR_CC) {
+			temp = readl(host->base + SDCI_NORMAL_ISR);
+			if (time_after(jiffies, deadline_time)) {
+				dev_err(host->dev,
+					"%s_%d: cmd response timeout\n",
+					__func__, __LINE__);
+				phytium_sd_error(host);
+				spin_lock_irqsave(&host->lock, flags);
+				host->mrq = NULL;
+				spin_unlock_irqrestore(&host->lock, flags);
+				mrq->cmd->error = -ETIMEDOUT;
+				mmc_request_done(host->mmc, mrq);
+				return false;
+			}
+		}
+
+		writel(1, host->base + SDCI_NORMAL_ISR);
+		writel(0, host->base + SDCI_NORMAL_ISR);
+		deadline_time = jiffies + msecs_to_jiffies(timeout);
+
+		temp = readl(host->base + SDCI_BD_ISR);
+		if ((mrq->data->flags & MMC_DATA_READ) == MMC_DATA_READ) {
+			while ((temp & SDCI_BD_ISR_TRS_R) != SDCI_BD_ISR_TRS_R) {
+				temp = readl(host->base + SDCI_BD_ISR);
+				if (time_after(jiffies, deadline_time)) {
+					dev_err(host->dev,
+						"Read Data  timeout:jiffies:0x%lx, dt_jiffies:0x%lx \n",
+						jiffies, jiffies - deadline_time);
+					phytium_sd_error(host);
+					data->error = -ETIMEDOUT;
+					mmc_request_done(host->mmc, mrq);
+					return false;
+				}
+			}
+		} else {
+			while ((temp & SDCI_BD_ISR_TRS_W) != SDCI_BD_ISR_TRS_W) {
+				temp = readl(host->base + SDCI_BD_ISR);
+				if (time_after(jiffies, deadline_time)) {
+					dev_err(host->dev,
+						"Write Date timeout: jiffies:0x%lx, dt_jiffies:0x%lx\n",
+						jiffies, jiffies - deadline_time);
+					phytium_sd_error(host);
+					data->error = -ETIMEDOUT;
+					mmc_request_done(host->mmc, mrq);
+					return false;
+				}
+			}
+		}
+		writel(1, host->base + SDCI_BD_ISR);
+		writel(0, host->base + SDCI_BD_ISR);
+		sd_block_addr = sd_block_addr + block_cnt;
+
+		if (j < (data->sg_count - 1) && 1 < block_cnt) {
+			private_cmd = MMC_STOP_TRANSMISSION;
+			resp_type = 0x2;
+			arg = 0;
+			res = phytium_sdci_private_send_cmd(host, private_cmd,
+							    resp_type, arg);
+			if (!res) {
+				spin_lock_irqsave(&host->lock, flags);
+				host->mrq = NULL;
+				spin_unlock_irqrestore(&host->lock, flags);
+				mrq->cmd->error = -ETIMEDOUT;
+				mmc_request_done(host->mmc, mrq);
+				dev_err(host->dev,
+					"[%s]cmd(%d) response timeout \n",
+					__func__, __LINE__);
+				phytium_sd_error(host);
+				return false;
+			}
+		}
+	}
+
+	phytium_sdci_cmd_done(host, SDCI_NORMAL_ISR_CC, mrq, cmd);
+	if ((mrq->data->flags & MMC_DATA_READ) == MMC_DATA_READ)
+		phytium_sdci_data_xfer_done(host, SDCI_BD_ISR_TRS_R,
+					    mrq, data);
+	else
+		phytium_sdci_data_xfer_done(host, SDCI_BD_ISR_TRS_W,
+					    mrq, data);
+
+	return true;
+}
+
+static int phytium_sdci_auto_cmd_done(struct phytium_sdci_host *host,
+				      int events, struct mmc_command *cmd)
+{
+	u32 *rsp = cmd->resp;
+
+	rsp[0] = readl(host->base + SDCI_RESP0);
+
+	if (events & SDCI_NORMAL_ISR_CC)
+		cmd->error = 0;
+	else {
+		phytium_sdci_reset_hw(host);
+		dev_err(host->dev,
+			"%s: AUTO_CMD%d arg=%08X; rsp %08X; cmd_error=%d\n",
+			__func__, cmd->opcode, cmd->arg, rsp[0], cmd->error);
+	}
+
+	return cmd->error;
+}
+
+static void phytium_sdci_track_cmd_data(struct phytium_sdci_host *host,
+					struct mmc_command *cmd,
+					struct mmc_data *data)
+{
+	if (host->error)
+		dev_dbg(host->dev, "%s: cmd=%d arg=%08X; host->error=0x%08X\n",
+			__func__, cmd->opcode, cmd->arg, host->error);
+}
+
+static void phytium_sdci_request_done(struct phytium_sdci_host *host,
+				      struct mmc_request *mrq)
+{
+	unsigned long flags;
+
+        dev_dbg(host->dev,
+		"%s_%d:mrq->cmd->opcode:%d, mrq->cmd->arg:0x%x resp 0x%x 0x%x 0x%x 0x%x\n",
+		__func__, __LINE__, mrq->cmd->opcode, mrq->cmd->arg,
+		mrq->cmd->resp[0], mrq->cmd->resp[1], mrq->cmd->resp[2],
+		mrq->cmd->resp[3]);
+
+	spin_lock_irqsave(&host->lock, flags);
+	host->mrq = NULL;
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	phytium_sdci_track_cmd_data(host, mrq->cmd, mrq->data);
+	if (mrq->data)
+		phytium_sdci_unprepare_data(host, mrq);
+	mmc_request_done(host->mmc, mrq);
+}
+
+/* returns true if command is fully handled; returns false otherwise */
+static bool phytium_sdci_cmd_done(struct phytium_sdci_host *host, int events,
+				  struct mmc_request *mrq,
+				  struct mmc_command *cmd)
+{
+	bool done = false;
+	bool sbc_error;
+	unsigned long flags;
+	u32 *rsp = cmd->resp;
+
+	if (mrq->sbc && cmd == mrq->cmd &&
+	    (events & SDCI_NORMAL_ISR_CC))
+		phytium_sdci_auto_cmd_done(host, events, mrq->sbc);
+
+	sbc_error = mrq->sbc && mrq->sbc->error;
+
+	if (!sbc_error && !(events & (SDCI_NORMAL_ISR_CC |
+				      SDCI_NORMAL_ISR_CR |
+				      SDCI_NORMAL_ISR_TIMEOUT)))
+		return done;
+
+	spin_lock_irqsave(&host->lock, flags);
+	done = !host->cmd;
+	host->cmd = NULL;
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	if (done)
+		return true;
+
+	sdr_clr_bits(host->base + SDCI_NORMAL_ISER, cmd_ints_mask);
+
+	if (cmd->flags & MMC_RSP_PRESENT) {
+		if (cmd->flags & MMC_RSP_136) {
+			rsp[0] = readl(host->base + SDCI_RESP0);
+			rsp[1] = readl(host->base + SDCI_RESP1);
+			rsp[2] = readl(host->base + SDCI_RESP2);
+			rsp[3] = readl(host->base + SDCI_RESP3);
+		} else
+			rsp[0] = readl(host->base + SDCI_RESP0);
+
+		if(cmd->opcode == SD_SEND_RELATIVE_ADDR)
+			host->current_rca = rsp[0] & 0xFFFF0000;
+	}
+
+	if (!sbc_error &&
+	    !(events & SDCI_NORMAL_ISR_CC) &&
+	    (events & SDCI_NORMAL_ISR_TIMEOUT))
+		cmd->error = -ETIMEDOUT;
+
+	if (cmd->error)
+		dev_dbg(host->dev,
+			"%s: cmd=%d arg=%08X; rsp %08X; cmd_error=%d\n",
+			__func__, cmd->opcode, cmd->arg, rsp[0],
+			cmd->error);
+
+	phytium_sdci_cmd_next(host, mrq, cmd);
+
+	return true;
+}
+
+static bool set_databus_width(struct phytium_sdci_host *host)
+{
+	bool res;
+	u32 cmd, resp_type, arg;
+
+	cmd = SD_APP_SET_BUS_WIDTH;
+	resp_type = 0x2;
+	arg = 0x2;
+	res = phytium_sdci_private_send_cmd(host, cmd, resp_type, arg);
+	if (!res)
+		return false;
+
+	cmd = MMC_APP_CMD;
+	resp_type = 0x2;
+	arg = host->current_rca;
+	res = phytium_sdci_private_send_cmd(host, cmd, resp_type, arg);
+	if (!res)
+		return false;
+
+	return true;
+}
+
+
+static void phytium_sdci_start_command(struct phytium_sdci_host *host,
+				       struct mmc_request *mrq,
+				       struct mmc_command *cmd)
+{
+	u32 rawcmd;
+	struct mmc_data *data = mrq->data;
+	dma_addr_t dma_adtc_buf;
+	u32 dma_bufh,dma_bufl;
+	u32 block_cnt = 0;
+
+	WARN_ON(host->cmd);
+	host->cmd = cmd;
+
+	cmd->error = 0;
+	rawcmd = phytium_sdci_cmd_prepare_raw_cmd(host, mrq, cmd);
+
+	sdr_set_bits(host->base + SDCI_NORMAL_ISER, cmd_ints_mask);
+	writel(rawcmd, host->base + SDCI_COMMAND);
+
+	if ((cmd->flags & MMC_CMD_MASK) == MMC_CMD_ADTC) {
+		WARN_ON(host->data);
+		host->data = data;
+
+		dma_adtc_buf = host->dma_rx.bd_addr;
+		dma_bufh = (u32) (dma_adtc_buf >> 32);
+		dma_bufl = (u32) dma_adtc_buf;
+		block_cnt = mrq->data->blocks;
+		sdr_set_bits(host->base + SDCI_BD_ISER, data_ints_mask);
+		writel(block_cnt, host->base + SDCI_BLK_CNT);
+
+		if ((mrq->data->flags & MMC_DATA_READ) == MMC_DATA_READ) {
+			writel(dma_bufl, host->base + SDCI_BD_RX);
+			writel(dma_bufh, host->base + SDCI_BD_RX);
+			writel(cmd->arg, host->base + SDCI_BD_RX);
+			writel(0, host->base + SDCI_BD_RX);
+		} else {
+			writel(dma_bufl, host->base + SDCI_BD_TX);
+			writel(dma_bufh, host->base + SDCI_BD_TX);
+			writel(cmd->arg, host->base + SDCI_BD_TX);
+			writel(0, host->base + SDCI_BD_TX);
+		}
+	} else
+		writel(cmd->arg, host->base + SDCI_ARGUMENT);
+
+}
+
+static void phytium_sdci_cmd_next(struct phytium_sdci_host *host,
+				  struct mmc_request *mrq,
+				  struct mmc_command *cmd)
+{
+	if (cmd->error || (mrq->sbc && mrq->sbc->error))
+		phytium_sdci_request_done(host, mrq);
+	else if (cmd == mrq->sbc)
+		phytium_sdci_start_command(host, mrq, mrq->cmd);
+	else if (!cmd->data)
+		phytium_sdci_request_done(host, mrq);
+}
+
+static bool phytium_sdci_erase_process(struct phytium_sdci_host *host,
+				       struct mmc_request *mrq)
+{
+	u32 private_cmd, resp_type, arg, temp;
+	unsigned long deadline_time;
+	unsigned long flags;
+	bool res;
+
+	private_cmd = mrq->cmd->opcode;
+	resp_type = 0x2;
+	arg = mrq->cmd->arg;
+
+	deadline_time = jiffies + msecs_to_jiffies(1000);
+	do {
+		temp = readl(host->base + SDCI_NORMAL_ISR);
+		if (time_after(jiffies, deadline_time)) {
+			dev_err(host->dev, "SD control not ready to erase!\n");
+			return false;
+		}
+	} while ((temp & SDCI_NORMAL_ISR_CC) != SDCI_NORMAL_ISR_CC);
+
+	res = phytium_sdci_private_send_cmd(host, private_cmd, resp_type, arg);
+	if (!res) {
+		spin_lock_irqsave(&host->lock, flags);
+		host->mrq = NULL;
+		spin_unlock_irqrestore(&host->lock, flags);
+		mrq->cmd->error = -ETIMEDOUT;
+		mmc_request_done(host->mmc, mrq);
+		dev_err(host->dev, "[%s]cmd(%d) response timeout \n", __func__, mrq->cmd->opcode);
+		phytium_sd_error(host);
+		return false;
+	}
+
+	return true;
+}
+
+static bool phytium_sdci_cmd13_process(struct phytium_sdci_host *host,
+				       struct mmc_request *mrq)
+{
+	u32 private_cmd, resp_type, arg, temp;
+	unsigned long deadline_time;
+	bool res;
+
+	private_cmd = MMC_SEND_STATUS;
+	resp_type = 0x2;
+	arg = mrq->cmd->arg;
+
+	deadline_time = jiffies + msecs_to_jiffies(1000);
+	temp = 0xc00;
+	while (((temp >> 8) & 0x1f) != 0x9) {
+		private_cmd = MMC_SEND_STATUS;
+		resp_type = 0x2;
+		arg = host->current_rca;
+		res = phytium_sdci_private_send_cmd(host, private_cmd,
+						    resp_type, arg);
+		if (!res)
+			return false;
+
+		temp = readl(host->base + SDCI_RESP0);
+
+		if (time_after(jiffies, deadline_time))
+			return false;
+
+		mdelay(5);
+	}
+
+	return true;
+}
+
+static void phytium_sdci_ops_request(struct mmc_host *mmc,
+				     struct mmc_request *mrq)
+{
+	struct phytium_sdci_host *host = mmc_priv(mmc);
+	unsigned long flags;
+	bool res;
+
+	host->error = 0;
+	WARN_ON(host->mrq);
+	host->mrq = mrq;
+
+        dev_dbg(host->dev,
+		"phytium_sdci_ops_request:mrq->cmd->opcode:%d, mrq->cmd->arg:0x%x \n",
+		mrq->cmd->opcode, mrq->cmd->arg);
+
+	if (mrq->cmd->opcode == MMC_SEND_STATUS) {
+		u32 status = readl(host->base + SDCI_STATUS);
+		if ((status >> 19) & 0x1) {
+			spin_lock_irqsave(&host->lock, flags);
+			host->mrq = NULL;
+			spin_unlock_irqrestore(&host->lock, flags);
+			mrq->cmd->error = -ETIMEDOUT;
+			mmc_request_done(host->mmc, mrq);
+			dev_err(host->dev, "[%s]cmd(%d) response timeout\n", __func__,
+				mrq->cmd->opcode);
+			phytium_sd_error(host);
+			return;
+		}
+		phytium_sdci_cmd13_process(host, mrq);
+	}
+
+	if (mrq->data){
+		phytium_sdci_prepare_data(host, mrq);
+		if (mrq->cmd->opcode == MMC_READ_MULTIPLE_BLOCK ||
+		    mrq->cmd->opcode == MMC_READ_SINGLE_BLOCK ||
+		    mrq->cmd->opcode == MMC_WRITE_MULTIPLE_BLOCK ||
+		    mrq->cmd->opcode == MMC_WRITE_BLOCK) {
+			host->adtc_type = BLOCK_RW_ADTC;
+			phytium_sdci_start_data(host, mrq,
+						mrq->cmd, mrq->data);
+			return;
+		}
+		host->adtc_type = COMMOM_ADTC;
+	}
+
+	if (mrq->cmd->opcode == SD_IO_RW_DIRECT ||
+	    mrq->cmd->opcode == SD_IO_SEND_OP_COND) {
+		spin_lock_irqsave(&host->lock, flags);
+		host->mrq = NULL;
+		spin_unlock_irqrestore(&host->lock, flags);
+		mrq->cmd->error = -EINVAL;
+		mmc_request_done(host->mmc, mrq);
+
+		return;
+	}
+
+	if (mrq->cmd->opcode == SD_APP_SEND_SCR) {
+		res = set_databus_width(host);
+		if (!res) {
+			spin_lock_irqsave(&host->lock, flags);
+			host->mrq = NULL;
+			spin_unlock_irqrestore(&host->lock, flags);
+			mrq->cmd->error = -ETIMEDOUT;
+			mmc_request_done(host->mmc, mrq);
+			dev_err(host->dev, "cmd(%d) response timeout\n",
+				mrq->cmd->opcode);
+			return;
+		}
+	}
+
+	if ((mrq->cmd->opcode == SD_ERASE_WR_BLK_START) ||
+	    (mrq->cmd->opcode == SD_ERASE_WR_BLK_END) ||
+	    (mrq->cmd->opcode == MMC_ERASE))
+		phytium_sdci_erase_process(host, mrq);
+
+	/* if SBC is required, we have HW option and SW option.
+	 * if HW option is enabled, and SBC does not have "special" flags,
+	 * use HW option,  otherwise use SW option
+	 */
+	if (mrq->sbc &&
+	    (!mmc_card_mmc(mmc->card) || (mrq->sbc->arg & 0xFFFF0000)))
+		phytium_sdci_start_command(host, mrq, mrq->sbc);
+	else
+		phytium_sdci_start_command(host, mrq, mrq->cmd);
+}
+
+static void phytium_sdci_data_xfer_next(struct phytium_sdci_host *host,
+					struct mmc_request *mrq,
+					struct mmc_data *data)
+{
+	if (mmc_op_multi(mrq->cmd->opcode) &&
+	    mrq->stop && !mrq->stop->error &&
+	    !mrq->sbc)
+		phytium_sdci_start_command(host, mrq, mrq->stop);
+	else
+		phytium_sdci_request_done(host, mrq);
+}
+
+static inline void get_data_buffer(struct mmc_data *data,
+				   u32 *bytes, u32 **pointer)
+{
+	struct scatterlist *sg;
+
+	sg = &data->sg[0];
+	*bytes = sg->length;
+	*pointer = sg_virt(sg);
+}
+
+static bool phytium_sdci_data_xfer_done(struct phytium_sdci_host *host,
+					u32 events, struct mmc_request *mrq,
+					struct mmc_data *data)
+{
+	struct mmc_command *stop = data->stop;
+	unsigned long flags;
+	bool done;
+	unsigned int check_data;
+	u32 sg_length,i;
+	u32 *sg_virt_addr;
+
+	check_data = events & (SDCI_BD_ISR_TRS_R | SDCI_BD_ISR_TRS_W | SDCI_BD_ISR_EDTE);
+
+	spin_lock_irqsave(&host->lock, flags);
+	done = !host->data;
+	if (check_data)
+		host->data = NULL;
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	if (done)
+		return true;
+
+	if (check_data || (stop && stop->error)) {
+		sdr_clr_bits(host->base + SDCI_BD_ISER, data_ints_mask);
+		dev_dbg(host->dev, "DMA stop\n");
+
+		 if (((events & SDCI_BD_ISR_TRS_R) ||
+		     (events & SDCI_BD_ISR_TRS_W)) &&
+		     (!stop || !stop->error)) {
+			if ((mrq->cmd->flags & MMC_CMD_MASK) == MMC_CMD_ADTC &&
+			    (host->adtc_type == COMMOM_ADTC)) {
+				get_data_buffer(data, &sg_length,
+						&host->sg_virt_addr);
+				sg_virt_addr = host->sg_virt_addr;
+
+				for (i = 0; i < (sg_length/4); i++) {
+					*sg_virt_addr = host->dma_rx.buf[i];
+					sg_virt_addr++;
+				}
+			}
+			data->bytes_xfered = data->blocks * data->blksz;
+		} else {
+			dev_dbg(host->dev, "interrupt events: %x\n", events);
+			phytium_sdci_reset_hw(host);
+			data->bytes_xfered = 0;
+			dev_dbg(host->dev, "%s: cmd=%d; blocks=%d",
+				__func__, mrq->cmd->opcode, data->blocks);
+			dev_dbg(host->dev, "data_error=%d xfer_size=%d\n",
+				(int)data->error, data->bytes_xfered);
+		}
+
+		phytium_sdci_data_xfer_next(host, mrq, data);
+		done = true;
+	}
+
+	return done;
+}
+
+
+static int phytium_sdci_card_busy(struct mmc_host *mmc)
+{
+	struct phytium_sdci_host *host = mmc_priv(mmc);
+	u32 status;
+
+	/* check if any pin between dat[0:3] is low */
+	status = readl(host->base + SDCI_STATUS);
+	if (((status >> 20) & 0xf) != 0xf)
+		return 1;
+
+	return 0;
+}
+
+static void phytium_sdci_request_timeout(struct work_struct *work)
+{
+	struct phytium_sdci_host *host;
+
+	host = container_of(work, struct phytium_sdci_host, req_timeout.work);
+	dev_err(host->dev, "%s: aborting cmd/data/mrq\n", __func__);
+	if (host->mrq) {
+		dev_err(host->dev, "%s: aborting mrq=%p cmd=%d\n", __func__,
+			host->mrq, host->mrq->cmd->opcode);
+		if (host->cmd) {
+			dev_err(host->dev, "%s: aborting cmd=%d\n",
+				__func__, host->cmd->opcode);
+			phytium_sdci_cmd_done(host, SDCI_NORMAL_ISR_TIMEOUT,
+					      host->mrq, host->cmd);
+		} else if (host->data) {
+			dev_err(host->dev, "%s: abort data: cmd%d; %d blocks\n",
+				__func__, host->mrq->cmd->opcode,
+				host->data->blocks);
+			phytium_sdci_data_xfer_done(host, SDCI_BD_ISR_EDTE,
+						    host->mrq, host->data);
+		}
+	}
+}
+
+static void hotplug_timer_func(struct timer_list *t)
+{
+	struct phytium_sdci_host *host;
+	u32 status;
+
+	host = from_timer(host, t, hotplug_timer);
+	if (!host)
+		dev_err(host->dev, "%s: Not find host!\n", __func__);
+	status = readl(host->base + SDCI_STATUS);
+
+	if ((status >> 19) & 0x1) {
+		cancel_delayed_work(&host->mmc->detect);
+		mmc_detect_change(host->mmc, msecs_to_jiffies(1));
+	} else {
+		cancel_delayed_work(&host->mmc->detect);
+		mmc_detect_change(host->mmc, msecs_to_jiffies(1000));
+	}
+}
+
+static irqreturn_t phytium_sdci_irq(int irq, void *dev_id)
+{
+	struct phytium_sdci_host *host = (struct phytium_sdci_host *) dev_id;
+	unsigned long flags;
+	struct mmc_request *mrq;
+	struct mmc_command *cmd;
+	u32 events;
+
+	spin_lock_irqsave(&host->lock, flags);
+	events = readl(host->base + SDCI_NORMAL_ISR);
+	/* clear interrupts */
+	writel(1, host->base + SDCI_NORMAL_ISR);
+	writel(0, host->base + SDCI_NORMAL_ISR);
+
+	mrq = host->mrq;
+	cmd = host->cmd;
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	if (events & (SDCI_NORMAL_ISR_CR | SDCI_NORMAL_ISR_CI)) {
+		mod_timer(&host->hotplug_timer,
+			  jiffies + usecs_to_jiffies(30000));
+		goto irq_out;
+	}
+
+	if (!(events & cmd_ints_mask))
+		goto irq_out;
+
+	if (!mrq) {
+		dev_err(host->dev, "%s: MRQ=NULL; events=%08X\n",
+			__func__, events);
+		WARN_ON(1);
+		goto irq_out;
+	}
+
+	dev_dbg(host->dev, "%s: events=%08X\n", __func__, events);
+
+	if (cmd)
+		phytium_sdci_cmd_done(host, events, mrq, cmd);
+
+irq_out:
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t phytium_sdci_dma_irq(int irq, void *dev_id)
+{
+	struct phytium_sdci_host *host = (struct phytium_sdci_host *) dev_id;
+	unsigned long flags;
+	struct mmc_request *mrq;
+	struct mmc_command *cmd;
+	struct mmc_data *data;
+	u32 events;
+
+	spin_lock_irqsave(&host->lock, flags);
+	events = readl(host->base + SDCI_BD_ISR);
+	writel(1, host->base + SDCI_BD_ISR);
+	writel(0, host->base + SDCI_BD_ISR);
+
+	mrq = host->mrq;
+	cmd = host->cmd;
+	data = host->data;
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	if (!(events & data_ints_mask)){
+		goto dma_irq_out;
+	}
+
+	if (!mrq) {
+		dev_err(host->dev,
+			"%s: MRQ=NULL; events=%08X\n",
+			__func__, events);
+		WARN_ON(1);
+		goto dma_irq_out;
+	}
+
+	dev_dbg(host->dev, "%s: events=%08X\n", __func__, events);
+
+	if (data)
+		phytium_sdci_data_xfer_done(host, events, mrq, data);
+
+dma_irq_out:
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t phytium_sdci_err_irq(int irq, void *dev_id)
+{
+	struct phytium_sdci_host *host = (struct phytium_sdci_host *) dev_id;
+	unsigned long flags;
+	u32 events;
+
+	spin_lock_irqsave(&host->lock, flags);
+	events = readl(host->base + SDCI_ERROR_ISR);
+	writel(1, host->base + SDCI_ERROR_ISR);
+	writel(0, host->base + SDCI_ERROR_ISR);
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	return IRQ_HANDLED;
+}
+
+static void phytium_sdci_init_hw(struct phytium_sdci_host *host)
+{
+	u32 val;
+
+	/* Reset */
+	phytium_sdci_reset_hw(host);
+
+	/* Disable card detection */
+	writel(0,host->base + SDCI_SD_SEN);
+
+	/* Disable and clear all interrupts */
+	writel(0, host->base + SDCI_NORMAL_ISER);
+	writel(0, host->base + SDCI_ERROR_ISER);
+	writel(0, host->base + SDCI_BD_ISER);
+
+	writel(0, host->base + SDCI_NORMAL_ISR);
+	writel(0, host->base + SDCI_ERROR_ISR);
+	writel(0, host->base + SDCI_BD_ISR);
+
+	sdr_set_bits(host->base + SDCI_NORMAL_ISER,
+		     SDCI_SDCI_NORMAL_ISER_ECI|SDCI_SDCI_NORMAL_ISER_ECR);
+	/* Configure to default cmd timeout */
+	writel(SDCI_TIMEOUT_CMD_VALUE,host->base + SDCI_TIMEOUT_CMD);
+
+	val = 0x0F00;
+	writel(val,host->base + SDCI_CONTROLLER);
+
+	dev_dbg(host->dev, "init hardware done!");
+}
+
+static void phytium_sdci_deinit_hw(struct phytium_sdci_host *host)
+{
+	/* Disable and clear all interrupts */
+	writel(0, host->base + SDCI_NORMAL_ISER);
+	writel(0, host->base + SDCI_ERROR_ISER);
+	writel(0, host->base + SDCI_BD_ISER);
+
+	writel(0, host->base + SDCI_NORMAL_ISR);
+	writel(0, host->base + SDCI_ERROR_ISR);
+	writel(0, host->base + SDCI_BD_ISR);
+}
+
+static void phytium_sdci_ops_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct phytium_sdci_host *host = mmc_priv(mmc);
+
+	if (ios->bus_width == MMC_BUS_WIDTH_4)
+		mmc->caps = mmc->caps & (~MMC_CAP_4_BIT_DATA);
+
+	/* Suspend/Resume will do power off/on */
+	switch (ios->power_mode) {
+	case MMC_POWER_UP:
+		writel(SDCI_POWER_ON, host->base + SDCI_POWER);
+		break;
+	case MMC_POWER_ON:
+		phytium_sdci_set_clk(host, ios);
+		break;
+	case MMC_POWER_OFF:
+		writel(SDCI_POWER_OFF, host->base + SDCI_POWER);
+		break;
+	default:
+		break;
+	}
+}
+
+static int phytium_sdci_get_cd(struct mmc_host *mmc)
+{
+	struct phytium_sdci_host *host = mmc_priv(mmc);
+	u32 status = readl(host->base + SDCI_STATUS);
+
+	if (((status >> 19) & 0x1) == 0x1)
+		return 0;
+
+	return 1;
+}
+
+static void phytium_sdci_hw_reset(struct mmc_host *mmc)
+{
+	struct phytium_sdci_host *host = mmc_priv(mmc);
+
+	sdr_set_bits(host->base + SDCI_SOFTWARE, SDCI_SOFTWARE_SRST);
+	udelay(1); /* 1us is enough */
+	sdr_clr_bits(host->base + SDCI_SOFTWARE, SDCI_SOFTWARE_SRST);
+}
+
+static struct mmc_host_ops phytium_sdci_ops = {
+	.request = phytium_sdci_ops_request,
+	.set_ios = phytium_sdci_ops_set_ios,
+	.get_cd = phytium_sdci_get_cd,
+	.card_busy = phytium_sdci_card_busy,
+	.hw_reset = phytium_sdci_hw_reset,
+};
+
+static bool phytium_sdci_private_send_cmd(struct phytium_sdci_host *host,
+					  u32 cmd, u32 resp_type,u32 arg)
+{
+	u32 temp,sd_cmd,sd_arg;
+	unsigned long deadline_time;
+
+	writel(1, host->base + SDCI_NORMAL_ISR);
+	writel(0, host->base + SDCI_NORMAL_ISR);
+	writel(1, host->base + SDCI_ERROR_ISR);
+	writel(0, host->base + SDCI_ERROR_ISR);
+
+	sd_cmd = (cmd << 8) | resp_type;
+	sd_arg = arg;
+	writel(sd_cmd, host->base + SDCI_COMMAND);
+	writel(sd_arg, host->base + SDCI_ARGUMENT);
+
+	if (cmd == SD_ERASE_WR_BLK_START ||
+	    cmd == SD_ERASE_WR_BLK_END ||
+	    cmd == MMC_ERASE)
+		deadline_time = jiffies + msecs_to_jiffies(10000);
+	else if (cmd == MMC_STOP_TRANSMISSION)
+		deadline_time = jiffies + msecs_to_jiffies(1000);
+	else
+		deadline_time = jiffies + msecs_to_jiffies(1);
+
+	temp = readl(host->base + SDCI_NORMAL_ISR);
+	while ((temp & SDCI_NORMAL_ISR_CC) != SDCI_NORMAL_ISR_CC) {
+		temp = readl(host->base + SDCI_NORMAL_ISR);
+		if (time_after(jiffies, deadline_time))
+			return false;
+
+		if (cmd == MMC_STOP_TRANSMISSION ||
+		    cmd == SD_ERASE_WR_BLK_START ||
+		    cmd == SD_ERASE_WR_BLK_END ||
+		    cmd == MMC_ERASE)
+			mdelay(1);
+	}
+
+	return true;
+}
+
+static int phytium_sdci_probe(struct platform_device *pdev)
+{
+	struct mmc_host *mmc;
+	struct phytium_sdci_host *host;
+	struct resource *res;
+	int ret;
+	const struct acpi_device_id *match;
+	struct device *dev = &pdev->dev;
+
+	dev_info(dev, "%s: \n",__func__);
+	if (dev->of_node) {
+		/* Allocate MMC host for this device */
+		mmc = mmc_alloc_host(sizeof(struct phytium_sdci_host), &pdev->dev);
+		if (!mmc)
+			return -ENOMEM;
+
+		host = mmc_priv(mmc);
+		ret = mmc_of_parse(mmc);
+		if (ret)
+			goto host_free;
+
+		host->src_clk = devm_clk_get(&pdev->dev, "phytium_sdc_clk");
+		if (IS_ERR(host->src_clk)) {
+			ret = PTR_ERR(host->src_clk);
+			goto host_free;
+		}
+
+		host->clk_rate = clk_get_rate(host->src_clk);
+
+	} else if (has_acpi_companion(dev)) {
+		match = acpi_match_device(dev->driver->acpi_match_table, dev);
+		if (!match) {
+			dev_err(dev, "Error ACPI match data is missing\n");
+			return -ENODEV;
+		}
+
+		acpi_dma_configure(dev, DEV_DMA_NOT_SUPPORTED);
+
+		/* Allocate MMC host for this device */
+		mmc = mmc_alloc_host(sizeof(struct phytium_sdci_host), &pdev->dev);
+		if (!mmc)
+			return -ENOMEM;
+
+		host = mmc_priv(mmc);
+
+		host->clk_rate = 600000000;
+	} else {
+		dev_err(&pdev->dev, "No DT found\n");
+		return -EINVAL;
+	}
+
+	dma_set_mask(dev, DMA_BIT_MASK(40));
+	dma_set_coherent_mask(dev, DMA_BIT_MASK(40));
+
+	timer_setup(&host->hotplug_timer, hotplug_timer_func, 0);
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	host->base = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(host->base)) {
+		ret = PTR_ERR(host->base);
+		goto host_free;
+	}
+
+	host->irq = platform_get_irq(pdev, 1);
+	if (host->irq < 0) {
+		ret = -EINVAL;
+		goto host_free;
+	}
+
+	host->irq_err = platform_get_irq(pdev, 2);
+	if (host->irq_err < 0) {
+		ret = -EINVAL;
+		goto host_free;
+	}
+
+	host->irq_bd = platform_get_irq(pdev, 0);
+	if (host->irq_bd < 0) {
+		ret = -EINVAL;
+		goto host_free;
+	}
+
+	host->caps = caps;
+	host->dev = &pdev->dev;
+	host->mmc = mmc;
+
+	if((4 * SDCI_F_MAX) > host->clk_rate)
+		host->clk_div	= 1;
+	else
+		host->clk_div	= ((host->clk_rate / (2 * SDCI_F_MAX)) - 1);
+
+	/* Set host parameters to mmc */
+	mmc->f_min 	= SDCI_F_MIN;
+	mmc->f_max 	= (host->clk_rate / ((host->clk_div + 1) * 2));
+	mmc->ops = &phytium_sdci_ops;
+	mmc->ocr_avail	= MMC_VDD_32_33 | MMC_VDD_33_34;
+
+	mmc->caps |= host->caps;
+	/* MMC core transfer sizes tunable parameters */
+	mmc->max_segs = MAX_BD_NUM;
+	mmc->max_seg_size = 512 * 1024;
+	mmc->max_blk_size = 512;
+	mmc->max_req_size = 512 * 1024;
+	mmc->max_blk_count = mmc->max_req_size / 512;
+
+	host->dma_rx.buf = dma_zalloc_coherent(&pdev->dev,
+					       MAX_BD_NUM,
+					       &host->dma_rx.bd_addr,
+					       GFP_KERNEL);
+	if (!host->dma_rx.buf){
+		ret = -ENOMEM;
+		goto release_mem;
+	}
+
+	host->cmd_timeout = msecs_to_jiffies(100);
+	host->data_timeout = msecs_to_jiffies(250);
+
+	INIT_DELAYED_WORK(&host->req_timeout, phytium_sdci_request_timeout);
+	spin_lock_init(&host->lock);
+
+	platform_set_drvdata(pdev, mmc);
+	phytium_sdci_init_hw(host);
+
+	ret = devm_request_irq(&pdev->dev, host->irq, phytium_sdci_irq,
+			       IRQF_SHARED, pdev->name, host);
+	if (ret)
+		goto release;
+
+	ret = devm_request_irq(&pdev->dev, host->irq_err, phytium_sdci_err_irq,
+			       IRQF_SHARED, pdev->name, host);
+	if (ret)
+		goto release;
+
+	ret = devm_request_irq(&pdev->dev, host->irq_bd, phytium_sdci_dma_irq,
+			       IRQF_SHARED, pdev->name, host);
+	if (ret)
+		goto release;
+
+	ret = mmc_add_host(mmc);
+	if (ret)
+		goto release;
+
+	return 0;
+
+release:
+	platform_set_drvdata(pdev, NULL);
+	phytium_sdci_deinit_hw(host);
+release_mem:
+	if (host->dma_rx.buf)
+		dma_free_coherent(&pdev->dev, MAX_BD_NUM,
+				  host->dma_rx.buf,
+				  host->dma_rx.bd_addr);
+host_free:
+	mmc_free_host(mmc);
+
+	return ret;
+}
+
+static int phytium_sdci_remove(struct platform_device *pdev)
+{
+	struct mmc_host *mmc;
+	struct phytium_sdci_host *host;
+
+	mmc = platform_get_drvdata(pdev);
+	host = mmc_priv(mmc);
+
+	cancel_delayed_work_sync(&host->req_timeout);
+	platform_set_drvdata(pdev, NULL);
+	mmc_remove_host(host->mmc);
+	phytium_sdci_deinit_hw(host);
+
+	if (host->dma_rx.buf)
+		dma_free_coherent(&pdev->dev, MAX_BD_NUM,
+				  host->dma_rx.buf, host->dma_rx.bd_addr);
+
+	mmc_free_host(host->mmc);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM_SLEEP
+static int phytium_sdci_suspend(struct device *dev)
+{
+	struct mmc_host *mmc = dev_get_drvdata(dev);
+	struct phytium_sdci_host *host = mmc_priv(mmc);
+
+	phytium_sdci_deinit_hw(host);
+	return 0;
+}
+
+static int phytium_sdci_resume(struct device *dev)
+{
+	struct mmc_host *mmc = dev_get_drvdata(dev);
+	struct phytium_sdci_host *host = mmc_priv(mmc);
+
+	phytium_sdci_init_hw(host);
+	mmc->caps = mmc->caps | MMC_CAP_4_BIT_DATA;
+
+	return 0;
+}
+#endif
+
+#ifdef CONFIG_PM
+static int phytium_sdci_runtime_suspend(struct device *dev)
+{
+	struct mmc_host *mmc = dev_get_drvdata(dev);
+	struct phytium_sdci_host *host = mmc_priv(mmc);
+
+	phytium_sdci_deinit_hw(host);
+
+	return 0;
+}
+
+static int phytium_sdci_runtime_resume(struct device *dev)
+{
+	struct mmc_host *mmc = dev_get_drvdata(dev);
+	struct phytium_sdci_host *host = mmc_priv(mmc);
+
+	phytium_sdci_init_hw(host);
+
+	return 0;
+}
+
+static const struct dev_pm_ops phytium_sdci_dev_pm_ops = {
+	SET_SYSTEM_SLEEP_PM_OPS(phytium_sdci_suspend,
+				phytium_sdci_resume)
+	SET_RUNTIME_PM_OPS(phytium_sdci_runtime_suspend,
+			   phytium_sdci_runtime_resume, NULL)
+};
+#else
+#define phytium_sdci_dev_pm_ops NULL
+#endif
+
+static const struct of_device_id phytium_sdci_of_ids[] = {
+	{ .compatible = "phytium,sdci", },
+	{ }
+};
+MODULE_DEVICE_TABLE(of, phytium_sdci_of_ids);
+
+#ifdef CONFIG_ACPI
+static const struct acpi_device_id phytium_sdci_acpi_ids[] = {
+	{ .id = "PHYT0005" },
+	{ }
+};
+
+MODULE_DEVICE_TABLE(acpi, phytium_sdci_acpi_ids);
+#else
+#define phytium_sdci_acpi_ids NULL
+#endif
+
+static struct platform_driver phytium_sdci_driver = {
+	.probe = phytium_sdci_probe,
+	.remove = phytium_sdci_remove,
+	.driver = {
+		.name = "sdci-phytium",
+		.of_match_table = phytium_sdci_of_ids,
+		.acpi_match_table = phytium_sdci_acpi_ids,
+		.pm = &phytium_sdci_dev_pm_ops,
+	},
+};
+
+module_platform_driver(phytium_sdci_driver);
+
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("Chen Baozi <chenbaozi@phytium.com.cn>");
+MODULE_DESCRIPTION("Phytium SD Card Interface driver");
diff --git a/drivers/mmc/host/phytium-sdci.h b/drivers/mmc/host/phytium-sdci.h
new file mode 100644
index 000000000000..361a63b5cbcb
--- /dev/null
+++ b/drivers/mmc/host/phytium-sdci.h
@@ -0,0 +1,176 @@
+/*
+ * File Name: phytium_sdci.h - Phytium FT SDCI dirver
+ *
+ * Copyright (C) 2019 Phytium Technology Co.,Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+/*---------------------------------------------------------------------------*/
+/* Common Definition                                                         */
+/*---------------------------------------------------------------------------*/
+#define MAX_BD_NUM           0x1000
+#define SD_BLOCK_SIZE        512
+
+/*---------------------------------------------------------------------------*/
+/* Register Offset                                                           */
+/*---------------------------------------------------------------------------*/
+#define SDCI_CONTROLLER      0x00  /* controller config reg                  */
+#define SDCI_ARGUMENT        0x04  /* argument reg                           */
+#define SDCI_COMMAND         0x08  /* command reg                            */
+#define SDCI_CLOCK_D         0x0C  /* clock divide reg                       */
+#define SDCI_SOFTWARE        0x10  /* controller reset reg                   */
+#define SDCI_POWER           0X14  /* POWRE CONTROL REG                      */
+#define SDCI_TIMEOUT_CMD     0x18  /* cmd timeout config reg                 */
+#define SDCI_TIMEOUT_DATA    0x1C  /* data timeout reg                       */
+#define SDCI_NORMAL_ISER     0x20  /* normal ISR config reg                  */
+#define SDCI_ERROR_ISER      0x24  /* erroe ISR config reg                   */
+#define SDCI_BD_ISER         0x28  /* BD ISR config reg                      */
+#define SDCI_CAPA            0x2C  /* BD ISR config reg                      */
+#define SDCI_SD_DRV          0x30  /* SD card driving phase position reg     */
+#define SDCI_SD_SAMP         0x34  /* SD card sampling phase position reg    */
+#define SDCI_SD_SEN          0x38  /* SD card detection reg                  */
+#define SDCI_HDS_AXI         0x3C  /* AXI boundary config reg                */
+#define SDCI_BD_RX           0x40  /* BD rx addr reg                         */
+#define SDCI_BD_TX           0x60  /* BD tx addr reg                         */
+#define SDCI_BLK_CNT         0x80  /* r/w block num reg                      */
+#define SDCI_NORMAL_ISR      0xC0  /* normal ISR status reg                  */
+#define SDCI_ERROR_ISR       0xC4  /* error ISR status reg                   */
+#define SDCI_BD_ISR          0xC8  /* BD ISR status reg                      */
+#define SDCI_BD_STATUS       0xCC  /* BD descriptor status reg               */
+#define SDCI_STATUS          0xD0  /* status reg                             */
+#define SDCI_BLOCK           0xD4  /* block len reg                          */
+#define SDCI_RESP0           0xE0  /* response reg0                          */
+#define SDCI_RESP1           0xE4  /* response reg1                          */
+#define SDCI_RESP2           0xE8  /* response reg2                          */
+#define SDCI_RESP3           0XEC  /* response reg3                          */
+
+/*---------------------------------------------------------------------------*/
+/* Register Mask                                                             */
+/*---------------------------------------------------------------------------*/
+/* SDCI_CONTROLLER mask */
+#define SDCI_CONTROLLER_ECRCWR		(0x1 << 0)	/* RW */
+#define SDCI_CONTROLLER_ECRCRD		(0x1 << 1)	/* RW */
+#define SDCI_CONTROLLER_RESEDE		(0x1 << 2)	/* RW */
+#define SDCI_CONTROLLER_PERMDR		(0x3 << 8)	/* RW */
+#define SDCI_CONTROLLER_PERMDX		(0x3 << 10)	/* RW */
+
+/* SDCI_SOFTWARE mask */
+#define SDCI_SOFTWARE_SRST		(0x1 << 0)	/* RW */
+#define SDCI_SOFTWARE_SCRST		(0x1 << 1)	/* RW */
+#define SDCI_SOFTWARE_BDRST		(0x1 << 2)	/* RW */
+#define SDCI_SOFTWARE_CFCLF		(0x1 << 3)	/* RW */
+#define SDCI_SOFTWARE_SDRST		(0x1 << 4)	/* RW */
+
+/* SDCI_NORMAL_ISER mask */
+#define SDCI_SDCI_NORMAL_ISER_ECC_EN	(0x1 << 0)	/* RW */
+#define SDCI_SDCI_NORMAL_ISER_ECR	(0x1 << 1)	/* RW */
+#define SDCI_SDCI_NORMAL_ISER_ECI	(0x1 << 2)	/* RW */
+#define SDCI_SDCI_NORMAL_ISER_EEI_EN	(0x1 << 15)	/* RW */
+
+/* SDCI_NORMAL_ISR mask */
+#define SDCI_NORMAL_ISR_CC		(0x1 << 0)	/* R  */
+#define SDCI_NORMAL_ISR_CR		(0x1 << 1)	/* R  */
+#define SDCI_NORMAL_ISR_CI		(0x1 << 2)	/* R  */
+#define SDCI_NORMAL_ISR_TIMEOUT		(0x1 << 3)	/* R  */
+
+/* SDCI_ERROR_ISER mask */
+#define SDCI_ERROR_ISER_ECTE_EN		(0x1 << 0)	/* RW */
+
+/* SDCI_ERROR_ISR mask */
+#define SDCI_ERROR_ISR_CTE		(0x1 << 0)	/* R  */
+
+/* SDCI_BD_ISER mask */
+#define SDCI_BD_ISER_ETRS_EN		(0x1 << 8)	/* RW */
+
+/* SDCI_BD_ISR mask */
+#define SDCI_BD_ISR_TRS_W		(0x1 << 0)	/* R  */
+#define SDCI_BD_ISR_TRS_R		(0x1 << 8)	/* R  */
+#define SDCI_BD_ISR_EDTE		(0x1 << 3)	/* R  */
+
+/* SDCI_HDS_AXI mask */
+#define SDCI_HDS_AXI_AWDOMAIN		(0x1 << 0)	/* RW */
+#define SDCI_HDS_AXI_ARDOMAIN		(0x1 << 12)	/* RW */
+#define SDCI_HDS_AXI_AWCACHE		(0x6 << 24)	/* RW */
+#define SDCI_HDS_AXI_ARCACHE		(0xB << 28)	/* RW */
+
+/* SDCI_STATUS mask */
+#define SDCI_STATUS_CMD_BUSY		(0x0 << 0)	/* R  */
+#define SDCI_STATUS_CMD_READY		(0x1 << 0)	/* R  */
+#define SDCI_STATUS_IDIE		(0x1 << 12)	/* R  */
+
+
+/*---------------------------------------------------------------------------*/
+/* Register Value                                                            */
+/*---------------------------------------------------------------------------*/
+#define SDCI_SD_DRV_VALUE		0
+#define SDCI_SD_SAMP_VALUE_MAX		50
+#define SDCI_SD_SAMP_VALUE_MIN		0
+
+#define SDCI_TIMEOUT_CMD_VALUE		0xFFFFFFFF
+#define SDCI_POWER_ON			1
+#define SDCI_POWER_OFF			0
+
+#define SDCI_CMD_TIMEOUT		10
+#define SDCI_DAT_TIMEOUT		5000
+
+#define SDCI_CMD_TYPE_ADTC		0x2
+
+#define SDCI_F_MIN			400000
+#define SDCI_F_MAX			25000000
+
+/*---------------------------------------------------------------------------*/
+/*  Structure Type                                                           */
+/*---------------------------------------------------------------------------*/
+struct phytium_sdci_dma {
+	struct scatterlist *sg;
+	u32 *buf;
+	dma_addr_t bd_addr;
+	size_t bytes;
+};
+
+typedef enum {
+	COMMOM_ADTC 	= 0,
+	BLOCK_RW_ADTC	= 1
+} adtc_type_t;
+
+struct phytium_sdci_host {
+	struct device *dev;
+	struct mmc_host *mmc;
+	u32 caps;
+	spinlock_t lock;
+
+	struct mmc_request *mrq;
+	struct mmc_command *cmd;
+	struct mmc_data *data;
+	int error;
+
+	void __iomem *base;
+
+	struct phytium_sdci_dma dma_rx;
+	struct phytium_sdci_dma dma_tx;
+
+	u32 *sg_virt_addr;
+	adtc_type_t adtc_type;
+
+	struct timer_list hotplug_timer;
+
+	struct delayed_work req_timeout;
+	u32 cmd_timeout;
+	u32 data_timeout;
+
+	int irq;
+	int irq_err;
+	int irq_bd;
+
+	struct clk *src_clk;
+	unsigned long clk_rate;
+	unsigned long clk_div;
+	unsigned long real_rate;
+
+	u32 current_rca;
+};
+
diff --git a/drivers/mtd/spi-nor/Kconfig b/drivers/mtd/spi-nor/Kconfig
index 6cc9c929ff57..9c2e9e8509b7 100644
--- a/drivers/mtd/spi-nor/Kconfig
+++ b/drivers/mtd/spi-nor/Kconfig
@@ -7,6 +7,15 @@ menuconfig MTD_SPI_NOR
 
 if MTD_SPI_NOR
 
+config SPI_PHYTIUM_QUADSPI
+	tristate "Phytium Quad SPI Controller"
+	depends on ARCH_PHYTIUM || ARM
+	depends on OF && HAS_IOMEM
+	help
+	  This enables support for the Quad SPI controller in master mode.
+	  This driver does not support generic SPI. The implementation only
+	  supports SPI NOR.
+
 config MTD_MT81xx_NOR
 	tristate "Mediatek MT81xx SPI NOR flash controller"
 	depends on HAS_IOMEM
diff --git a/drivers/mtd/spi-nor/Makefile b/drivers/mtd/spi-nor/Makefile
index f4c61d282abd..ebc8ce095bd0 100644
--- a/drivers/mtd/spi-nor/Makefile
+++ b/drivers/mtd/spi-nor/Makefile
@@ -1,5 +1,6 @@
 # SPDX-License-Identifier: GPL-2.0
 obj-$(CONFIG_MTD_SPI_NOR)	+= spi-nor.o
+obj-$(CONFIG_SPI_PHYTIUM_QUADSPI)	+= phytium-quadspi.o
 obj-$(CONFIG_SPI_ASPEED_SMC)	+= aspeed-smc.o
 obj-$(CONFIG_SPI_ATMEL_QUADSPI)	+= atmel-quadspi.o
 obj-$(CONFIG_SPI_CADENCE_QUADSPI)	+= cadence-quadspi.o
diff --git a/drivers/mtd/spi-nor/phytium-quadspi.c b/drivers/mtd/spi-nor/phytium-quadspi.c
new file mode 100644
index 000000000000..9169a4662d90
--- /dev/null
+++ b/drivers/mtd/spi-nor/phytium-quadspi.c
@@ -0,0 +1,870 @@
+/*
+ * Phytium SPI core controller driver.
+ *
+ * Copyright (c) 2019, Phytium Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+#include <linux/clk.h>
+#include <linux/errno.h>
+#include <linux/io.h>
+#include <linux/iopoll.h>
+#include <linux/interrupt.h>
+#include <linux/module.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+#include <linux/mtd/spi-nor.h>
+#include <linux/mutex.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/reset.h>
+#include <linux/sizes.h>
+#include <linux/spinlock.h>
+#include <linux/swab.h>
+
+#define QSPI_FLASH_CAP_REG   0x000
+#define QSPI_RD_CFG_REG      0x004
+#define QSPI_WR_CFG_REG      0x008
+#define QSPI_FLUSH_REG       0x00C
+#define QSPI_CMD_PORT_REG    0x010
+#define QSPI_ADDR_PORT_REG   0x014
+#define QSPI_HD_PORT_REG     0x018
+#define QSPI_LD_PORT_REG     0x01C
+#define QSPI_FUN_SET_REG     0x020
+#define QSPI_WIP_REG         0x024
+#define QSPI_WP_REG          0x028
+#define QSPI_MODE_REG        0x02C
+
+#define QSPI_FLASH_CAP_NUM_SHIFT	3
+#define QSPI_FLASH_CAP_NUM_MASK		(0x3 << QSPI_FLASH_CAP_NUM_SHIFT)
+#define QSPI_FLASH_CAP_CAP_SHIFT	0
+#define QSPI_FLASH_CAP_CAP_MASK		(0x7 << QSPI_FLASH_CAP_CAP_SHIFT)
+
+#define QSPI_RD_CFG_RD_CMD_SHIFT	24
+#define QSPI_RD_CFG_RD_CMD_MASK		(0xFF << QSPI_RD_CFG_RD_CMD_SHIFT)
+#define QSPI_RD_CFG_RD_THROUGH_SHIFT	23
+#define QSPI_RD_CFG_RD_THROUGH_MASK	(0x01 << QSPI_RD_CFG_RD_THROUGH_SHIFT)
+#define QSPI_RD_CFG_RD_TRANSFER_SHIFT	20
+#define QSPI_RD_CFG_RD_TRANSFER_MASK	(0x07 << QSPI_RD_CFG_RD_TRANSFER_SHIFT)
+#define QSPI_RD_CFG_RD_ADDR_SEL_SHIFT	19
+#define QSPI_RD_CFG_RD_ADDR_SEL_MASK	(0x1 << QSPI_RD_CFG_RD_ADDR_SEL_SHIFT)
+#define QSPI_RD_CFG_RD_LATENCY_SHIFT	18
+#define QSPI_RD_CFG_RD_LATENCY_MASK	(0x1 << QSPI_RD_CFG_RD_LATENCY_SHIFT)
+#define QSPI_RD_CFG_MODE_BYTE_SHIFT	17
+#define QSPI_RD_CFG_MODE_BYTE_MASK	(0x1 << QSPI_RD_CFG_MODE_BYTE_SHIFT)
+#define QSPI_RD_CFG_CMD_SIGN_SHIFT	9
+#define QSPI_RD_CFG_CMD_SIGN_MASK	(0xFF << QSPI_RD_CFG_CMD_SIGN_SHIFT)
+#define QSPI_RD_CFG_DUMMY_SHIFT		4
+#define QSPI_RD_CFG_DUMMY_MASK		(0x1F << QSPI_RD_CFG_DUMMY_SHIFT)
+#define QSPI_RD_CFG_D_BUFFER_SHIFT	3
+#define QSPI_RD_CFG_D_BUFFER_MASK	(0x1 << QSPI_RD_CFG_D_BUFFER_SHIFT)
+#define QSPI_RD_CFG_RD_SCK_SEL_SHIFT	0
+#define QSPI_RD_CFG_RD_SCK_SEL_MASK	(0x3 << QSPI_RD_CFG_RD_SCK_SEL_SHIFT)
+
+#define QSPI_WR_CFG_WR_CMD_SHIFT	24
+#define QSPI_WR_CFG_WR_CMD_MASK		(0xFF << QSPI_WR_CFG_WR_CMD_SHIFT)
+#define QSPI_WR_CFG_WR_WAIT_SHIFT	9
+#define QSPI_WR_CFG_WR_WAIT_MASK	(0x01 << QSPI_WR_CFG_WR_WAIT_SHIFT)
+#define QSPI_WR_CFG_WR_THROUGH_SHIFT	8
+#define QSPI_WR_CFG_WR_THROUGH_MAS	(0x01 << QSPI_WR_CFG_WR_THROUGH_SHIFT)
+#define QSPI_WR_CFG_WR_TRANSFER_SHIFT	5
+#define QSPI_WR_CFG_WR_TRANSFER_MASK	(0X7 << QSPI_WR_CFG_WR_TRANSFER_SHIFT)
+#define QSPI_WR_CFG_WR_ADDR_SEL_SHIFT	4
+#define QSPI_WR_CFG_WR_ADDR_SEL_MASK	(0x1 << QSPI_WR_CFG_WR_ADDR_SEL_SHIFT)
+#define QSPI_WR_CFG_WR_MODE_SHIFT	3
+#define QSPI_WR_CFG_WR_MODE		(0x01 << QSPI_WR_CFG_WR_MODE_SHIFT)
+#define QSPI_WR_CFG_WR_SCK_SEL_SHIFT	0
+#define QSPI_WR_CFG_WR_SCK_SEL_MASK	(0x7 << QSPI_WR_CFG_WR_SCK_SEL_SHIFT)
+
+#define QSPI_FLUSH_EN			(0x1 << 0)
+
+#define QSPI_CMD_PORT_CMD_SHIFT		24
+#define QSPI_CMD_PORT_CMD_MASK		(0xFF << QSPI_CMD_PORT_CMD_SHIFT)
+#define QSPI_CMD_PORT_WAIT_SHIFT	22
+#define QSPI_CMD_PORT_WAIT_MASK		(0x1 << QSPI_CMD_PORT_WAIT_SHIFT)
+#define QSPI_CMD_PORT_THROUGH_SHIFT	21
+#define QSPI_CMD_PORT_THROUGH_MASK	(0x1 << QSPI_CMD_PORT_THROUGH_SHIFT)
+#define QSPI_CMD_PORT_CS_SHIFT		19
+#define QSPI_CMD_PORT_CS_MASK		(0x3 << QSPI_CMD_PORT_CS_SHIFT)
+#define QSPI_CMD_PORT_TRANSFER_SHIFT	16
+#define QSPI_CMD_PORT_TRANSFER_MASK	(0x7 << QSPI_CMD_PORT_TRANSFER_SHIFT)
+#define QSPI_CMD_PORT_CMD_ADDR_SHIFT	15
+#define QSPI_CMD_PORT_CMD_ADDR_MASK	(0x1 << QSPI_CMD_PORT_CMD_ADDR_SHIFT)
+#define QSPI_CMD_PORT_LATENCY_SHIFT	14
+#define QSPI_CMD_PORT_LATENCY_MASK	(0x1 << QSPI_CMD_PORT_LATENCY_SHIFT)
+#define QSPI_CMD_PORT_DATA_TRANSFER_SHIFT	13
+#define QSPI_CMD_PORT_DATA_TRANSFER_MASK	(0x1 << 13)
+#define QSPI_CMD_PORT_SEL_SHIFT		12
+#define QSPI_CMD_PORT_SEL_MASK		(0x1 << QSPI_CMD_PORT_SEL_SHIFT)
+#define QSPI_CMD_PORT_DUMMY_SHIFT	7
+#define QSPI_CMD_PORT_DUMMY_MASK	(0x1F << QSPI_CMD_PORT_DUMMY_SHIFT)
+#define QSPI_CMD_PORT_P_BUFFER_SHIFT	6
+#define QSPI_CMD_PORT_P_BUFFER_MASK	(0x1 << QSPI_CMD_PORT_P_BUFFER_SHIFT)
+#define QSPI_CMD_PORT_RW_NUM_SHIFT	3
+#define QSPI_CMD_PORT_RW_NUM_MASK	(0x7 << QSPI_CMD_PORT_RW_NUM_SHIFT)
+#define QSPI_CMD_PORT_SCK_SEL_SHIFT	0
+#define QSPI_CMD_PORT_SCK_SEL_MASK	(0x7 << QSPI_CMD_PORT_SCK_SEL_SHIFT)
+
+#define QSPI_FUN_SET_HOLD_SHIFT		24
+#define QSPI_FUN_SET_HOLD_MASK		(0xFF << QSPI_FUN_SET_HOLD_SHIFT)
+#define QSPI_FUN_SET_SETUP_SHIFT	16
+#define QSPI_FUN_SET_SETUP_MASK		(0xFF << QSPI_FUN_SET_SETUP_SHIFT)
+#define QSPI_FUN_SET_DELAY_SHIFT	0
+#define QSPI_FUN_SET_DELAY_MASK		(0xFFFF << QSPI_FUN_SET_DELAY_SHIFT)
+
+#define QSPI_WIP_W_CMD_SHIFT		24
+#define QSPI_WIP_W_CMD_MASK		(0xFF << QSPI_WIP_W_CMD_SHIFT)
+#define QSPI_WIP_W_TRANSFER_SHIFT	3
+#define QSPI_WIP_W_TRANSFER_MASK	(0x3 << QSPI_WIP_W_TRANSFER_SHIFT)
+#define QSPI_WIP_W_SCK_SEL_SHIFT      	0
+#define QSPI_WIP_W_SCK_SEL_MASK		(0x7 << QSPI_WIP_W_SCK_SEL_SHIFT)
+
+#define QSPI_WP_EN_SHIFT		17
+#define QSPI_WP_EN_MASK			(0x1 << QSPI_WP_EN_SHIFT)
+#define QSPI_WP_IO2_SHIFT		16
+#define QSPI_WP_IO2_MASK		(0x1 << QSPI_WP_IO2_SHIFT)
+#define QSPI_WP_HOLD_SHIFT		8
+#define QSPI_WP_HOLD_MASK		(0xFF << QSPI_WP_HOLD_SHIFT)
+#define QSPI_WP_SETUP_SHIFT		0
+#define QSPI_WP_SETUP_MASK		(0xFF << QSPI_WP_SETUP_SHIFT)
+
+#define QSPI_MODE_VALID_SHIFT		8
+#define QSPI_MODE_VALID_MASK		(0xFF << QSPI_MODE_VALID_SHIFT)
+#define QSPI_MODE_SHIFT			0
+#define QSPI_MODE_MASK			(0xFF << QSPI_MODE_SHIFT)
+
+#define FSIZE_VAL(size)			(__fls(size) - 1)
+
+#define PHYTIUM_MAX_MMAP_S		SZ_512M
+#define PHYTIUM_MAX_NORCHIP		2
+
+#define PHYTIUM_QSPI_FIFO_SZ		32
+#define PHYTIUM_QSPI_FIFO_TIMEOUT_US	50000
+#define PHYTIUM_QSPI_BUSY_TIMEOUT_US	100000
+
+#define PHYTIUM_SCK_SEL			0x05
+#define PHYTIUM_CMD_SCK_SEL		0x07
+
+#define PHYTIUM_FMODE_MM		0x01
+#define PHYTIUM_FMODE_IN		0x02
+
+/*
+ * the codes of the different commands
+ */
+#define CMD_WRDI	  0x04
+#define CMD_RDID	  0x9F
+#define CMD_RDSR	  0x05
+#define CMD_WREN	  0x06
+#define CMD_RDAR	  0x65
+#define CMD_P4E           0x20
+#define CMD_4P4E          0x21
+#define CMD_BE      	  0x60
+#define CMD_4BE           0xC7
+#define	CMD_READ          0x03
+#define	CMD_FAST_READ     0x0B
+#define	CMD_QOR           0x6B
+#define	CMD_QIOR          0xEB
+#define CMD_DDRFR         0x0D
+#define	CMD_DDRQIOQ       0xED
+#define	CMD_PP            0x02
+#define	CMD_QPP           0x32
+#define	CMD_SE            0xD8
+#define	CMD_4FAST_READ    0x0C
+#define	CMD_4READ         0x13
+#define	CMD_4QOR          0x6C
+#define	CMD_4QIOR         0xEC
+#define	CMD_4DDRFR        0x0E
+#define	CMD_4DDRQIOR      0xEE
+#define	CMD_4PP           0x12
+#define	CMD_4QPP          0x34
+#define	CMD_4SE           0xDC
+
+#define PHYTIUM_QSPI_1_1_1	0
+#define PHYTIUM_QSPI_1_1_2	1
+#define PHYTIUM_QSPI_1_1_4	2
+#define PHYTIUM_QSPI_1_2_2	3
+#define PHYTIUM_QSPI_1_4_4	4
+#define PHYTIUM_QSPI_2_2_2	5
+#define PHYTIUM_QSPI_4_4_4	6
+
+struct phytium_qspi_flash {
+	struct spi_nor nor;
+	struct phytium_qspi *qspi;
+	u32 cs;
+	u32 fsize;
+	u32 presc;
+	u32 read_mode;
+	bool registered;
+	u32 prefetch_limit;
+	u32 addr_width;
+};
+
+struct phytium_qspi {
+	struct device *dev;
+	void __iomem *io_base;
+	void __iomem *mm_base;
+	resource_size_t mm_size;
+	u32 nor_num;
+	struct clk *clk;
+	u32 clk_rate;
+	struct phytium_qspi_flash flash[PHYTIUM_MAX_NORCHIP];
+
+	spinlock_t spinlock;
+
+	/*
+	 * to protect device configuration, could be different between
+	 * 2 flash access (bk1, bk2)
+	 */
+	struct mutex lock;
+};
+
+/* Need to enable p_buffer */
+static int memcpy_from_ftreg(struct phytium_qspi *qspi, u_char *buf, size_t len)
+{
+	int i;
+	u32 val = 0;
+
+	if (!qspi || !buf)
+		return -EINVAL;
+
+	for (i = 0; i < len; i++) {
+		if (0 == i % 4)
+			val = readl_relaxed(qspi->io_base + QSPI_LD_PORT_REG);
+
+		buf[i] = (u_char) (val >> (i % 4) * 8) & 0xFF;
+	}
+
+	return 0;
+}
+
+/* Not to enable p_buffer */
+static int memcpy_to_ftreg(struct phytium_qspi *qspi, u_char *buf, size_t len)
+{
+	int i;
+	u32 val = 0;
+
+	if (!qspi || !buf || (len >= 8))
+		return -EINVAL;
+
+	for (i=0; i<len; i++) {
+		val = (val << 8) + buf[i];
+		if (3 == i){
+			writel_relaxed(__swab32(val), qspi->io_base + QSPI_LD_PORT_REG);
+			val = 0;
+		} else if (7 == i) {
+			writel_relaxed(__swab32(val), qspi->io_base + QSPI_HD_PORT_REG);
+			val = 0;
+		}
+	}
+
+	return 0;
+}
+
+static int phytium_qspi_wait_cmd(struct phytium_qspi *qspi)
+{
+	u32 cmd = 0;
+	u32 sr  = 0;
+	int err = 0;
+
+	cmd |= CMD_RDSR;
+	cmd |= QSPI_CMD_PORT_DATA_TRANSFER_SHIFT;
+
+	writel_relaxed(cmd, qspi->io_base + QSPI_CMD_PORT_REG);
+	err = readl_relaxed_poll_timeout(qspi->io_base + QSPI_LD_PORT_REG,
+					 sr, ~(sr & 0x01), 10,
+					 PHYTIUM_QSPI_BUSY_TIMEOUT_US);
+	if (err)
+		dev_err(qspi->dev,
+			"wait command process timeout (stat:%#x, sr:%#x)\n",
+			err, sr);
+
+	return err;
+}
+
+static int phytium_qspi_cmd_enable(struct phytium_qspi *qspi)
+{
+	u32 val = 0;
+
+	writel_relaxed(val, qspi->io_base + QSPI_LD_PORT_REG);
+
+	return 0;
+}
+
+static int phytium_qspi_write_enable(struct phytium_qspi *qspi)
+{
+	u32 cmd = 0;
+
+	cmd  = CMD_WREN << QSPI_CMD_PORT_CMD_SHIFT;
+	cmd |= BIT(QSPI_CMD_PORT_WAIT_SHIFT);
+	cmd |= PHYTIUM_SCK_SEL << QSPI_CMD_PORT_SCK_SEL_SHIFT;
+
+	writel_relaxed(cmd, qspi->io_base + QSPI_CMD_PORT_REG);
+	phytium_qspi_cmd_enable(qspi);
+
+	return 0;
+}
+
+static int phytium_qspi_write_disable(struct phytium_qspi *qspi)
+{
+	u32 cmd = 0;
+
+	cmd  = CMD_WRDI << QSPI_CMD_PORT_CMD_SHIFT;
+	cmd |= BIT(QSPI_CMD_PORT_WAIT_SHIFT);
+	cmd |= PHYTIUM_SCK_SEL << QSPI_CMD_PORT_SCK_SEL_SHIFT;
+
+	writel_relaxed(cmd, qspi->io_base + QSPI_CMD_PORT_REG);
+	phytium_qspi_cmd_enable(qspi);
+
+	return 0;
+}
+
+static int phytium_qspi_read_flash_id(struct phytium_qspi *qspi,
+			       u8 opcode, u8 *buf, int len)
+{
+	u32 cmd = 0;
+	unsigned long iflags;
+
+	cmd  = opcode << QSPI_CMD_PORT_CMD_SHIFT;
+	cmd |= BIT(QSPI_CMD_PORT_DATA_TRANSFER_SHIFT);
+	cmd |= BIT(QSPI_CMD_PORT_P_BUFFER_SHIFT);
+	cmd |= PHYTIUM_CMD_SCK_SEL << QSPI_CMD_PORT_SCK_SEL_SHIFT;
+
+	writel_relaxed(cmd, qspi->io_base + QSPI_CMD_PORT_REG);
+	phytium_qspi_cmd_enable(qspi);
+
+	spin_lock_irqsave(&qspi->spinlock, iflags);
+	memcpy_from_ftreg(qspi, buf, len);
+	spin_unlock_irqrestore(&qspi->spinlock, iflags);
+
+	return 0;
+}
+
+static int phytium_qspi_read_flash_sfdp(struct phytium_qspi *qspi,
+			       u8 opcode, loff_t from, u8 *buf, int len)
+{
+	unsigned long iflags;
+	u32 cmd = 0;
+
+	cmd  = opcode << QSPI_CMD_PORT_CMD_SHIFT;
+	cmd |= BIT(QSPI_CMD_PORT_DATA_TRANSFER_SHIFT);
+	cmd |= BIT(QSPI_CMD_PORT_P_BUFFER_SHIFT);
+	cmd |= BIT(QSPI_CMD_PORT_CMD_ADDR_SHIFT);
+	cmd |= PHYTIUM_SCK_SEL << QSPI_CMD_PORT_SCK_SEL_SHIFT;
+
+	writel_relaxed(cmd, qspi->io_base + QSPI_CMD_PORT_REG);
+	writel_relaxed(from, qspi->io_base + QSPI_ADDR_PORT_REG);
+	phytium_qspi_cmd_enable(qspi);
+
+	spin_lock_irqsave(&qspi->spinlock, iflags);
+	memcpy_from_ftreg(qspi, buf, len);
+	spin_unlock_irqrestore(&qspi->spinlock, iflags);
+
+	return 0;
+}
+
+static int phytium_qspi_read_flash_sr1(struct phytium_qspi *qspi,
+			       u8 opcode, u8 *buf, int len)
+{
+	u32 cmd = 0;
+	u32 val;
+
+	cmd  = opcode << QSPI_CMD_PORT_CMD_SHIFT;
+	cmd |= BIT(QSPI_CMD_PORT_DATA_TRANSFER_SHIFT);
+	cmd |= (len << QSPI_CMD_PORT_RW_NUM_SHIFT) & QSPI_CMD_PORT_RW_NUM_MASK;
+	cmd |= PHYTIUM_CMD_SCK_SEL << QSPI_CMD_PORT_SCK_SEL_SHIFT;
+
+	writel_relaxed(cmd, qspi->io_base + QSPI_CMD_PORT_REG);
+	phytium_qspi_cmd_enable(qspi);
+
+	val = readl_relaxed(qspi->io_base + QSPI_LD_PORT_REG);
+	buf[0] = (u8)val;
+
+	return 0;
+}
+
+static int phytium_qspi_read_reg(struct spi_nor *nor,
+			       u8 opcode, u8 *buf, int len)
+{
+	struct phytium_qspi_flash *flash = nor->priv;
+	struct device *dev = flash->qspi->dev;
+	struct phytium_qspi *qspi = flash->qspi;
+	unsigned long iflags;
+	u32 cmd = 0;
+
+	dev_dbg(dev, "read_reg: cmd:%#.2x buf:%pK len:%#x\n", opcode, buf, len);
+
+	switch (opcode) {
+	case CMD_RDID:
+		phytium_qspi_read_flash_id(qspi, opcode, buf, len);
+		return 0;
+	case CMD_RDSR:
+		phytium_qspi_read_flash_sr1(qspi, opcode, buf, len);
+		return 0;
+	default:
+		break;
+	}
+
+	cmd  = opcode << QSPI_CMD_PORT_CMD_SHIFT;
+	cmd |= BIT(QSPI_CMD_PORT_DATA_TRANSFER_SHIFT);
+	cmd |= BIT(QSPI_CMD_PORT_P_BUFFER_SHIFT);
+	cmd |= PHYTIUM_CMD_SCK_SEL << QSPI_CMD_PORT_SCK_SEL_SHIFT;
+
+	writel_relaxed(cmd, qspi->io_base + QSPI_CMD_PORT_REG);
+	phytium_qspi_cmd_enable(qspi);
+
+	spin_lock_irqsave(&qspi->spinlock, iflags);
+	memcpy_from_ftreg(qspi, buf, len);
+	spin_unlock_irqrestore(&qspi->spinlock, iflags);
+
+	return 0;
+}
+
+static int phytium_qspi_write_reg(struct spi_nor *nor, u8 opcode,
+				u8 *buf, int len)
+{
+	struct phytium_qspi_flash *flash = nor->priv;
+	struct device *dev = flash->qspi->dev;
+	struct phytium_qspi *qspi = flash->qspi;
+	u32 cmd = 0;
+
+	dev_dbg(dev, "write_reg: cmd:%#.2x buf:%pK len:%#x\n",
+		opcode, buf, len);
+
+	switch(opcode){
+	case CMD_WREN:
+		phytium_qspi_write_enable(qspi);
+		return 0;
+	case CMD_WRDI:
+		phytium_qspi_write_disable(qspi);
+		return 0;
+	default:
+		break;
+	}
+
+	cmd  = opcode << QSPI_CMD_PORT_CMD_SHIFT;
+	cmd |= BIT(QSPI_CMD_PORT_WAIT_SHIFT);
+	cmd |= PHYTIUM_SCK_SEL << QSPI_CMD_PORT_SCK_SEL_SHIFT;
+
+	if ((len > 8) || (NULL == buf)) {
+		dev_err(dev, "data length exceed. commad %x, len:%d \n", opcode, len);
+		return -EINVAL;
+	} else {
+		cmd |= (len << QSPI_CMD_PORT_RW_NUM_SHIFT) & QSPI_CMD_PORT_RW_NUM_MASK;
+		cmd |= BIT(QSPI_CMD_PORT_DATA_TRANSFER_SHIFT);
+		memcpy_to_ftreg(qspi, buf, len);
+	}
+
+	writel_relaxed(cmd, qspi->io_base + QSPI_CMD_PORT_REG);
+	phytium_qspi_cmd_enable(qspi);
+
+	return 0;
+}
+
+
+static ssize_t phytium_qspi_read(struct spi_nor *nor, loff_t from, size_t len,
+				 u_char *buf)
+{
+	struct phytium_qspi_flash *flash = nor->priv;
+	struct phytium_qspi *qspi = flash->qspi;
+	u32 cmd = nor->read_opcode;
+	u32 addr = (u32)from;
+
+	dev_dbg(qspi->dev, "read(%#.2x): buf:%pK from:%#.8x len:%#zx\n",
+		nor->read_opcode, buf, (u32)from, len);
+
+	cmd  = cmd << QSPI_RD_CFG_RD_CMD_SHIFT;
+	cmd |= BIT(QSPI_RD_CFG_D_BUFFER_SHIFT);
+	cmd |= PHYTIUM_SCK_SEL << QSPI_CMD_PORT_SCK_SEL_SHIFT;
+
+	cmd &= ~QSPI_RD_CFG_RD_TRANSFER_MASK;
+	cmd |= (flash->addr_width << QSPI_RD_CFG_RD_TRANSFER_SHIFT);
+
+	switch (nor->read_opcode) {
+	case CMD_READ:
+	case CMD_FAST_READ:
+	case CMD_QIOR:
+	case CMD_QOR:
+		cmd &= ~QSPI_RD_CFG_RD_ADDR_SEL_MASK;
+		break;
+	case CMD_4READ:
+	case CMD_4FAST_READ:
+	case CMD_4QOR:
+	case CMD_4QIOR:
+		cmd |= BIT(QSPI_RD_CFG_RD_ADDR_SEL_SHIFT);
+		break;
+	case 0x5A:
+		cmd &= ~QSPI_RD_CFG_RD_ADDR_SEL_MASK;
+		phytium_qspi_read_flash_sfdp(qspi, nor->read_opcode, from, buf, len);
+		return 0;
+		break;
+	default:
+		break;
+	}
+
+	writel_relaxed(cmd, qspi->io_base + QSPI_RD_CFG_REG);
+	phytium_qspi_cmd_enable(qspi);
+
+	memcpy_fromio(buf, qspi->mm_base + addr, len);
+
+	return len;
+}
+
+static ssize_t phytium_qspi_write(struct spi_nor *nor, loff_t to, size_t len,
+				  const u_char *buf)
+{
+	struct phytium_qspi_flash *flash = nor->priv;
+	struct device *dev = flash->qspi->dev;
+	struct phytium_qspi *qspi = flash->qspi;
+	u32 cmd = nor->program_opcode;
+	u32 addr = (u32)to;
+
+	dev_dbg(dev, "write(%#.2x): buf:%p to:%#.8x len:%#zx\n",
+		nor->program_opcode, buf, (u32)to, len);
+
+	cmd  = cmd << QSPI_WR_CFG_WR_CMD_SHIFT;
+	cmd |= BIT(QSPI_WR_CFG_WR_WAIT_SHIFT);
+	cmd |= BIT(QSPI_WR_CFG_WR_MODE_SHIFT);
+	cmd |= PHYTIUM_SCK_SEL << QSPI_CMD_PORT_SCK_SEL_SHIFT;
+
+	switch (nor->program_opcode) {
+	case CMD_PP:
+	case CMD_QPP:
+		cmd &= ~QSPI_WR_CFG_WR_ADDR_SEL_MASK;
+		break;
+	case CMD_4PP:
+	case CMD_4QPP:
+		cmd |= BIT(QSPI_WR_CFG_WR_ADDR_SEL_SHIFT);
+		break;
+	default:
+		dev_err(qspi->dev, "Not support program command:%#x\n",
+			nor->erase_opcode);
+		return -EINVAL;
+	}
+
+	writel_relaxed(cmd, qspi->io_base + QSPI_WR_CFG_REG);
+	memcpy_toio(qspi->mm_base + addr, buf, len);
+	writel_relaxed(QSPI_FLUSH_EN, qspi->io_base + QSPI_FLUSH_REG);
+
+	phytium_qspi_wait_cmd(qspi);
+
+	return len;
+}
+
+static int phytium_qspi_erase(struct spi_nor *nor, loff_t offs)
+{
+	struct phytium_qspi_flash *flash = nor->priv;
+	struct device *dev = flash->qspi->dev;
+	struct phytium_qspi *qspi = flash->qspi;
+	u32 cmd = nor->erase_opcode;
+	u32 addr = (u32)offs;
+
+	dev_dbg(dev, "erase(%#.2x):offs:%#x\n", nor->erase_opcode, (u32)offs);
+
+	phytium_qspi_write_enable(qspi);
+	cmd  = cmd << QSPI_CMD_PORT_CMD_SHIFT;
+	cmd |= BIT(QSPI_CMD_PORT_WAIT_SHIFT);
+	cmd |= PHYTIUM_SCK_SEL << QSPI_CMD_PORT_SCK_SEL_SHIFT;
+
+	/* s25fl256s1 not supoort D8, DC, 20, 21 */
+	switch (nor->erase_opcode) {
+	case CMD_SE:
+		cmd &= ~QSPI_CMD_PORT_SEL_MASK;
+		cmd |= BIT(QSPI_CMD_PORT_CMD_ADDR_SHIFT);
+		writel_relaxed(addr, qspi->io_base + QSPI_ADDR_PORT_REG);
+		break;
+	case CMD_4SE:
+		cmd |= BIT(QSPI_CMD_PORT_SEL_SHIFT);
+		cmd |= BIT(QSPI_CMD_PORT_CMD_ADDR_SHIFT);
+		writel_relaxed(addr, qspi->io_base + QSPI_ADDR_PORT_REG);
+		break;
+	case CMD_P4E:
+		cmd &= ~QSPI_CMD_PORT_SEL_MASK;
+		cmd |= BIT(QSPI_CMD_PORT_CMD_ADDR_SHIFT);
+		writel_relaxed(addr, qspi->io_base + QSPI_ADDR_PORT_REG);
+		break;
+	case CMD_4P4E:
+		cmd |= BIT(QSPI_CMD_PORT_SEL_SHIFT);
+		cmd |= BIT(QSPI_CMD_PORT_CMD_ADDR_SHIFT);
+		writel_relaxed(addr, qspi->io_base + QSPI_ADDR_PORT_REG);
+		break;
+	case CMD_BE:
+		cmd &= ~QSPI_CMD_PORT_SEL_MASK;
+		break;
+	case CMD_4BE:
+		cmd |= BIT(QSPI_CMD_PORT_SEL_SHIFT);
+		break;
+	default:
+		dev_err(qspi->dev, "Not support erase command:%#x\n",
+			nor->erase_opcode);
+		return -EINVAL;
+	}
+
+	writel_relaxed(cmd, qspi->io_base + QSPI_CMD_PORT_REG);
+	phytium_qspi_cmd_enable(qspi);
+	phytium_qspi_wait_cmd(qspi);
+
+	return 0;
+}
+
+static int phytium_qspi_prep(struct spi_nor *nor, enum spi_nor_ops ops)
+{
+	struct phytium_qspi_flash *flash = nor->priv;
+	struct phytium_qspi *qspi = flash->qspi;
+
+	mutex_lock(&qspi->lock);
+	return 0;
+}
+
+static void phytium_qspi_unprep(struct spi_nor *nor, enum spi_nor_ops ops)
+{
+	struct phytium_qspi_flash *flash = nor->priv;
+	struct phytium_qspi *qspi = flash->qspi;
+
+	mutex_unlock(&qspi->lock);
+}
+
+static int phytium_qspi_flash_size_set(struct phytium_qspi *qspi, u32 size)
+{
+	int ret = 0;
+	u32 value;
+
+	switch (size) {
+	case SZ_4M:
+		value = 0;
+		break;
+	case SZ_8M:
+		value = 1;
+		break;
+	case SZ_16M:
+		value = 2;
+		break;
+	case SZ_32M:
+		value = 3;
+		break;
+	case SZ_64M:
+		value = 4;
+		break;
+	case SZ_128M:
+		value = 5;
+		break;
+	case SZ_256M:
+		value = 6;
+		break;
+	case SZ_512M:
+		value = 7;
+		break;
+	default:
+		value = 0;
+
+		ret = -EINVAL;
+		return ret;
+	}
+
+	writel_relaxed(value & 0x07, qspi->io_base + QSPI_FLASH_CAP_REG);
+
+	return ret;
+}
+static int phytium_qspi_flash_setup(struct phytium_qspi *qspi,
+				    struct device_node *np)
+{
+	struct spi_nor_hwcaps hwcaps = {
+		.mask = SNOR_HWCAPS_READ |
+			SNOR_HWCAPS_READ_FAST |
+			SNOR_HWCAPS_PP,
+	};
+	u32 width, presc;
+	u32 cs_num = 0;
+	u32 max_rate = 0;
+	u32 addr_width = PHYTIUM_QSPI_1_1_1;
+	struct phytium_qspi_flash *flash;
+	struct mtd_info *mtd;
+	int ret;
+
+    of_property_read_u32(np, "reg", &cs_num);
+    if (cs_num >= PHYTIUM_MAX_NORCHIP)
+		return -EINVAL;
+
+	of_property_read_u32(np, "spi-max-frequency", &max_rate);
+	if (!max_rate)
+		return -EINVAL;
+
+	presc = DIV_ROUND_UP(qspi->clk_rate, max_rate) - 1;
+
+	if (of_property_read_u32(np, "spi-rx-bus-width", &width))
+		width = 1;
+
+	if (width == 4) {
+		hwcaps.mask |= SNOR_HWCAPS_READ_1_1_4;
+		addr_width   = PHYTIUM_QSPI_1_1_4;
+	} else if (width == 2) {
+		hwcaps.mask |= SNOR_HWCAPS_READ_1_1_2;
+		addr_width   = PHYTIUM_QSPI_1_1_2;
+	} else if (width != 1)
+		return -EINVAL;
+
+	flash = &qspi->flash[cs_num];
+	flash->qspi = qspi;
+	flash->cs = cs_num;
+	flash->presc = presc;
+	flash->addr_width = addr_width;
+
+	flash->nor.dev = qspi->dev;
+	spi_nor_set_flash_node(&flash->nor, np);
+	flash->nor.priv = flash;
+	mtd = &flash->nor.mtd;
+
+	flash->nor.read = phytium_qspi_read;
+	flash->nor.write = phytium_qspi_write;
+	flash->nor.erase = phytium_qspi_erase;
+	flash->nor.read_reg = phytium_qspi_read_reg;
+	flash->nor.write_reg = phytium_qspi_write_reg;
+	flash->nor.prepare = phytium_qspi_prep;
+	flash->nor.unprepare = phytium_qspi_unprep;
+
+	flash->fsize = FSIZE_VAL(SZ_1K);
+
+	ret = spi_nor_scan(&flash->nor, NULL, &hwcaps);
+	if (ret) {
+		dev_err(qspi->dev, "device scan failed\n");
+		return ret;
+	}
+
+	flash->fsize = FSIZE_VAL(mtd->size);
+	flash->prefetch_limit = mtd->size - PHYTIUM_QSPI_FIFO_SZ;
+
+	ret = phytium_qspi_flash_size_set(flash->qspi, mtd->size);
+	if (ret) {
+		dev_err(qspi->dev, "flash size invalid\n");
+		return ret;
+	}
+
+	flash->read_mode = PHYTIUM_FMODE_MM;
+
+	ret = mtd_device_register(mtd, NULL, 0);
+	if (ret) {
+		dev_err(qspi->dev, "mtd device parse failed\n");
+		return ret;
+	}
+
+	flash->registered = true;
+
+	dev_dbg(qspi->dev, "read mm:%s cs:%d bus:%d\n",
+		flash->read_mode == PHYTIUM_FMODE_MM ? "yes" : "no",
+		cs_num, width);
+
+	return 0;
+}
+
+static void phytium_qspi_mtd_free(struct phytium_qspi *qspi)
+{
+	int i;
+
+	for (i = 0; i < PHYTIUM_MAX_NORCHIP; i++)
+		if (qspi->flash[i].registered)
+			mtd_device_unregister(&qspi->flash[i].nor.mtd);
+}
+
+static int phytium_qspi_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct device_node *flash_np;
+	struct phytium_qspi *qspi;
+	struct resource *res;
+	int ret;
+
+	qspi = devm_kzalloc(dev, sizeof(*qspi), GFP_KERNEL);
+	if (!qspi)
+		return -ENOMEM;
+
+	qspi->nor_num = of_get_child_count(dev->of_node);
+	if (!qspi->nor_num || qspi->nor_num > PHYTIUM_MAX_NORCHIP)
+		return -ENODEV;
+
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "qspi");
+	qspi->io_base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(qspi->io_base))
+		return PTR_ERR(qspi->io_base);
+
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "qspi_mm");
+	qspi->mm_base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(qspi->mm_base))
+		return PTR_ERR(qspi->mm_base);
+
+	qspi->mm_size = resource_size(res);
+
+	qspi->clk = devm_clk_get(dev, NULL);
+	if (IS_ERR(qspi->clk))
+		return PTR_ERR(qspi->clk);
+
+	qspi->clk_rate = clk_get_rate(qspi->clk);
+	if (!qspi->clk_rate)
+		return -EINVAL;
+
+	ret = clk_prepare_enable(qspi->clk);
+	if (ret) {
+		dev_err(dev, "can not enable the clock\n");
+		return ret;
+	}
+
+	qspi->dev = dev;
+	platform_set_drvdata(pdev, qspi);
+	mutex_init(&qspi->lock);
+	spin_lock_init(&qspi->spinlock);
+
+	for_each_available_child_of_node(dev->of_node, flash_np) {
+		ret = phytium_qspi_flash_setup(qspi, flash_np);
+		if (ret) {
+			dev_err(dev, "unable to setup flash chip\n");
+			goto err_flash;
+		}
+	}
+
+	return 0;
+
+err_flash:
+	mutex_destroy(&qspi->lock);
+	phytium_qspi_mtd_free(qspi);
+
+	clk_disable_unprepare(qspi->clk);
+	return ret;
+}
+
+static int phytium_qspi_remove(struct platform_device *pdev)
+{
+	struct phytium_qspi *qspi = platform_get_drvdata(pdev);
+
+	phytium_qspi_mtd_free(qspi);
+	mutex_destroy(&qspi->lock);
+
+	clk_disable_unprepare(qspi->clk);
+	return 0;
+}
+
+static const struct of_device_id phytium_qspi_match[] = {
+	{.compatible = "phytium,qspi"},
+	{ }
+};
+MODULE_DEVICE_TABLE(of, phytium_qspi_match);
+
+static struct platform_driver phytium_qspi_driver = {
+	.probe	= phytium_qspi_probe,
+	.remove	= phytium_qspi_remove,
+	.driver	= {
+		.name = "phytium-quadspi",
+		.of_match_table = phytium_qspi_match,
+	},
+};
+
+module_platform_driver(phytium_qspi_driver);
+
+MODULE_AUTHOR("Mingshuai Zhu <zhumingshui@phytium.com.cn>");
+MODULE_DESCRIPTION("Phytium QuadSPI driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/mtd/spi-nor/spi-nor.c b/drivers/mtd/spi-nor/spi-nor.c
index f028277fb1ce..6bd2bd88f29c 100644
--- a/drivers/mtd/spi-nor/spi-nor.c
+++ b/drivers/mtd/spi-nor/spi-nor.c
@@ -1263,6 +1263,7 @@ static const struct flash_info spi_nor_ids[] = {
 	/* XMC (Wuhan Xinxin Semiconductor Manufacturing Corp.) */
 	{ "XM25QH64A", INFO(0x207017, 0, 64 * 1024, 128, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ "XM25QH128A", INFO(0x207018, 0, 64 * 1024, 256, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "XM25QH128B", INFO(0x205018, 0, 64 * 1024, 256, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ },
 };
 
diff --git a/drivers/net/can/Kconfig b/drivers/net/can/Kconfig
index 7cdd0cead693..5c83528028f2 100644
--- a/drivers/net/can/Kconfig
+++ b/drivers/net/can/Kconfig
@@ -119,6 +119,13 @@ config CAN_JANZ_ICAN3
 	  This driver can also be built as a module. If so, the module will be
 	  called janz-ican3.ko.
 
+config CAN_PHYTIUM
+	tristate "Phytium CAN"
+	depends on ARCH_PHYTIUM
+	---help---
+	  Phytium CAN driver. This driver supports support for the Phytium
+          CAN Controller
+
 config CAN_SUN4I
 	tristate "Allwinner A10 CAN controller"
 	depends on MACH_SUN4I || MACH_SUN7I || COMPILE_TEST
diff --git a/drivers/net/can/Makefile b/drivers/net/can/Makefile
index 44922bf29b6a..2c5786895ee1 100644
--- a/drivers/net/can/Makefile
+++ b/drivers/net/can/Makefile
@@ -28,6 +28,7 @@ obj-$(CONFIG_CAN_JANZ_ICAN3)	+= janz-ican3.o
 obj-$(CONFIG_CAN_MSCAN)		+= mscan/
 obj-$(CONFIG_CAN_M_CAN)		+= m_can/
 obj-$(CONFIG_CAN_PEAK_PCIEFD)	+= peak_canfd/
+obj-$(CONFIG_CAN_PHYTIUM)	+= phytium-can.o
 obj-$(CONFIG_CAN_SJA1000)	+= sja1000/
 obj-$(CONFIG_CAN_SUN4I)		+= sun4i_can.o
 obj-$(CONFIG_CAN_TI_HECC)	+= ti_hecc.o
diff --git a/drivers/net/can/phytium-can.c b/drivers/net/can/phytium-can.c
new file mode 100644
index 000000000000..b115f08306d6
--- /dev/null
+++ b/drivers/net/can/phytium-can.c
@@ -0,0 +1,1002 @@
+/* Phytium CAN device driver
+ *
+ * Copyright (C) 2018-2019, Phytium Technology Co., Ltd.
+ *
+ * Author: Leo Hou <houyuefei@phytium.com.cn>
+ * Author: Chen Baozi <chenbaozi@phytium.com.cn>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation version 2.
+ *
+ * This program is distributed as is WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/clk.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/of.h>
+#include <linux/platform_device.h>
+#include <linux/skbuff.h>
+#include <linux/string.h>
+#include <linux/types.h>
+#include <linux/can/dev.h>
+#include <linux/can/error.h>
+#include <linux/can/led.h>
+
+#define DRIVER_NAME "phytium_can"
+
+/* CAN registers offset */
+enum ftcan_reg {
+	FTCAN_CTRL_OFFSET		= 0x00,  /* Global control register */
+	FTCAN_INTR_OFFSET		= 0x04,  /* Interrupt register */
+	FTCAN_ARB_RATE_CTRL_OFFSET	= 0x08,  /* Arbitration rate control register */
+	FTCAN_DAT_RATE_CTRL_OFFSET	= 0x0C,  /* Data rate control register */
+	FTCAN_ACC_ID0_OFFSET	  	= 0x10,  /* Acceptance identifier0 register */
+	FTCAN_ACC_ID1_OFFSET	  	= 0x14,  /* Acceptance identifier1 register */
+	FTCAN_ACC_ID2_OFFSET	  	= 0x18,  /* Acceptance identifier2 register */
+	FTCAN_ACC_ID3_OFFSET	  	= 0x1C,  /* Acceptance identifier3 register */
+	FTCAN_ACC_ID0_MASK_OFFSET 	= 0x20,  /* Acceptance identifier0 mask register */
+	FTCAN_ACC_ID1_MASK_OFFSET 	= 0x24,  /* Acceptance identifier1 mask register */
+	FTCAN_ACC_ID2_MASK_OFFSET 	= 0x28,  /* Acceptance identifier2 mask register */
+	FTCAN_ACC_ID3_MASK_OFFSET 	= 0x2C,  /* Acceptance identifier3 mask register */
+	FTCAN_XFER_STS_OFFSET	  	= 0x30,  /* Transfer status register */
+	FTCAN_ERR_CNT_OFFSET	  	= 0x34,  /* Error counter register */
+	FTCAN_FIFO_CNT_OFFSET	  	= 0x38,  /* FIFO counter register */
+	FTCAN_DMA_CTRL_OFFSET	  	= 0x3C,  /* DMA request control register */
+	FTCAN_TX_FIFO_OFFSET	  	= 0x100, /* TX FIFO shadow register */
+	FTCAN_RX_FIFO_OFFSET	  	= 0x200, /* RX FIFO shadow register */
+};
+
+
+/*---------------------------------------------------------------------------*/
+/* CAN register bit masks - FTCAN_<REG>_<BIT>_MASK                           */
+/*---------------------------------------------------------------------------*/
+/* FTCAN_CTRL mask */
+#define FTCAN_CTRL_XFER_MASK   (0x1 << 0)  /*Transfer enable*/
+#define FTCAN_CTRL_TXREQ_MASK  (0x1 << 1)  /*Transmit request*/
+#define FTCAN_CTRL_AIME_MASK   (0x1 << 2)  /*Acceptance identifier mask enable*/
+
+/* FTCAN_INTR mask */
+#define FTCAN_INTR_STATUS_MASK (0xFF << 0) /*the interrupt status*/
+#define FTCAN_INTR_BOIS_MASK   (0x1 << 0)  /*Bus off interrupt status*/
+#define FTCAN_INTR_PWIS_MASK   (0x1 << 1)  /*Passive warning interrupt status*/
+#define FTCAN_INTR_PEIS_MASK   (0x1 << 2)  /*Passive error interrupt status*/
+#define FTCAN_INTR_RFIS_MASK   (0x1 << 3)  /*RX FIFO full interrupt status*/
+#define FTCAN_INTR_TFIS_MASK   (0x1 << 4)  /*TX FIFO empty interrupt status*/
+#define FTCAN_INTR_REIS_MASK   (0x1 << 5)  /*RX frame end interrupt status*/
+#define FTCAN_INTR_TEIS_MASK   (0x1 << 6)  /*TX frame end interrupt status*/
+#define FTCAN_INTR_EIS_MASK    (0x1 << 7)  /*Error interrupt status*/
+
+#define FTCAN_INTR_EN_MASK     (0xFF << 8) /*the interrupt enable*/
+#define FTCAN_INTR_BOIE_MASK   (0x1 << 8)  /*Bus off interrupt enable*/
+#define FTCAN_INTR_PWIE_MASK   (0x1 << 9)  /*Passive warning interrupt enable*/
+#define FTCAN_INTR_PEIE_MASK   (0x1 << 10) /*Passive error interrupt enable*/
+#define FTCAN_INTR_RFIE_MASK   (0x1 << 11) /*RX FIFO full interrupt enable*/
+#define FTCAN_INTR_TFIE_MASK   (0x1 << 12) /*TX FIFO empty interrupt enable*/
+#define FTCAN_INTR_REIE_MASK   (0x1 << 13) /*RX frame end interrupt enable*/
+#define FTCAN_INTR_TEIE_MASK   (0x1 << 14) /*TX frame end interrupt enable*/
+#define FTCAN_INTR_EIE_MASK    (0x1 << 15) /*Error interrupt enable*/
+
+#define FTCAN_INTR_BOIC_MASK   (0x1 << 16) /*Bus off interrupt clear*/
+#define FTCAN_INTR_PWIC_MASK   (0x1 << 17) /*Passive warning interrupt clear*/
+#define FTCAN_INTR_PEIC_MASK   (0x1 << 18) /*Passive error interrupt clear*/
+#define FTCAN_INTR_RFIC_MASK   (0x1 << 19) /*RX FIFO full interrupt clear*/
+#define FTCAN_INTR_TFIC_MASK   (0x1 << 20) /*TX FIFO empty interrupt clear*/
+#define FTCAN_INTR_REIC_MASK   (0x1 << 21) /*RX frame end interrupt clear*/
+#define FTCAN_INTR_TEIC_MASK   (0x1 << 22) /*TX frame end interrupt clear*/
+#define FTCAN_INTR_EIC_MASK    (0x1 << 23) /*Error interrupt clear*/
+
+/* FTCAN_ACC_ID(0-3)_MASK mask */
+#define FTCAN_ACC_IDN_MASK      0x1FFFFFFF /*dont care the matching */
+
+/* FTCAN_ERR_CNT_OFFSET mask */
+#define FTCAN_ERR_CNT_RFN_MASK (0xFF << 0) /*Receive error counter*/
+#define FTCAN_ERR_CNT_TFN_MASK (0xFF << 16)/*Transmit error counter*/
+
+/* FTCAN_FIFO_CNT_OFFSET mask */
+#define FTCAN_FIFO_CNT_RFN_MASK (0xFF << 0) /*Receive FIFO valid data number*/
+#define FTCAN_FIFO_CNT_TFN_MASK (0xFF << 16)/*Transmit FIFO valid data number*/
+
+#define FTCAN_ERR_CNT_TFN_SHIFT	  16  /* Tx Error Count shift */
+#define FTCAN_FIFO_CNT_TFN_SHIFT  16  /* Tx FIFO Count shift*/
+#define FTCAN_IDR_ID1_SHIFT       21  /* Standard Messg Identifier */
+#define FTCAN_IDR_ID2_SHIFT       1   /* Extended Message Identifier */
+#define FTCAN_IDR_SDLC_SHIFT      14
+#define FTCAN_IDR_EDLC_SHIFT      26
+
+#define FTCAN_IDR_ID2_MASK	0x0007FFFE /* Extended message ident */
+#define FTCAN_IDR_ID1_MASK	0xFFE00000 /* Standard msg identifier */
+#define FTCAN_IDR_IDE_MASK	0x00080000 /* Identifier extension */
+#define FTCAN_IDR_SRR_MASK	0x00100000 /* Substitute remote TXreq */
+#define FTCAN_IDR_RTR_MASK	0x00000001 /* Extended frames remote TX request */
+#define FTCAN_IDR_DLC_MASK	0x0003C000 /* Standard msg dlc */
+#define FTCAN_IDR_PAD_MASK	0x00003FFF /* Standard msg padding 1 */
+
+#define FTCAN_INTR_EN		(FTCAN_INTR_TEIE_MASK | FTCAN_INTR_REIE_MASK)
+
+#define FTCAN_INTR_DIS      0x00000000
+#define FTCAN_NAPI_WEIGHT	64
+
+/**
+ * struct ftcan_priv - This definition define CAN driver instance
+ * @can:		CAN private data structure.
+ * @tx_head:		Tx CAN packets ready to send on the queue
+ * @tx_tail:		Tx CAN packets successfully sended on the queue
+ * @tx_max:		Maximum number packets the driver can send
+ * @napi:		NAPI structure
+ * @read_reg:		For reading data from CAN registers
+ * @write_reg:		For writing data to CAN registers
+ * @set_reg_bits:	For writing data to CAN registers bit
+ * @clr_reg_bits:	For writing 0 to CAN registers bit
+ * @dev:		Network device data structure
+ * @reg_base:		Ioremapped address to registers
+ * @irq_flags:		For request_irq()
+ * @can_clk:		Pointer to struct clk
+ * @lock:		The spin lock flag
+ * @isr:		The interrupt status
+ */
+struct ftcan_priv {
+	struct can_priv can;
+	unsigned int tx_head;
+	unsigned int tx_tail;
+	unsigned int tx_max;
+	u32 (*read_reg)(const struct ftcan_priv *priv,
+			enum ftcan_reg reg);
+	void (*write_reg)(const struct ftcan_priv *priv,
+			  enum ftcan_reg reg, u32 val);
+	void (*set_reg_bits)(const struct ftcan_priv *priv,
+			     enum ftcan_reg reg, u32 bs);
+	void (*clr_reg_bits)(const struct ftcan_priv *priv,
+			     enum ftcan_reg reg, u32 bs);
+	struct device *dev;
+	void __iomem *reg_base;
+	unsigned long irq_flags;
+	struct clk *can_clk;
+	spinlock_t lock;
+	u32 isr;
+};
+
+struct ftcan_tasklet {
+	struct net_device *ndev;
+	struct tasklet_struct   *done_task;
+};
+
+/* CAN Bittiming constants as per Phytium CAN specs */
+static const struct can_bittiming_const ftcan_bittiming_const = {
+	.name = DRIVER_NAME,
+	.tseg1_min = 1,
+	.tseg1_max = 16,
+	.tseg2_min = 1,
+	.tseg2_max = 8,
+	.sjw_max = 4,
+	.brp_min = 1,
+	.brp_max = 512,
+	.brp_inc = 2,
+};
+
+/**
+ * ftcan_write_reg - Write a value to the device register
+ * @priv:	Driver private data structure
+ * @reg:	Register offset
+ * @val:	Value to write at the Register offset
+ *
+ * Write data to the paricular CAN register
+ */
+static void ftcan_write_reg(const struct ftcan_priv *priv,
+			    enum ftcan_reg reg, u32 val)
+{
+	writel(val, priv->reg_base + reg);
+}
+
+/**
+ * ftcan_read_reg - Read a value from the device register
+ * @priv:	Driver private data structure
+ * @reg:	Register offset
+ *
+ * Read data from the particular CAN register
+ * Return: value read from the CAN register
+ */
+static u32 ftcan_read_reg(const struct ftcan_priv *priv, enum ftcan_reg reg)
+{
+	return readl(priv->reg_base + reg);
+}
+
+/**
+ * ftcan_set_reg_bits - set a bit value to the device register
+ * @priv:	Driver private data structure
+ * @reg:	Register offset
+ * @bs:     The bit mask
+ *
+ * Read data from the particular CAN register
+ * Return: value read from the CAN register
+ */
+static void ftcan_set_reg_bits(const struct ftcan_priv *priv,
+			       enum ftcan_reg reg, u32 bs)
+{
+	u32 val = readl(priv->reg_base + reg);
+
+	val |= bs;
+	writel(val, priv->reg_base + reg);
+}
+
+/**
+ * ftcan_clr_reg_bits - clear a bit value to the device register
+ * @priv:	Driver private data structure
+ * @reg:	Register offset
+ * @bs:     The bit mask
+ *
+ * Read data from the particular CAN register
+ * Return: value read from the CAN register
+ */
+static void ftcan_clr_reg_bits(const struct ftcan_priv *priv,
+			       enum ftcan_reg reg, u32 bs)
+{
+	u32 val = readl(priv->reg_base + reg);
+
+	val &= ~bs;
+	writel(val, priv->reg_base + reg);
+}
+
+/**
+ * ftcan_set_bittiming - CAN set bit timing routine
+ * @ndev:	Pointer to net_device structure
+ *
+ * This is the driver set bittiming  routine.
+ * Return: 0 on success and failure value on error
+ */
+static int ftcan_set_bittiming(struct net_device *ndev)
+{
+	struct ftcan_priv *priv = netdev_priv(ndev);
+	struct can_bittiming *bt = &priv->can.bittiming;
+	u32 btr;
+	u32 is_config_mode;
+
+	/* Check whether Phytium CAN is in configuration mode.
+	 * It cannot set bit timing if Phytium CAN is not in configuration mode.
+	 */
+	is_config_mode = (priv->read_reg(priv, FTCAN_CTRL_OFFSET) &
+			  FTCAN_CTRL_XFER_MASK);
+	if (is_config_mode) {
+		netdev_alert(ndev,
+		     "BUG! Cannot set bittiming - CAN is not in config mode\n");
+		return -EPERM;
+	}
+
+	/* Setting Baud Rate prescalar value in BRPR Register */
+	btr = (bt->brp - 1) << 16;
+
+	/* Setting Time Segment 1 in BTR Register */
+	btr |= (bt->prop_seg - 1) << 2;
+
+	btr |= (bt->phase_seg1 - 1) << 5;
+
+	/* Setting Time Segment 2 in BTR Register */
+	btr |= (bt->phase_seg2 - 1) << 8;
+
+	/* Setting Synchronous jump width in BTR Register */
+	btr |= (bt->sjw - 1);
+
+	priv->write_reg(priv, FTCAN_DAT_RATE_CTRL_OFFSET, btr);
+	priv->write_reg(priv, FTCAN_ARB_RATE_CTRL_OFFSET, btr);
+
+	netdev_dbg(ndev, "DAT=0x%08x, ARB=0x%08x\n",
+		   priv->read_reg(priv, FTCAN_DAT_RATE_CTRL_OFFSET),
+		   priv->read_reg(priv, FTCAN_ARB_RATE_CTRL_OFFSET));
+
+	return 0;
+}
+
+/**
+ * ftcan_chip_start - This the drivers start routine
+ * @ndev:	Pointer to net_device structure
+ *
+ * This is the drivers start routine.
+ * Based on the State of the CAN device it puts
+ * the CAN device into a proper mode.
+ *
+ * Return: 0 on success and failure value on error
+ */
+static int ftcan_chip_start(struct net_device *ndev)
+{
+	struct ftcan_priv *priv = netdev_priv(ndev);
+	int err;
+
+	err = ftcan_set_bittiming(ndev);
+	if (err < 0)
+		return err;
+
+	/* Identifier mask enable */
+	priv->set_reg_bits(priv, FTCAN_CTRL_OFFSET, FTCAN_CTRL_AIME_MASK);
+	priv->write_reg(priv, FTCAN_ACC_ID0_MASK_OFFSET, FTCAN_ACC_IDN_MASK);
+	priv->write_reg(priv, FTCAN_ACC_ID1_MASK_OFFSET, FTCAN_ACC_IDN_MASK);
+	priv->write_reg(priv, FTCAN_ACC_ID2_MASK_OFFSET, FTCAN_ACC_IDN_MASK);
+	priv->write_reg(priv, FTCAN_ACC_ID3_MASK_OFFSET, FTCAN_ACC_IDN_MASK);
+
+	/* Enable interrupts */
+	priv->write_reg(priv, FTCAN_INTR_OFFSET, FTCAN_INTR_EN);
+
+	/*Enable Transfer*/
+	priv->set_reg_bits(priv, FTCAN_CTRL_OFFSET, FTCAN_CTRL_XFER_MASK);
+
+	netdev_dbg(ndev, "status:#x%08x\n",
+		   priv->read_reg(priv, FTCAN_XFER_STS_OFFSET));
+
+	priv->can.state = CAN_STATE_ERROR_ACTIVE;
+	return 0;
+}
+
+/**
+ * ftcan_do_set_mode - This sets the mode of the driver
+ * @ndev:	Pointer to net_device structure
+ * @mode:	Tells the mode of the driver
+ *
+ * This check the drivers state and calls the
+ * the corresponding modes to set.
+ *
+ * Return: 0 on success and failure value on error
+ */
+static int ftcan_do_set_mode(struct net_device *ndev, enum can_mode mode)
+{
+	int ret;
+
+	switch (mode) {
+	case CAN_MODE_START:
+		ret = ftcan_chip_start(ndev);
+		if (ret < 0) {
+			netdev_err(ndev, "xcan_chip_start failed!\n");
+			return ret;
+		}
+		netif_wake_queue(ndev);
+		break;
+	default:
+		ret = -EOPNOTSUPP;
+		break;
+	}
+
+	return ret;
+}
+
+/**
+ * ftcan_start_xmit - Starts the transmission
+ * @skb:	sk_buff pointer that contains data to be Txed
+ * @ndev:	Pointer to net_device structure
+ *
+ * This function is invoked from upper layers to initiate transmission. This
+ * function uses the next available free txbuff and populates their fields to
+ * start the transmission.
+ *
+ * Return: 0 on success and failure value on error
+ */
+static int ftcan_start_xmit(struct sk_buff *skb, struct net_device *ndev)
+{
+	struct ftcan_priv *priv = netdev_priv(ndev);
+	struct net_device_stats *stats = &ndev->stats;
+	struct can_frame *cf = (struct can_frame *)skb->data;
+	u32 id, dlc, frame_head[2] = {0, 0},  data[8] = {0, 0};
+	u32 tx_fifo_cnt;
+	unsigned long flags;
+
+	if (can_dropped_invalid_skb(ndev, skb))
+		return NETDEV_TX_OK;
+
+	/* Check if the TX buffer is full */
+	tx_fifo_cnt = (priv->read_reg(priv, FTCAN_FIFO_CNT_OFFSET) >> FTCAN_FIFO_CNT_TFN_SHIFT);
+	if (tx_fifo_cnt == priv->tx_max) {
+		netif_stop_queue(ndev);
+		netdev_err(ndev, "BUG!, TX FIFO full when queue awake!\n");
+		return NETDEV_TX_BUSY;
+	}
+
+	if(priv->tx_head == priv->tx_tail){
+		priv->tx_head = priv->tx_tail = 0;
+	}
+
+	/* Watch carefully on the bit sequence */
+	if (cf->can_id & CAN_EFF_FLAG) {
+		/* Extended CAN ID format */
+		id = ((cf->can_id & CAN_EFF_MASK) << FTCAN_IDR_ID2_SHIFT) &
+			FTCAN_IDR_ID2_MASK;
+		id |= (((cf->can_id & CAN_EFF_MASK) >>
+			(CAN_EFF_ID_BITS-CAN_SFF_ID_BITS)) <<
+			FTCAN_IDR_ID1_SHIFT) & FTCAN_IDR_ID1_MASK;
+
+		/* The substibute remote TX request bit should be "1"
+		 * for extended frames as in the Xilinx CAN datasheet
+		 */
+		id |= FTCAN_IDR_IDE_MASK | FTCAN_IDR_SRR_MASK;
+
+		if (cf->can_id & CAN_RTR_FLAG)
+			/* Extended frames remote TX request */
+			id |= FTCAN_IDR_RTR_MASK;
+
+		dlc = cf->can_dlc << FTCAN_IDR_EDLC_SHIFT;
+
+		frame_head[0] = cpu_to_be32p(&id);//id;
+		frame_head[1] = cpu_to_be32p(&dlc);//dlc;
+
+		/* Write the Frame to Phytium CAN TX FIFO */
+		priv->write_reg(priv, FTCAN_TX_FIFO_OFFSET, frame_head[0]);
+		priv->write_reg(priv, FTCAN_TX_FIFO_OFFSET, frame_head[1]);
+	} else {
+		/* Standard CAN ID format */
+		id = ((cf->can_id & CAN_SFF_MASK) << FTCAN_IDR_ID1_SHIFT) &
+		     FTCAN_IDR_ID1_MASK;
+
+		if (cf->can_id & CAN_RTR_FLAG)
+			/* Standard frames remote TX request */
+			id |= FTCAN_IDR_SRR_MASK;
+
+		dlc = ((cf->can_dlc << FTCAN_IDR_SDLC_SHIFT) | FTCAN_IDR_PAD_MASK);
+		id |= dlc;
+
+		frame_head[0] =  cpu_to_be32p(&id);
+
+		/* Write the Frame to Xilinx CAN TX FIFO */
+		priv->write_reg(priv, FTCAN_TX_FIFO_OFFSET, frame_head[0]);
+	}
+
+	if (!(cf->can_id & CAN_RTR_FLAG)) {
+		if (cf->can_dlc > 0) {
+			data[0] = (*(__be32*)(cf->data + 0));
+			priv->write_reg(priv, FTCAN_TX_FIFO_OFFSET, data[0]);
+		}
+		if (cf->can_dlc > 4) {
+			data[1] = (*(__be32*)(cf->data + 4));
+			priv->write_reg(priv, FTCAN_TX_FIFO_OFFSET, data[1]);
+		}
+		stats->tx_bytes += cf->can_dlc;
+	}
+
+	can_put_echo_skb(skb, ndev, priv->tx_head % priv->tx_max);
+	priv->tx_head++;
+
+	/* triggers tranmission */
+	spin_lock_irqsave(&priv->lock, flags);
+	priv->clr_reg_bits(priv, FTCAN_CTRL_OFFSET, FTCAN_CTRL_XFER_MASK);
+	priv->set_reg_bits(priv, FTCAN_CTRL_OFFSET, FTCAN_CTRL_TXREQ_MASK);
+	priv->set_reg_bits(priv, FTCAN_CTRL_OFFSET, FTCAN_CTRL_TXREQ_MASK|FTCAN_CTRL_XFER_MASK);
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	/* Check if the TX buffer is full */
+	if ((priv->tx_head - priv->tx_tail) == priv->tx_max)
+		netif_stop_queue(ndev);
+
+	return NETDEV_TX_OK;
+}
+
+/**
+ * ftcan_rx -  Is called from CAN isr to complete the received
+ *		frame  processing
+ * @ndev:	Pointer to net_device structure
+ *
+ * This function is invoked from the CAN isr(poll) to process the Rx frames. It
+ * does minimal processing and invokes "netif_receive_skb" to complete further
+ * processing.
+ * Return: 1 on success and 0 on failure.
+ */
+static int ftcan_rx(struct net_device *ndev)
+{
+	struct ftcan_priv *priv = netdev_priv(ndev);
+	struct net_device_stats *stats = &ndev->stats;
+	struct can_frame *cf;
+	struct sk_buff *skb;
+	u32 id_ftcan, dlc, data[2] = {0, 0};
+
+	skb = alloc_can_skb(ndev, &cf);
+	if (unlikely(!skb)) {
+		stats->rx_dropped++;
+		return 0;
+	}
+
+	/* Read a frame from Phytium CAN */
+	id_ftcan = priv->read_reg(priv, FTCAN_RX_FIFO_OFFSET);
+	id_ftcan = be32_to_cpup(&id_ftcan);
+
+	/* Change Phytium CAN ID format to socketCAN ID format */
+	if (id_ftcan & FTCAN_IDR_IDE_MASK) {
+		/* The received frame is an Extended format frame */
+		dlc = priv->read_reg(priv, FTCAN_RX_FIFO_OFFSET);
+
+		cf->can_id = (id_ftcan & FTCAN_IDR_ID1_MASK) >> 3;
+		cf->can_id |= (id_ftcan & FTCAN_IDR_ID2_MASK) >> FTCAN_IDR_ID2_SHIFT;
+		cf->can_id |= CAN_EFF_FLAG;
+		if (id_ftcan & FTCAN_IDR_RTR_MASK)
+			cf->can_id |= CAN_RTR_FLAG;
+	} else {
+		dlc = ((id_ftcan & FTCAN_IDR_DLC_MASK ) >> FTCAN_IDR_SDLC_SHIFT);
+
+		/* The received frame is a standard format frame */
+		cf->can_id = (id_ftcan & FTCAN_IDR_ID1_MASK) >> FTCAN_IDR_ID1_SHIFT;
+		if (id_ftcan & FTCAN_IDR_SRR_MASK)
+			cf->can_id |= CAN_RTR_FLAG;
+	}
+
+	/* Change Phytium CAN data length format to socketCAN data format */
+	cf->can_dlc = get_can_dlc(dlc);
+
+	if (!(cf->can_id & CAN_RTR_FLAG)) {
+		/* Change Phytium CAN data format to socketCAN data format */
+		if (cf->can_dlc > 0){
+			data[0] = priv->read_reg(priv, FTCAN_RX_FIFO_OFFSET);
+			*(__be32 *)(cf->data) = (data[0]);
+		}
+
+		if (cf->can_dlc > 4){
+			data[1] = priv->read_reg(priv, FTCAN_RX_FIFO_OFFSET);
+			*(__be32 *)(cf->data + 4) = (data[1]);
+		}
+
+	}
+
+	stats->rx_bytes += cf->can_dlc;
+	stats->rx_packets++;
+	netif_receive_skb(skb);
+
+	return 1;
+}
+
+/**
+ * ftcan_err_interrupt - error frame Isr
+ * @ndev:	net_device pointer
+ * @isr:	interrupt status register value
+ *
+ * This is the CAN error interrupt and it will
+ * check the the type of error and forward the error
+ * frame to upper layers.
+ */
+static void ftcan_err_interrupt(struct net_device *ndev, u32 isr)
+{
+	struct ftcan_priv *priv = netdev_priv(ndev);
+	struct net_device_stats *stats = &ndev->stats;
+	struct can_frame *cf;
+	struct sk_buff *skb;
+	u32  txerr = 0, rxerr = 0;
+
+	skb = alloc_can_err_skb(ndev, &cf);
+
+	rxerr = priv->read_reg(priv, FTCAN_ERR_CNT_OFFSET) & FTCAN_ERR_CNT_RFN_MASK;
+	txerr = ((priv->read_reg(priv, FTCAN_ERR_CNT_OFFSET) &
+		FTCAN_ERR_CNT_TFN_MASK) >> FTCAN_ERR_CNT_TFN_SHIFT);
+
+	if (isr & FTCAN_INTR_BOIS_MASK) {
+		priv->can.state = CAN_STATE_BUS_OFF;
+		priv->can.can_stats.bus_off++;
+		/* Leave device in Config Mode in bus-off state */
+		can_bus_off(ndev);
+		if (skb)
+			cf->can_id |= CAN_ERR_BUSOFF;
+	} else if ((isr & FTCAN_INTR_PEIS_MASK) == FTCAN_INTR_PEIS_MASK) {
+		priv->can.state = CAN_STATE_ERROR_PASSIVE;
+		priv->can.can_stats.error_passive++;
+		if (skb) {
+			cf->can_id |= CAN_ERR_CRTL;
+			cf->data[1] = (rxerr > 127) ?
+					CAN_ERR_CRTL_RX_PASSIVE :
+					CAN_ERR_CRTL_TX_PASSIVE;
+			cf->data[6] = txerr;
+			cf->data[7] = rxerr;
+		}
+	} else if (isr & FTCAN_INTR_PWIS_MASK) {
+		priv->can.state = CAN_STATE_ERROR_WARNING;
+		priv->can.can_stats.error_warning++;
+		if (skb) {
+			cf->can_id |= CAN_ERR_CRTL;
+			cf->data[1] |= (txerr > rxerr) ?
+					CAN_ERR_CRTL_TX_WARNING :
+					CAN_ERR_CRTL_RX_WARNING;
+			cf->data[6] = txerr;
+			cf->data[7] = rxerr;
+		}
+	}
+
+	/* Check for RX FIFO Overflow interrupt */
+	if (isr & FTCAN_INTR_RFIS_MASK) {
+		stats->rx_over_errors++;
+		stats->rx_errors++;
+
+		if (skb) {
+			cf->can_id |= CAN_ERR_CRTL;
+			cf->data[1] |= CAN_ERR_CRTL_RX_OVERFLOW;
+		}
+	}
+
+	if (skb) {
+		stats->rx_packets++;
+		stats->rx_bytes += cf->can_dlc;
+		netif_rx(skb);
+	}
+
+	netdev_dbg(ndev, "%s: error status register:0x%x\n",
+			__func__, (priv->read_reg(priv, FTCAN_INTR_OFFSET) & FTCAN_INTR_STATUS_MASK));
+}
+
+/**
+ * ftcan_rx_poll - Poll routine for rx packets (NAPI)
+ * @napi:	napi structure pointer
+ * @quota:	Max number of rx packets to be processed.
+ *
+ * This is the poll routine for rx part.
+ * It will process the packets maximux quota value.
+ *
+ * Return: number of packets received
+ */
+
+static void  ftcan_rx_poll(unsigned long data)
+{
+	struct ftcan_tasklet *t = (struct ftcan_tasklet *)data;
+	struct net_device *ndev = t->ndev;
+	int work_done = 0;
+
+	struct tasklet_struct *pcan_task = NULL;
+
+	pcan_task = t->done_task;
+
+	if (t)
+		kfree(t);
+
+	if (ndev) {
+		work_done += ftcan_rx(ndev);
+
+		if (work_done)
+			can_led_event(ndev, CAN_LED_EVENT_RX);
+	}
+
+	if (pcan_task) {
+		kfree(pcan_task);
+		pcan_task = NULL;
+	}
+
+	return ;
+}
+
+/**
+ * ftcan_tx_interrupt - Tx Done Isr
+ * @ndev:	net_device pointer
+ * @isr:	Interrupt status register value
+ */
+static void ftcan_tx_interrupt(struct net_device *ndev, u32 isr)
+{
+	struct ftcan_priv *priv = netdev_priv(ndev);
+	struct net_device_stats *stats = &ndev->stats;
+
+	while ((priv->tx_head - priv->tx_tail > 0) &&
+		(isr & FTCAN_INTR_TEIS_MASK)) {
+		priv->set_reg_bits(priv, FTCAN_INTR_OFFSET,
+				   FTCAN_INTR_TEIC_MASK|FTCAN_INTR_REIC_MASK);
+		can_get_echo_skb(ndev, priv->tx_tail % priv->tx_max);
+		priv->tx_tail++;
+		stats->tx_packets++;
+		isr = (priv->read_reg(priv, FTCAN_INTR_OFFSET) &
+		       FTCAN_INTR_STATUS_MASK);
+	}
+
+	priv->clr_reg_bits(priv, FTCAN_CTRL_OFFSET, FTCAN_CTRL_XFER_MASK);
+	priv->clr_reg_bits(priv, FTCAN_CTRL_OFFSET, FTCAN_CTRL_TXREQ_MASK);
+	priv->set_reg_bits(priv, FTCAN_CTRL_OFFSET, FTCAN_CTRL_XFER_MASK);
+
+	can_led_event(ndev, CAN_LED_EVENT_TX);
+	netif_wake_queue(ndev);
+}
+
+/**
+ * ftcan_interrupt - CAN Isr
+ * @irq:	irq number
+ * @dev_id:	device id poniter
+ *
+ * This is the xilinx CAN Isr. It checks for the type of interrupt
+ * and invokes the corresponding ISR.
+ *
+ * Return:
+ * IRQ_NONE - If CAN device is in sleep mode, IRQ_HANDLED otherwise
+ */
+static irqreturn_t ftcan_interrupt(int irq, void *dev_id)
+{
+	struct net_device *ndev = (struct net_device *)dev_id;
+	struct ftcan_priv *priv = netdev_priv(ndev);
+	u32 isr;
+	struct ftcan_tasklet *pcan_tasklet_priv = NULL;
+	struct tasklet_struct *pcan_tasklet = NULL;
+
+	/* Get the interrupt status from Phytium CAN */
+	isr = (priv->read_reg(priv, FTCAN_INTR_OFFSET) & FTCAN_INTR_STATUS_MASK);
+	if (!isr)
+		return IRQ_NONE;
+
+	/* Check for Tx interrupt and Processing it */
+	if ((isr & FTCAN_INTR_TEIS_MASK)) {
+		isr &= (~FTCAN_INTR_REIS_MASK);
+		ftcan_tx_interrupt(ndev, isr);
+	}
+
+	/* Check for the type of error interrupt and Processing it */
+	if (isr & (FTCAN_INTR_EIS_MASK | FTCAN_INTR_RFIS_MASK |
+			FTCAN_INTR_BOIS_MASK | FTCAN_INTR_PEIS_MASK)) {
+		priv->clr_reg_bits(priv, FTCAN_INTR_OFFSET,
+				   (FTCAN_INTR_EIC_MASK | FTCAN_INTR_RFIC_MASK |
+				    FTCAN_INTR_BOIC_MASK | FTCAN_INTR_PEIC_MASK));
+		ftcan_err_interrupt(ndev, isr);
+	}
+
+	/* Check for the type of receive interrupt and Processing it */
+	if (isr & (FTCAN_INTR_REIS_MASK)) {
+		priv->isr = (isr & FTCAN_INTR_REIS_MASK);
+		priv->set_reg_bits(priv, FTCAN_INTR_OFFSET, FTCAN_INTR_REIC_MASK);
+
+		pcan_tasklet_priv = (struct ftcan_tasklet *)kzalloc(sizeof(struct ftcan_tasklet), GFP_ATOMIC);
+		pcan_tasklet = (struct tasklet_struct *)kzalloc(sizeof(struct tasklet_struct), GFP_ATOMIC);
+		if (pcan_tasklet_priv && pcan_tasklet) {
+			pcan_tasklet_priv->ndev = ndev;
+			pcan_tasklet_priv->done_task = pcan_tasklet;
+			tasklet_init(pcan_tasklet, ftcan_rx_poll, (unsigned long)pcan_tasklet_priv);
+			tasklet_schedule(pcan_tasklet);
+		} else {
+			if(pcan_tasklet)
+				kfree(pcan_tasklet);
+			if(pcan_tasklet_priv)
+				kfree(pcan_tasklet_priv);
+		}
+ 	}
+
+	return IRQ_HANDLED;
+}
+
+/**
+ * ftcan_chip_stop - Driver stop routine
+ * @ndev:	Pointer to net_device structure
+ *
+ * This is the drivers stop routine. It will disable the
+ * interrupts and put the device into configuration mode.
+ */
+static void ftcan_chip_stop(struct net_device *ndev)
+{
+	struct ftcan_priv *priv = netdev_priv(ndev);
+	u32 ier;
+
+	/* Disable interrupts and leave the can in configuration mode */
+	ier = (FTCAN_INTR_DIS & FTCAN_INTR_EN_MASK);
+	priv->clr_reg_bits(priv, FTCAN_INTR_OFFSET, ier);
+
+	/*Disable Transfer*/
+	priv->clr_reg_bits(priv, FTCAN_CTRL_OFFSET, FTCAN_CTRL_XFER_MASK);
+	priv->can.state = CAN_STATE_STOPPED;
+}
+
+/**
+ * ftcan_open - Driver open routine
+ * @ndev:	Pointer to net_device structure
+ *
+ * This is the driver open routine.
+ * Return: 0 on success and failure value on error
+ */
+static int ftcan_open(struct net_device *ndev)
+{
+	struct ftcan_priv *priv = netdev_priv(ndev);
+	int ret;
+
+	ret = request_irq(ndev->irq, ftcan_interrupt, priv->irq_flags,
+			  ndev->name, ndev);
+	if (ret < 0) {
+		netdev_err(ndev, "irq allocation for CAN failed\n");
+		goto err;
+	}
+
+	/* Common open */
+	ret = open_candev(ndev);
+	if (ret)
+		goto err_irq;
+
+	ret = ftcan_chip_start(ndev);
+	if (ret < 0) {
+		netdev_err(ndev, "ftcan_chip_start failed!\n");
+		goto err_candev;
+	}
+
+	can_led_event(ndev, CAN_LED_EVENT_OPEN);
+
+	netif_start_queue(ndev);
+
+	return 0;
+
+err_candev:
+	close_candev(ndev);
+err_irq:
+	free_irq(ndev->irq, ndev);
+err:
+	return ret;
+}
+
+/**
+ * ftcan_close - Driver close routine
+ * @ndev:	Pointer to net_device structure
+ *
+ * Return: 0 always
+ */
+static int ftcan_close(struct net_device *ndev)
+{
+	netif_stop_queue(ndev);
+	ftcan_chip_stop(ndev);
+	free_irq(ndev->irq, ndev);
+	close_candev(ndev);
+
+	can_led_event(ndev, CAN_LED_EVENT_STOP);
+
+	return 0;
+}
+
+/**
+ * ftcan_get_berr_counter - error counter routine
+ * @ndev:	Pointer to net_device structure
+ * @bec:	Pointer to can_berr_counter structure
+ *
+ * This is the driver error counter routine.
+ * Return: 0 on success and failure value on error
+ */
+static int ftcan_get_berr_counter(const struct net_device *ndev,
+					struct can_berr_counter *bec)
+{
+	struct ftcan_priv *priv = netdev_priv(ndev);
+
+	bec->rxerr = priv->read_reg(priv, FTCAN_ERR_CNT_OFFSET) & FTCAN_ERR_CNT_RFN_MASK;
+	bec->txerr = ((priv->read_reg(priv, FTCAN_ERR_CNT_OFFSET) &
+			FTCAN_ERR_CNT_TFN_MASK) >> FTCAN_ERR_CNT_TFN_SHIFT);
+
+	return 0;
+}
+
+
+static const struct net_device_ops ftcan_netdev_ops = {
+	.ndo_open	= ftcan_open,
+	.ndo_stop	= ftcan_close,
+	.ndo_start_xmit	= ftcan_start_xmit,
+	.ndo_change_mtu	= can_change_mtu,
+};
+
+
+#define ftcan_dev_pm_ops NULL
+
+/**
+ * ftcan_probe - Platform registration call
+ * @pdev:	Handle to the platform device structure
+ *
+ * This function does all the memory allocation and registration for the CAN
+ * device.
+ *
+ * Return: 0 on success and failure value on error
+ */
+static int ftcan_probe(struct platform_device *pdev)
+{
+	struct resource *res; /* IO mem resources */
+	struct net_device *ndev;
+	struct ftcan_priv *priv;
+	void __iomem *addr;
+	int ret, rx_max, tx_max;
+
+	/* Get the virtual base address for the device */
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	addr = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(addr)) {
+		ret = PTR_ERR(addr);
+		goto err;
+	}
+
+	ret = of_property_read_u32(pdev->dev.of_node, "tx-fifo-depth", &tx_max);
+	if (ret < 0)
+		goto err;
+
+	ret = of_property_read_u32(pdev->dev.of_node, "rx-fifo-depth", &rx_max);
+	if (ret < 0)
+		goto err;
+
+	/* Create a CAN device instance */
+	ndev = alloc_candev(sizeof(struct ftcan_priv), tx_max);
+	if (!ndev)
+		return -ENOMEM;
+
+	priv = netdev_priv(ndev);
+	priv->dev = &pdev->dev;
+	priv->can.bittiming_const = &ftcan_bittiming_const;
+	priv->can.do_set_mode = ftcan_do_set_mode;
+	priv->can.do_get_berr_counter = ftcan_get_berr_counter;
+	priv->can.ctrlmode_supported = CAN_CTRLMODE_BERR_REPORTING;
+	priv->reg_base = addr;
+	priv->tx_max = tx_max;
+	priv->tx_head = 0;
+	priv->tx_tail = 0;
+
+	/* Get IRQ for the device */
+	ndev->irq = platform_get_irq(pdev, 0);
+	ndev->flags |= IFF_ECHO;	/* We support local echo */
+	priv->irq_flags = IRQF_SHARED;
+
+	spin_lock_init(&priv->lock);
+
+	platform_set_drvdata(pdev, ndev);
+	SET_NETDEV_DEV(ndev, &pdev->dev);
+	ndev->netdev_ops = &ftcan_netdev_ops;
+
+	/* Getting the CAN can_clk info */
+	priv->can_clk = devm_clk_get(&pdev->dev, "phytium_can_clk");
+	if (IS_ERR(priv->can_clk)) {
+		dev_err(&pdev->dev, "Device clock not found.\n");
+		ret = PTR_ERR(priv->can_clk);
+		goto err_free;
+	}
+
+	priv->can.clock.freq = clk_get_rate(priv->can_clk);
+
+	ret = clk_prepare_enable(priv->can_clk);
+	if (ret)
+		return ret;
+
+	priv->write_reg = ftcan_write_reg;
+	priv->read_reg = ftcan_read_reg;
+	priv->set_reg_bits = ftcan_set_reg_bits;
+	priv->clr_reg_bits = ftcan_clr_reg_bits;
+
+	ret = register_candev(ndev);
+	if (ret) {
+		dev_err(&pdev->dev, "fail to register failed (err=%d)\n", ret);
+		goto err_disableclks;
+	}
+	devm_can_led_init(ndev);
+	netdev_dbg(ndev, "reg_base=0x%p irq=%d clock=%d, tx fifo depth:%d\n",
+			priv->reg_base, ndev->irq, priv->can.clock.freq,
+			priv->tx_max);
+
+	return 0;
+
+err_disableclks:
+
+err_free:
+	free_candev(ndev);
+err:
+	return ret;
+}
+
+/**
+ * ftcan_remove - Unregister the device after releasing the resources
+ * @pdev:	Handle to the platform device structure
+ *
+ * This function frees all the resources allocated to the device.
+ * Return: 0 always
+ */
+static int ftcan_remove(struct platform_device *pdev)
+{
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	unregister_candev(ndev);
+	free_candev(ndev);
+	return 0;
+}
+
+/* Match table for OF platform binding */
+static const struct of_device_id ftcan_of_match[] = {
+	{ .compatible = "phytium,can", },
+	{ /* end of list */ },
+};
+MODULE_DEVICE_TABLE(of, ftcan_of_match);
+
+static struct platform_driver ftcan_driver = {
+	.probe = ftcan_probe,
+	.remove	= ftcan_remove,
+	.driver	= {
+		.name = "phytium-can",
+		.pm = ftcan_dev_pm_ops,
+		.of_match_table	= ftcan_of_match,
+	},
+};
+
+module_platform_driver(ftcan_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Leo Hou <houyuefei@phytium.com.cn>");
+MODULE_AUTHOR("Chen Baozi <chenbaozi@phytium.com.cn>");
+MODULE_DESCRIPTION("Phytium CAN Controller");
diff --git a/drivers/net/ethernet/stmicro/stmmac/dwmac-generic.c b/drivers/net/ethernet/stmicro/stmmac/dwmac-generic.c
index fad503820e04..8241d670f6a1 100644
--- a/drivers/net/ethernet/stmicro/stmmac/dwmac-generic.c
+++ b/drivers/net/ethernet/stmicro/stmmac/dwmac-generic.c
@@ -9,6 +9,7 @@
  * warranty of any kind, whether express or implied.
  */
 
+#include <linux/acpi.h>
 #include <linux/module.h>
 #include <linux/of.h>
 #include <linux/platform_device.h>
@@ -32,6 +33,12 @@ static int dwmac_generic_probe(struct platform_device *pdev)
 			dev_err(&pdev->dev, "dt configuration failed\n");
 			return PTR_ERR(plat_dat);
 		}
+	} else if (has_acpi_companion(&pdev->dev)) {
+		plat_dat = stmmac_probe_config_acpi(pdev, &stmmac_res.mac);
+		if (!plat_dat) {
+			dev_err(&pdev->dev, "acpi configuration failed\n");
+			return  -EINVAL;
+		}
 	} else {
 		plat_dat = dev_get_platdata(&pdev->dev);
 		if (!plat_dat) {
@@ -84,6 +91,17 @@ static const struct of_device_id dwmac_generic_match[] = {
 };
 MODULE_DEVICE_TABLE(of, dwmac_generic_match);
 
+#ifdef CONFIG_ACPI
+static const struct acpi_device_id dwmac_acpi_ids[] = {
+	{ .id = "PHYT0004" },
+	{},
+};
+
+MODULE_DEVICE_TABLE(acpi, dwmac_acpi_ids);
+#else
+#define dwmac_acpi_ids NULL
+#endif
+
 static struct platform_driver dwmac_generic_driver = {
 	.probe  = dwmac_generic_probe,
 	.remove = stmmac_pltfr_remove,
@@ -91,6 +109,7 @@ static struct platform_driver dwmac_generic_driver = {
 		.name           = STMMAC_RESOURCE_NAME,
 		.pm		= &stmmac_pltfr_pm_ops,
 		.of_match_table = of_match_ptr(dwmac_generic_match),
+		.acpi_match_table = ACPI_PTR(dwmac_acpi_ids),
 	},
 };
 module_platform_driver(dwmac_generic_driver);
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
index 75896d6ba6e2..0ddcfa4fdce7 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
@@ -24,6 +24,7 @@
 	https://bugzilla.stlinux.com/
 *******************************************************************************/
 
+#include <linux/acpi.h>
 #include <linux/clk.h>
 #include <linux/kernel.h>
 #include <linux/interrupt.h>
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.c
index 2b800ce1d5bf..a4485ea0d2b1 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.c
@@ -18,6 +18,9 @@
   Author: Giuseppe Cavallaro <peppe.cavallaro@st.com>
 *******************************************************************************/
 
+#include <linux/acpi.h>
+#include <linux/clk-provider.h>
+#include <linux/clkdev.h>
 #include <linux/platform_device.h>
 #include <linux/module.h>
 #include <linux/io.h>
@@ -607,6 +610,248 @@ void stmmac_remove_config_dt(struct platform_device *pdev,
 EXPORT_SYMBOL_GPL(stmmac_probe_config_dt);
 EXPORT_SYMBOL_GPL(stmmac_remove_config_dt);
 
+#ifdef CONFIG_ACPI
+/*
+ * Parse ACPI _DSD to setup AXI register
+ */
+static struct stmmac_axi * stmmac_axi_setup_acpi(struct platform_device *pdev)
+{
+	struct fwnode_handle *np = dev_fwnode(&(pdev->dev));
+	struct stmmac_axi * axi;
+
+	axi = devm_kzalloc(&pdev->dev, sizeof(*axi), GFP_KERNEL);
+	if (!axi)
+		return ERR_PTR(-ENOMEM);
+
+	axi->axi_lpi_en = fwnode_property_read_bool(np, "snps,lpi_en");
+	axi->axi_xit_frm = fwnode_property_read_bool(np, "snps,xit_frm");
+	axi->axi_kbbe = fwnode_property_read_bool(np, "snps,axi_kbbe");
+	axi->axi_fb = fwnode_property_read_bool(np, "snps,axi_fb");
+	axi->axi_mb = fwnode_property_read_bool(np, "snps,axi_mb");
+	axi->axi_rb = fwnode_property_read_bool(np, "snps,axi_rb");
+
+	if (fwnode_property_read_u32(np, "snps,wr_osr_lmt", &axi->axi_wr_osr_lmt))
+		axi->axi_wr_osr_lmt = 1;
+	if (fwnode_property_read_u32(np, "snps,rd_osr_lmt", &axi->axi_rd_osr_lmt))
+		axi->axi_rd_osr_lmt = 1;
+	fwnode_property_read_u32_array(np, "snps,blen", axi->axi_blen, AXI_BLEN);
+
+	return axi;
+}
+
+/**
+ * Parse ACPI _DSD parameters for multiple queues configuration
+ */
+static void stmmac_mtl_setup_acpi(struct platform_device *pdev,
+				  struct plat_stmmacenet_data *plat)
+{
+	plat->rx_queues_to_use = 1;
+	plat->tx_queues_to_use = 1;
+
+	/**
+	 * First Queue must always be in DCB mode. As MTL_QUEUE_DCB=1 we need
+	 * to always set this, otherwise Queue will be classified as AVB
+	 * (because MTL_QUEUE_AVB = 0).
+	 */
+	plat->rx_queues_cfg[0].mode_to_use = MTL_QUEUE_DCB;
+	plat->tx_queues_cfg[0].mode_to_use = MTL_QUEUE_DCB;
+
+	plat->rx_queues_cfg[0].use_prio = true;
+
+	plat->rx_queues_cfg[0].pkt_route = 0x0;
+
+	plat->rx_sched_algorithm = MTL_RX_ALGORITHM_SP;
+	plat->tx_sched_algorithm = MTL_TX_ALGORITHM_SP;
+
+	plat->tx_queues_cfg[0].use_prio = true;
+}
+
+static int stmmac_acpi_phy(struct plat_stmmacenet_data *plat,
+			   struct fwnode_handle *np, struct device *dev)
+{
+	plat->mdio_bus_data = devm_kzalloc(dev,
+					   sizeof(struct stmmac_mdio_bus_data),
+					   GFP_KERNEL);
+
+	return 0;
+}
+
+int fw_get_phy_mode(struct fwnode_handle *np)
+{
+	const char *pm;
+	int err, i;
+
+	err = fwnode_property_read_string(np, "phy-mode", &pm);
+	if (err < 0)
+		err = fwnode_property_read_string(np, "phy-connection-mode", &pm);
+	if (err < 0)
+		return err;
+
+	for (i = 0; i < PHY_INTERFACE_MODE_MAX; i++) {
+		if (!strcasecmp(pm, phy_modes(i)))
+			return i;
+	}
+
+	return -ENODEV;
+}
+
+int stmmac_acpi_clock_setup(struct plat_stmmacenet_data *plat,
+			    struct platform_device *pdev)
+{
+	struct fwnode_handle *np = dev_fwnode(&(pdev->dev));
+	struct device * dev = &pdev->dev;
+	struct clk *clk = ERR_PTR(-ENODEV);
+	u64 clk_freq = 0;
+	int err;
+
+	err = fwnode_property_read_u64(np, "clock-frequency", &clk_freq);
+	if (err < 0)
+		clk_freq = 125000000; /* default to 125MHz */
+
+	plat->stmmac_clk = devm_clk_get(dev, dev_name(dev));
+	if (IS_ERR(plat->stmmac_clk)) {
+		clk = clk_register_fixed_rate(dev, dev_name(dev), NULL, 0, clk_freq);
+		if (IS_ERR(clk))
+			return -1;
+		if (clk_register_clkdev(clk, dev_name(dev), dev_name(dev)))
+			return -1;
+		plat->stmmac_clk = clk;
+	}
+	clk_prepare_enable(plat->stmmac_clk);
+
+	plat->pclk = devm_clk_get(dev, "pclk");
+	if (IS_ERR(plat->pclk))
+		plat->pclk = NULL;
+	clk_prepare_enable(plat->pclk);
+
+	plat->clk_ptp_ref = devm_clk_get(dev, "ptp_ref");
+	if (IS_ERR(plat->clk_ptp_ref)) {
+		plat->clk_ptp_rate = clk_get_rate(plat->stmmac_clk);
+		plat->clk_ptp_ref = NULL;
+	}
+
+	plat->stmmac_rst = devm_reset_control_get(dev,STMMAC_RESOURCE_NAME);
+	if (IS_ERR(plat->stmmac_rst)) {
+		dev_info(dev, "no reset control found\n");
+		plat->stmmac_rst = NULL;
+	}
+
+	return 0;
+}
+
+/**
+ * Parse ACPI driver parameters
+ */
+struct plat_stmmacenet_data *
+stmmac_probe_config_acpi(struct platform_device *pdev, const char **mac)
+{
+	struct fwnode_handle *np;
+	struct plat_stmmacenet_data *plat;
+	struct stmmac_dma_cfg *dma_cfg;
+
+	plat = devm_kzalloc(&pdev->dev, sizeof(*plat), GFP_KERNEL);
+	if (!plat)
+		return ERR_PTR(-ENOMEM);
+
+	np = dev_fwnode(&(pdev->dev));
+
+	plat->interface = fw_get_phy_mode(np);
+
+	/* Get max speed of operation from device tree */
+	if (fwnode_property_read_u32(np, "max-speed", &plat->max_speed))
+		plat->max_speed = -1;
+
+	if (fwnode_property_read_u32(np, "bus_id", &plat->bus_id))
+		plat->bus_id = 2;
+
+	/* Default to PHY auto-detection */
+	plat->phy_addr = -1;
+
+	/* "snps,phy-addr" is not a standard property. Mark it as deprecated
+	 * and warn of its use. Remove this when PHY node support is added.
+         */
+	if (fwnode_property_read_u32(np, "snps,phy-addr", &plat->phy_addr) == 0)
+		dev_warn(&pdev->dev, "snps,phy-addr property is deprecated\n");
+
+	if (stmmac_acpi_phy(plat, np, &pdev->dev))
+		return ERR_PTR(-ENODEV);
+
+	fwnode_property_read_u32(np, "tx-fifo-depth", &plat->tx_fifo_size);
+	fwnode_property_read_u32(np, "rx-fifo-depth", &plat->rx_fifo_size);
+	if (plat->tx_fifo_size == 0)
+		plat->tx_fifo_size = 0x10000;
+	if (plat->rx_fifo_size == 0)
+		plat->rx_fifo_size = 0x10000;
+
+	plat->force_sf_dma_mode =
+		fwnode_property_read_bool(np, "snps,force_sf_dma_mode");
+	plat->en_tx_lpi_clockgating =
+		fwnode_property_read_bool(np, "snps,en-tx-lpi-clockgating");
+
+	/* Set the maxmtu to a default of JUMBO_LEN in case the
+	 * parameter is not present.
+	 */
+	plat->maxmtu = JUMBO_LEN;
+
+	/* Set default value for multicast hash bins */
+	plat->multicast_filter_bins = HASH_TABLE_SIZE;
+
+	/* Set default value for unicast filter entries */
+	plat->unicast_filter_entries = 1;
+
+	/* Only to "snps,dwmac" */
+	fwnode_property_read_u32(np, "max-frame-size", &plat->maxmtu);
+	fwnode_property_read_u32(np, "snps,multicast-filter-bins",
+				 &plat->multicast_filter_bins);
+	fwnode_property_read_u32(np, "snps,perfect-filter-entries",
+				 &plat->unicast_filter_entries);
+	plat->unicast_filter_entries = dwmac1000_validate_ucast_entries(
+						plat->unicast_filter_entries);
+	plat->multicast_filter_bins = dwmac1000_validate_mcast_bins(
+						plat->multicast_filter_bins);
+	plat->has_gmac = 1;
+	plat->pmt = 1;
+
+	dma_cfg = devm_kzalloc(&pdev->dev, sizeof(*dma_cfg), GFP_KERNEL);
+	if (!dma_cfg)
+		return ERR_PTR(-ENOMEM);
+	plat->dma_cfg = dma_cfg;
+
+	fwnode_property_read_u32(np, "snps,pbl", &dma_cfg->pbl);
+	if (!dma_cfg->pbl)
+		dma_cfg->pbl = DEFAULT_DMA_PBL;
+
+	fwnode_property_read_u32(np, "snps,txpbl", &dma_cfg->txpbl);
+	fwnode_property_read_u32(np, "snps,rxpbl", &dma_cfg->rxpbl);
+	dma_cfg->pblx8 = !fwnode_property_read_bool(np, "snps,no-pbl-x8");
+
+	dma_cfg->aal = fwnode_property_read_bool(np, "snps,aal");
+	dma_cfg->fixed_burst = fwnode_property_read_bool(np, "snps,fixed-burst");
+	dma_cfg->mixed_burst = fwnode_property_read_bool(np, "snps,mixed-burst");
+
+	plat->force_thresh_dma_mode = fwnode_property_read_bool(np, "snps,force_thresh_dma_mode");
+	if (plat->force_thresh_dma_mode)
+		plat->force_sf_dma_mode = 0;
+
+	fwnode_property_read_u32(np, "snps,ps-speed", &plat->mac_port_sel_speed);
+
+	plat->axi = stmmac_axi_setup_acpi(pdev);
+
+	stmmac_mtl_setup_acpi(pdev, plat);
+
+	stmmac_acpi_clock_setup(plat,pdev);
+
+	return plat;
+}
+#else
+struct plat_stmmacenet_data *
+stmmac_probe_config_acpi(struct platform_device *pdev, const char **mac)
+{
+	return ERR_PTR(-EINVAL);
+}
+#endif /* CONFIG_ACPI */
+EXPORT_SYMBOL_GPL(stmmac_probe_config_acpi);
+
 int stmmac_get_platform_resources(struct platform_device *pdev,
 				  struct stmmac_resources *stmmac_res)
 {
@@ -617,33 +862,43 @@ int stmmac_get_platform_resources(struct platform_device *pdev,
 	/* Get IRQ information early to have an ability to ask for deferred
 	 * probe if needed before we went too far with resource allocation.
 	 */
-	stmmac_res->irq = platform_get_irq_byname(pdev, "macirq");
-	if (stmmac_res->irq < 0) {
-		if (stmmac_res->irq != -EPROBE_DEFER) {
-			dev_err(&pdev->dev,
-				"MAC IRQ configuration information not found\n");
+	if (pdev->dev.of_node) {
+		stmmac_res->irq = platform_get_irq_byname(pdev, "macirq");
+		if (stmmac_res->irq < 0) {
+			if (stmmac_res->irq != -EPROBE_DEFER) {
+				dev_err(&pdev->dev,
+					"MAC IRQ configuration information not found\n");
+			}
+			return stmmac_res->irq;
 		}
-		return stmmac_res->irq;
-	}
 
-	/* On some platforms e.g. SPEAr the wake up irq differs from the mac irq
-	 * The external wake up irq can be passed through the platform code
-	 * named as "eth_wake_irq"
-	 *
-	 * In case the wake up interrupt is not passed from the platform
-	 * so the driver will continue to use the mac irq (ndev->irq)
-	 */
-	stmmac_res->wol_irq = platform_get_irq_byname(pdev, "eth_wake_irq");
-	if (stmmac_res->wol_irq < 0) {
-		if (stmmac_res->wol_irq == -EPROBE_DEFER)
+		/* On some platforms e.g. SPEAr the wake up irq differs from the mac irq
+		 * The external wake up irq can be passed through the platform code
+		 * named as "eth_wake_irq"
+		 *
+		 * In case the wake up interrupt is not passed from the platform
+		 * so the driver will continue to use the mac irq (ndev->irq)
+		 */
+		stmmac_res->wol_irq = platform_get_irq_byname(pdev, "eth_wake_irq");
+		if (stmmac_res->wol_irq < 0) {
+			if (stmmac_res->wol_irq == -EPROBE_DEFER)
+				return -EPROBE_DEFER;
+			stmmac_res->wol_irq = stmmac_res->irq;
+		}
+
+		stmmac_res->lpi_irq = platform_get_irq_byname(pdev, "eth_lpi");
+		if (stmmac_res->lpi_irq == -EPROBE_DEFER)
 			return -EPROBE_DEFER;
+	} else if (has_acpi_companion(&pdev->dev)) {
+		stmmac_res->irq = platform_get_irq(pdev, 0);
+		if (stmmac_res->irq < 0)
+			dev_err(&pdev->dev,
+				"MAC IRQ configuration information not found\n");
+
 		stmmac_res->wol_irq = stmmac_res->irq;
+		stmmac_res->lpi_irq = -1;
 	}
 
-	stmmac_res->lpi_irq = platform_get_irq_byname(pdev, "eth_lpi");
-	if (stmmac_res->lpi_irq == -EPROBE_DEFER)
-		return -EPROBE_DEFER;
-
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	stmmac_res->addr = devm_ioremap_resource(&pdev->dev, res);
 
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.h b/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.h
index b72eb0de57b7..8e117ad0e42a 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.h
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.h
@@ -23,6 +23,8 @@
 
 struct plat_stmmacenet_data *
 stmmac_probe_config_dt(struct platform_device *pdev, const char **mac);
+struct plat_stmmacenet_data *
+stmmac_probe_config_acpi(struct platform_device *pdev, const char **mac);
 void stmmac_remove_config_dt(struct platform_device *pdev,
 			     struct plat_stmmacenet_data *plat);
 
diff --git a/drivers/rtc/Kconfig b/drivers/rtc/Kconfig
index 7d7be60a2413..3e4effbf31ef 100644
--- a/drivers/rtc/Kconfig
+++ b/drivers/rtc/Kconfig
@@ -1793,6 +1793,16 @@ config RTC_DRV_RTD119X
 	  If you say yes here, you get support for the RTD1295 SoC
 	  Real Time Clock.
 
+config RTC_DRV_PHYTIUM
+	tristate "Phytium RTC"
+	depends on ARCH_PHYTIUM
+	default y if ARCH_PHYTIUM
+	help
+	  Say yes here to support the Phytium SoC real time clock.
+
+	  This driver can also be built as a module, if so, the module
+	  will be called "rtc-phytium".
+
 comment "HID Sensor RTC drivers"
 
 config RTC_DRV_HID_SENSOR_TIME
diff --git a/drivers/rtc/Makefile b/drivers/rtc/Makefile
index 5ff2fc0c361a..289447233c6b 100644
--- a/drivers/rtc/Makefile
+++ b/drivers/rtc/Makefile
@@ -120,6 +120,7 @@ obj-$(CONFIG_RTC_DRV_PCF85363)	+= rtc-pcf85363.o
 obj-$(CONFIG_RTC_DRV_PCF8523)	+= rtc-pcf8523.o
 obj-$(CONFIG_RTC_DRV_PCF8563)	+= rtc-pcf8563.o
 obj-$(CONFIG_RTC_DRV_PCF8583)	+= rtc-pcf8583.o
+obj-$(CONFIG_RTC_DRV_PHYTIUM)	+= rtc-phytium.o
 obj-$(CONFIG_RTC_DRV_PIC32)	+= rtc-pic32.o
 obj-$(CONFIG_RTC_DRV_PL030)	+= rtc-pl030.o
 obj-$(CONFIG_RTC_DRV_PL031)	+= rtc-pl031.o
diff --git a/drivers/rtc/rtc-phytium.c b/drivers/rtc/rtc-phytium.c
new file mode 100644
index 000000000000..97a560dfa3af
--- /dev/null
+++ b/drivers/rtc/rtc-phytium.c
@@ -0,0 +1,331 @@
+/*
+ * Phytium Real Time Clock Driver
+ *
+ * Copyright (c) 2019, Phytium Technology Co., Ltd.
+ *
+ * Chen Baozi <chenbaozi@phytium.com.cn>
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/platform_device.h>
+#include <linux/io.h>
+#include <linux/slab.h>
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/rtc.h>
+#include <linux/acpi.h>
+
+#define RTC_CMR                 0x04
+#define RTC_AES_SEL             0x08
+#define RTC_AES_SEL_COUNTER     0x100
+#define RTC_CCR                 0x0C
+#define RTC_CCR_IE              BIT(0)
+#define RTC_CCR_MASK            BIT(1)
+#define RTC_CCR_EN              BIT(2)
+#define RTC_CCR_WEN             BIT(3)
+#define RTC_STAT                0x10
+#define RTC_STAT_BIT            BIT(0)
+#define RTC_RSTAT               0x14
+#define RTC_EOI                 0x18
+#define RTC_VER                 0x1C
+#define RTC_CDR_LOW             0x20
+#define RTC_CCVR                0x24
+#define RTC_CLR_LOW             0x28
+#define RTC_CLR                 0x2c
+#define RTC_COUNTER_HB_OFFSET   15
+#define RTC_COUNTER_LB_MASK     0x7fff
+
+spinlock_t spinlock_phytium_rtc;
+
+struct phytium_rtc_dev {
+	struct rtc_device *rtc;
+	struct device *dev;
+	unsigned long alarm_time;
+	void __iomem *csr_base;
+	struct clk *clk;
+	unsigned int irq_wake;
+	unsigned int irq_enabled;
+};
+
+static int phytium_rtc_read_time(struct device *dev, struct rtc_time *tm)
+{
+	struct phytium_rtc_dev *pdata = dev_get_drvdata(dev);
+
+	unsigned long counter = 0;
+	unsigned long tmp = 0;
+
+	spin_lock(&spinlock_phytium_rtc);
+	writel(RTC_AES_SEL_COUNTER, pdata->csr_base + RTC_AES_SEL);
+	counter = readl(pdata->csr_base + RTC_CCVR);
+	tmp = readl(pdata->csr_base + RTC_CDR_LOW);
+	printk("%s_%d:counter:0x%lx\n", __func__, __LINE__, counter);
+	spin_unlock(&spinlock_phytium_rtc);
+
+	rtc_time_to_tm(counter, tm);
+	return rtc_valid_tm(tm);
+}
+
+static int phytium_rtc_set_mmss(struct device *dev, unsigned long secs)
+{
+	struct phytium_rtc_dev *pdata = dev_get_drvdata(dev);
+	unsigned long counter = 0;
+	unsigned long tmp = 0;
+
+	spin_lock(&spinlock_phytium_rtc);
+
+	writel(RTC_AES_SEL_COUNTER, pdata->csr_base + RTC_AES_SEL);
+	writel(0x00000000, pdata->csr_base + RTC_CLR_LOW);
+	writel((u32)secs, pdata->csr_base + RTC_CLR);
+	writel(RTC_AES_SEL_COUNTER, pdata->csr_base + RTC_AES_SEL);
+	counter = readl(pdata->csr_base + RTC_CLR);
+	tmp = readl(pdata->csr_base + RTC_CLR_LOW);
+
+	spin_unlock(&spinlock_phytium_rtc);
+
+	return 0;
+}
+
+static int phytium_rtc_read_alarm(struct device *dev, struct rtc_wkalrm *alrm)
+{
+	struct phytium_rtc_dev *pdata = dev_get_drvdata(dev);
+
+	rtc_time_to_tm(pdata->alarm_time, &alrm->time);
+	alrm->enabled = readl(pdata->csr_base + RTC_CCR) & RTC_CCR_IE;
+
+	return 0;
+}
+
+static int phytium_rtc_alarm_irq_enable(struct device *dev, u32 enabled)
+{
+	struct phytium_rtc_dev *pdata = dev_get_drvdata(dev);
+	u32 ccr;
+
+	ccr = readl(pdata->csr_base + RTC_CCR);
+	if (enabled) {
+		ccr &= ~RTC_CCR_MASK;
+		ccr |= RTC_CCR_IE;
+	} else {
+		ccr &= ~RTC_CCR_IE;
+		ccr |= RTC_CCR_MASK;
+	}
+	writel(ccr, pdata->csr_base + RTC_CCR);
+
+	return 0;
+}
+
+static int phytium_rtc_alarm_irq_enabled(struct device *dev)
+{
+	struct phytium_rtc_dev *pdata = dev_get_drvdata(dev);
+
+	return readl(pdata->csr_base + RTC_CCR) & RTC_CCR_IE ? 1: 0;
+}
+
+static int phytium_rtc_set_alarm(struct device *dev, struct rtc_wkalrm *alrm)
+{
+	struct phytium_rtc_dev *pdata = dev_get_drvdata(dev);
+	unsigned long rtc_time;
+	unsigned long alarm_time;
+
+	rtc_time = readl(pdata->csr_base + RTC_CCVR);
+	rtc_tm_to_time(&alrm->time, &alarm_time);
+
+	pdata->alarm_time = alarm_time;
+	writel((u32) pdata->alarm_time, pdata->csr_base + RTC_CMR);
+
+	phytium_rtc_alarm_irq_enable(dev, alrm->enabled);
+
+	return 0;
+}
+
+static const struct rtc_class_ops phytium_rtc_ops = {
+	.read_time	= phytium_rtc_read_time,
+	.set_mmss	= phytium_rtc_set_mmss,
+	.read_alarm	= phytium_rtc_read_alarm,
+	.set_alarm	= phytium_rtc_set_alarm,
+	.alarm_irq_enable = phytium_rtc_alarm_irq_enable,
+};
+
+static irqreturn_t phytium_rtc_interrupt(int irq, void *id)
+{
+	struct phytium_rtc_dev *pdata = (struct phytium_rtc_dev *) id;
+
+	/* Check if interrupt asserted */
+	if (!(readl(pdata->csr_base + RTC_STAT) & RTC_STAT_BIT))
+		return IRQ_NONE;
+
+	/* Clear interrupt */
+	readl(pdata->csr_base + RTC_EOI);
+
+	rtc_update_irq(pdata->rtc, 1, RTC_IRQF | RTC_AF);
+
+	return IRQ_HANDLED;
+}
+
+static int phytium_rtc_probe(struct platform_device *pdev)
+{
+	struct phytium_rtc_dev *pdata;
+	struct resource *res;
+	int ret;
+	int irq;
+
+	pdata = devm_kzalloc(&pdev->dev, sizeof(*pdata), GFP_KERNEL);
+	if (!pdata)
+		return -ENOMEM;
+	platform_set_drvdata(pdev, pdata);
+	pdata->dev = &pdev->dev;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	pdata->csr_base = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(pdata->csr_base))
+		return PTR_ERR(pdata->csr_base);
+
+	irq = platform_get_irq(pdev, 0);
+	if (irq < 0) {
+		dev_err(&pdev->dev, "No IRQ resource\n");
+		return irq;
+	}
+	ret = devm_request_irq(&pdev->dev, irq, phytium_rtc_interrupt, 0,
+			       dev_name(&pdev->dev), pdata);
+	if (ret) {
+		dev_err(&pdev->dev, "Could not request IRQ\n");
+		return ret;
+	}
+
+#ifndef CONFIG_ACPI
+	pdata->clk = devm_clk_get(&pdev->dev, NULL);
+	if (IS_ERR(pdata->clk)) {
+		dev_err(&pdev->dev, "Couldn't get the clock for RTC\n");
+		return -ENODEV;
+	}
+
+	ret = clk_prepare_enable(pdata->clk);
+	if (ret)
+		return ret;
+#endif
+
+	spin_lock_init(&spinlock_phytium_rtc);
+
+	/* Turn on the clock and the crystal */
+	writel(RTC_CCR_EN, pdata->csr_base + RTC_CCR);
+
+	ret = device_init_wakeup(&pdev->dev, 1);
+	if (ret) {
+		clk_disable_unprepare(pdata->clk);
+		return ret;
+	}
+
+	pdata->rtc = devm_rtc_device_register(&pdev->dev, pdev->name,
+					 &phytium_rtc_ops, THIS_MODULE);
+	if (IS_ERR(pdata->rtc)) {
+		clk_disable_unprepare(pdata->clk);
+		return PTR_ERR(pdata->rtc);
+	}
+
+	/* HW does not support update faster than 1 seconds */
+	pdata->rtc->uie_unsupported = 1;
+
+	return 0;
+}
+
+static int phytium_rtc_remove(struct platform_device *pdev)
+{
+	struct phytium_rtc_dev *pdata = platform_get_drvdata(pdev);
+
+	phytium_rtc_alarm_irq_enable(&pdev->dev, 0);
+	device_init_wakeup(&pdev->dev, 0);
+	clk_disable_unprepare(pdata->clk);
+	return 0;
+}
+
+#ifdef CONFIG_PM_SLEEP
+static int phytium_rtc_suspend(struct device *dev)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct phytium_rtc_dev *pdata = platform_get_drvdata(pdev);
+	int irq;
+
+	/*
+	 * If this RTC alarm will be used for waking the system up,
+	 * don't disable it of course. Else we just disable the alarm
+	 * and await suspension.
+         */
+	irq = platform_get_irq(pdev, 0);
+	if (device_may_wakeup(&pdev->dev)) {
+		if (!enable_irq_wake(irq))
+			pdata->irq_wake = 1;
+	} else {
+		pdata->irq_enabled = phytium_rtc_alarm_irq_enabled(dev);
+		phytium_rtc_alarm_irq_enable(dev, 0);
+		clk_disable_unprepare(pdata->clk);
+	}
+
+	return 0;
+}
+
+static int phytium_rtc_resume(struct device *dev)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct phytium_rtc_dev *pdata = platform_get_drvdata(pdev);
+	int irq;
+	int rc;
+
+	irq = platform_get_irq(pdev, 0);
+	if (device_may_wakeup(&pdev->dev)) {
+		if (pdata->irq_wake) {
+			disable_irq_wake(irq);
+			pdata->irq_wake = 0;
+		}
+	} else {
+		rc = clk_prepare_enable(pdata->clk);
+		if (rc) {
+			dev_err(dev, "Unable to enable clock error %d\n", rc);
+			return rc;
+		}
+		phytium_rtc_alarm_irq_enable(dev, pdata->irq_enabled);
+	}
+
+	return 0;
+}
+#endif
+
+static SIMPLE_DEV_PM_OPS(phytium_rtc_pm_ops, phytium_rtc_suspend, phytium_rtc_resume);
+
+#ifdef CONFIG_OF
+static const struct of_device_id phytium_rtc_of_match[] = {
+	{ .compatible = "phytium,rtc" },
+	{ }
+};
+MODULE_DEVICE_TABLE(of, phytium_rtc_of_match);
+#endif
+
+#ifdef CONFIG_ACPI
+static const struct acpi_device_id phytium_rtc_acpi_match[] = {
+	{ "PHYT0002", 0 },
+	{ }
+};
+#endif
+
+static struct platform_driver phytium_rtc_driver = {
+	.probe		= phytium_rtc_probe,
+	.remove		= phytium_rtc_remove,
+	.driver		= {
+		.name	= "phytium-rtc",
+		.pm = &phytium_rtc_pm_ops,
+		.of_match_table	= of_match_ptr(phytium_rtc_of_match),
+		.acpi_match_table = ACPI_PTR(phytium_rtc_acpi_match),
+	},
+};
+
+module_platform_driver(phytium_rtc_driver);
+
+MODULE_DESCRIPTION("Phytium RTC driver");
+MODULE_AUTHOR("Chen Baozi <chenbaozi@phytium.com.cn>");
+MODULE_LICENSE("GPL");
diff --git a/drivers/spi/Kconfig b/drivers/spi/Kconfig
index 671d078349cc..3cdcfa96d11e 100644
--- a/drivers/spi/Kconfig
+++ b/drivers/spi/Kconfig
@@ -454,6 +454,15 @@ config SPI_ORION
 	  This enables using the SPI master controller on the Orion
 	  and MVEBU chips.
 
+config SPI_PHYTIUM
+	tristate "Phytium SPI controller core support"
+	depends on ARM64
+	help
+	  This selects a driver for Phytium SPI controller.
+
+	  If you say yes to this option, support will be included for
+	  FT-2000/4 SoC SPI controller.
+
 config SPI_PIC32
 	tristate "Microchip PIC32 series SPI"
 	depends on MACH_PIC32 || COMPILE_TEST
diff --git a/drivers/spi/Makefile b/drivers/spi/Makefile
index a90d55970036..49ae6a09adfd 100644
--- a/drivers/spi/Makefile
+++ b/drivers/spi/Makefile
@@ -35,6 +35,7 @@ obj-$(CONFIG_SPI_DESIGNWARE)		+= spi-dw.o
 obj-$(CONFIG_SPI_DW_MMIO)		+= spi-dw-mmio.o
 obj-$(CONFIG_SPI_DW_PCI)		+= spi-dw-midpci.o
 spi-dw-midpci-objs			:= spi-dw-pci.o spi-dw-mid.o
+obj-$(CONFIG_SPI_PHYTIUM)		+= spi-phytium.o
 obj-$(CONFIG_SPI_EFM32)			+= spi-efm32.o
 obj-$(CONFIG_SPI_EP93XX)		+= spi-ep93xx.o
 obj-$(CONFIG_SPI_FALCON)		+= spi-falcon.o
diff --git a/drivers/spi/spi-phytium.c b/drivers/spi/spi-phytium.c
new file mode 100644
index 000000000000..826fe8039313
--- /dev/null
+++ b/drivers/spi/spi-phytium.c
@@ -0,0 +1,648 @@
+/*
+ * Phytium SPI core controller driver.
+ *
+ * Copyright (c) 2019, Phytium Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ */
+
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+#include <linux/gpio.h>
+#include <linux/highmem.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/spi/spi.h>
+#include <linux/scatterlist.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_gpio.h>
+#include <linux/of_platform.h>
+#include <linux/property.h>
+#include <linux/acpi.h>
+
+#define CTRL0			0x00
+#define SSIENR			0x08
+#define SER			0x10
+#define BAUDR			0x14
+#define TXFLTR			0x18
+#define TXFLR			0x20
+#define RXFLR			0x24
+#define IMR			0x2c
+#define ISR			0x30
+#define ICR			0x48
+#define DR			0x60
+
+#define FRF_OFFSET		4
+#define MODE_OFFSET		6
+#define TMOD_OFFSET		8
+
+#define TMOD_MASK		(0x3 << TMOD_OFFSET)
+#define	TMOD_TR			0x0
+#define TMOD_TO			0x1
+#define TMOD_RO			0x2
+
+#define INT_TXEI		(1 << 0)
+#define INT_TXOI		(1 << 1)
+#define INT_RXUI		(1 << 2)
+#define INT_RXOI		(1 << 3)
+
+struct ft_spi {
+	struct spi_master	*master;
+	char			name[16];
+
+	void __iomem		*regs;
+	unsigned long		paddr;
+	int			irq;
+	u32			fifo_len;
+	u32			max_freq;
+
+	u32			reg_io_width;
+	u16			bus_num;
+	u16			num_cs;
+
+	size_t			len;
+	void			*tx;
+	void			*tx_end;
+	void			*rx;
+	void			*rx_end;
+	u8			n_bytes;
+	irqreturn_t		(*transfer_handler)(struct ft_spi *fts);
+};
+
+static inline u32 ft_readl(struct ft_spi *fts, u32 offset)
+{
+	return __raw_readl(fts->regs + offset);
+}
+
+static inline u16 ft_readw(struct ft_spi *fts, u32 offset)
+{
+	return __raw_readw(fts->regs + offset);
+}
+
+static inline void ft_writel(struct ft_spi *fts, u32 offset, u32 val)
+{
+	__raw_writel(val, fts->regs + offset);
+}
+
+static inline void ft_writew(struct ft_spi *fts, u32 offset, u16 val)
+{
+	__raw_writew(val, fts->regs + offset);
+}
+
+static inline u32 ft_read_io_reg(struct ft_spi *fts, u32 offset)
+{
+	switch (fts->reg_io_width) {
+	case 2:
+		return ft_readw(fts, offset);
+	case 4:
+	default:
+		return ft_readl(fts, offset);
+	}
+}
+
+static inline void ft_write_io_reg(struct ft_spi *fts, u32 offset, u32 val)
+{
+	switch (fts->reg_io_width) {
+	case 2:
+		ft_writew(fts, offset, val);
+		break;
+	case 4:
+	default:
+		ft_writel(fts, offset, val);
+		break;
+	}
+}
+
+static inline void spi_enable_chip(struct ft_spi *fts, int enable)
+{
+	ft_writel(fts, SSIENR, (enable ? 1 : 0));
+}
+
+static inline void spi_set_clk(struct ft_spi *fts, u16 div)
+{
+	ft_writel(fts, BAUDR, div);
+}
+
+static inline void spi_mask_intr(struct ft_spi *fts, u32 mask)
+{
+	u32 new_mask;
+
+	new_mask = ft_readl(fts, IMR) & ~mask;
+	ft_writel(fts, IMR, new_mask);
+}
+
+static inline void spi_umask_intr(struct ft_spi *fts, u32 mask)
+{
+	u32 new_mask;
+
+	new_mask = ft_readl(fts, IMR) | mask;
+	ft_writel(fts, IMR, new_mask);
+}
+
+static inline void spi_reset_chip(struct ft_spi *fts)
+{
+	spi_enable_chip(fts, 0);
+	spi_mask_intr(fts, 0xff);
+	spi_enable_chip(fts, 1);
+}
+
+static inline void spi_shutdown_chip(struct ft_spi *fts)
+{
+	spi_enable_chip(fts, 0);
+	spi_set_clk(fts, 0);
+}
+
+struct ft_spi_chip {
+	u8 poll_mode;
+	u8 type;
+	void (*cs_control)(u32 command);
+};
+
+struct chip_data {
+	u8 cs;
+	u8 tmode;
+	u8 type;
+
+	u8 poll_mode;
+
+	u16 clk_div;
+	u32 speed_hz;
+	void (*cs_control)(u32 command);
+};
+
+static void ft_spi_set_cs(struct spi_device *spi, bool enable)
+{
+	struct ft_spi *fts = spi_master_get_devdata(spi->master);
+	struct chip_data *chip = spi_get_ctldata(spi);
+
+	if (chip && chip->cs_control)
+		chip->cs_control(!enable);
+
+	if (!enable)
+		ft_writel(fts, SER, BIT(spi->chip_select));
+}
+
+static inline u32 tx_max(struct ft_spi *fts)
+{
+	u32 tx_left, tx_room, rxtx_gap;
+
+	tx_left = (fts->tx_end - fts->tx) / fts->n_bytes;
+	tx_room = fts->fifo_len - ft_readl(fts, TXFLR);
+
+	rxtx_gap =  ((fts->rx_end - fts->rx) - (fts->tx_end - fts->tx))
+			/ fts->n_bytes;
+
+	return min3(tx_left, tx_room, (u32) (fts->fifo_len - rxtx_gap));
+}
+
+static inline u32 rx_max(struct ft_spi *fts)
+{
+	u32 rx_left = (fts->rx_end - fts->rx) / fts->n_bytes;
+
+	return min_t(u32, rx_left, ft_readl(fts, RXFLR));
+}
+
+static void ft_writer(struct ft_spi *fts)
+{
+	u32 max = tx_max(fts);
+	u16 txw = 0;
+
+	while (max--) {
+		if (fts->tx_end - fts->len) {
+			if (fts->n_bytes == 1)
+				txw = *(u8 *)(fts->tx);
+			else
+				txw = *(u16 *)(fts->tx);
+		}
+		ft_write_io_reg(fts, DR, txw);
+		fts->tx += fts->n_bytes;
+	}
+}
+
+static void ft_reader(struct ft_spi *fts)
+{
+	u32 max = rx_max(fts);
+	u16 rxw;
+
+	while (max--) {
+		rxw = ft_read_io_reg(fts, DR);
+		if (fts->rx_end - fts->len) {
+			if (fts->n_bytes == 1)
+				*(u8 *)(fts->rx) = rxw;
+			else
+				*(u16 *)(fts->rx) = rxw;
+		}
+		fts->rx += fts->n_bytes;
+	}
+}
+
+static void int_error_stop(struct ft_spi *fts, const char *msg)
+{
+	spi_reset_chip(fts);
+
+	dev_err(&fts->master->dev, "%s\n", msg);
+	fts->master->cur_msg->status = -EIO;
+	spi_finalize_current_transfer(fts->master);
+}
+
+static irqreturn_t interrupt_transfer(struct ft_spi *fts)
+{
+	u16 irq_status = ft_readl(fts, ISR);
+
+	if (irq_status & (INT_TXOI | INT_RXOI | INT_RXUI)) {
+		ft_readl(fts, ICR);
+		int_error_stop(fts, "interrupt_transfer: fifo overrun/underrun");
+		return IRQ_HANDLED;
+	}
+
+	ft_reader(fts);
+	if (fts->rx_end == fts->rx) {
+		spi_mask_intr(fts, INT_TXEI);
+		spi_finalize_current_transfer(fts->master);
+		return IRQ_HANDLED;
+	}
+	if (irq_status & INT_TXEI) {
+		spi_mask_intr(fts, INT_TXEI);
+		ft_writer(fts);
+		spi_umask_intr(fts, INT_TXEI);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t ft_spi_irq(int irq, void *dev_id)
+{
+	struct spi_master *master = dev_id;
+	struct ft_spi *fts = spi_master_get_devdata(master);
+	u16 irq_status = ft_readl(fts, ISR) & 0x3f;
+
+	if (!irq_status)
+		return IRQ_NONE;
+
+	if (!master->cur_msg) {
+		spi_mask_intr(fts, INT_TXEI);
+		return IRQ_HANDLED;
+	}
+
+	return fts->transfer_handler(fts);
+}
+
+static int poll_transfer(struct ft_spi *fts)
+{
+	do {
+		ft_writer(fts);
+		ft_reader(fts);
+		cpu_relax();
+	} while (fts->rx_end > fts->rx);
+
+	return 0;
+}
+
+static int ft_spi_transfer_one(struct spi_master *master,
+		struct spi_device *spi, struct spi_transfer *transfer)
+{
+	struct ft_spi *fts = spi_master_get_devdata(master);
+	struct chip_data *chip = spi_get_ctldata(spi);
+	u8 imask = 0;
+	u16 txlevel = 0;
+	u16 clk_div;
+	u32 cr0;
+
+	fts->tx = (void *)transfer->tx_buf;
+	fts->tx_end = fts->tx + transfer->len;
+	fts->rx = transfer->rx_buf;
+	fts->rx_end = fts->rx + transfer->len;
+	fts->len = transfer->len;
+
+	spi_enable_chip(fts, 0);
+
+	if (transfer->speed_hz != chip->speed_hz) {
+		clk_div = (fts->max_freq / transfer->speed_hz + 1) & 0xfffe;
+
+		chip->speed_hz = transfer->speed_hz;
+		chip->clk_div = clk_div;
+
+		spi_set_clk(fts, chip->clk_div);
+	}
+
+	if (transfer->bits_per_word == 8) {
+		fts->n_bytes = 1;
+	} else if (transfer->bits_per_word == 16) {
+		fts->n_bytes = 2;
+	} else {
+		return -EINVAL;
+	}
+
+	cr0 = (transfer->bits_per_word - 1)
+		| (chip->type << FRF_OFFSET)
+		| (spi->mode << MODE_OFFSET)
+		| (chip->tmode << TMOD_OFFSET);
+
+	if (chip->cs_control) {
+		if (fts->rx && fts->tx)
+			chip->tmode = TMOD_TR;
+		else if (fts->rx)
+			chip->tmode = TMOD_RO;
+		else
+			chip->tmode = TMOD_TO;
+
+		cr0 &= ~TMOD_MASK;
+		cr0 |= (chip->tmode << TMOD_OFFSET);
+	}
+
+	ft_writel(fts, CTRL0, cr0);
+
+	spi_mask_intr(fts, 0xff);
+
+	if (!chip->poll_mode) {
+		txlevel = min_t(u16, fts->fifo_len / 2, fts->len / fts->n_bytes);
+		ft_writel(fts, TXFLTR, txlevel);
+
+		imask |= INT_TXEI | INT_TXOI |
+			 INT_RXUI | INT_RXOI;
+		spi_umask_intr(fts, imask);
+
+		fts->transfer_handler = interrupt_transfer;
+	}
+
+	spi_enable_chip(fts, 1);
+
+	if (chip->poll_mode)
+		return poll_transfer(fts);
+
+	return 1;
+}
+
+static void ft_spi_handle_err(struct spi_master *master,
+		struct spi_message *msg)
+{
+	struct ft_spi *fts = spi_master_get_devdata(master);
+
+	spi_reset_chip(fts);
+}
+
+static int ft_spi_setup(struct spi_device *spi)
+{
+	struct ft_spi_chip *chip_info = NULL;
+	struct chip_data *chip;
+	int ret;
+
+	chip = spi_get_ctldata(spi);
+	if (!chip) {
+		chip = kzalloc(sizeof(struct chip_data), GFP_KERNEL);
+		if (!chip)
+			return -ENOMEM;
+		spi_set_ctldata(spi, chip);
+	}
+
+	chip_info = spi->controller_data;
+
+	if (chip_info) {
+		if (chip_info->cs_control)
+			chip->cs_control = chip_info->cs_control;
+
+		chip->poll_mode = chip_info->poll_mode;
+		chip->type = chip_info->type;
+	}
+
+	chip->tmode = 0;
+
+	if (gpio_is_valid(spi->cs_gpio)) {
+		ret = gpio_direction_output(spi->cs_gpio,
+				!(spi->mode & SPI_CS_HIGH));
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+static void ft_spi_cleanup(struct spi_device *spi)
+{
+	struct chip_data *chip = spi_get_ctldata(spi);
+
+	kfree(chip);
+	spi_set_ctldata(spi, NULL);
+}
+
+static void spi_hw_init(struct device *dev, struct ft_spi *fts)
+{
+	spi_reset_chip(fts);
+
+	if (!fts->fifo_len) {
+		u32 fifo;
+
+		for (fifo = 1; fifo < 256; fifo++) {
+			ft_writel(fts, TXFLTR, fifo);
+			if (fifo != ft_readl(fts, TXFLTR))
+				break;
+		}
+		ft_writel(fts, TXFLTR, 0);
+
+		fts->fifo_len = (fifo == 1) ? 0 : fifo;
+		dev_dbg(dev, "Detected FIFO size: %u bytes\n", fts->fifo_len);
+	}
+}
+
+int ft_spi_add_host(struct device *dev, struct ft_spi *fts)
+{
+	struct spi_master *master;
+	int ret;
+
+	BUG_ON(fts == NULL);
+
+	master = spi_alloc_master(dev, 0);
+	if (!master)
+		return -ENOMEM;
+
+	fts->master = master;
+	snprintf(fts->name, sizeof(fts->name), "ft_spi%d", fts->bus_num);
+
+	ret = request_irq(fts->irq, ft_spi_irq, IRQF_SHARED, fts->name, master);
+	if (ret < 0) {
+		dev_err(dev, "can not get IRQ\n");
+		goto err_free_master;
+	}
+
+	master->mode_bits = SPI_CPOL | SPI_CPHA | SPI_LOOP;
+	master->bits_per_word_mask = SPI_BPW_MASK(8) | SPI_BPW_MASK(16);
+	master->bus_num = fts->bus_num;
+	master->num_chipselect = fts->num_cs;
+	master->setup = ft_spi_setup;
+	master->cleanup = ft_spi_cleanup;
+	master->set_cs = ft_spi_set_cs;
+	master->transfer_one = ft_spi_transfer_one;
+	master->handle_err = ft_spi_handle_err;
+	master->max_speed_hz = fts->max_freq;
+	master->dev.of_node = dev->of_node;
+
+	spi_hw_init(dev, fts);
+
+	spi_master_set_devdata(master, fts);
+	ret = devm_spi_register_master(dev, master);
+	if (ret) {
+		dev_err(&master->dev, "problem registering spi master\n");
+		goto err_exit;
+	}
+
+	return 0;
+
+err_exit:
+	spi_enable_chip(fts, 0);
+	free_irq(fts->irq, master);
+err_free_master:
+	spi_master_put(master);
+	return ret;
+}
+
+void ft_spi_remove_host(struct ft_spi *fts)
+{
+	spi_shutdown_chip(fts);
+
+	free_irq(fts->irq, fts->master);
+}
+
+#define DRIVER_NAME "phytium_spi"
+
+struct ft_spi_clk {
+	struct ft_spi  fts;
+	struct clk     *clk;
+};
+
+static int ft_spi_probe(struct platform_device *pdev)
+{
+	struct ft_spi_clk *ftsc;
+	struct ft_spi *fts;
+	struct resource *mem;
+	int ret;
+	int num_cs;
+
+	ftsc = devm_kzalloc(&pdev->dev, sizeof(struct ft_spi_clk),
+			GFP_KERNEL);
+	if (!ftsc)
+		return -ENOMEM;
+
+	fts = &ftsc->fts;
+
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!mem) {
+		dev_err(&pdev->dev, "no mem resource?\n");
+		return -EINVAL;
+	}
+
+	fts->regs = devm_ioremap_resource(&pdev->dev, mem);
+	if (IS_ERR(fts->regs)) {
+		dev_err(&pdev->dev, "SPI region map failed\n");
+		return PTR_ERR(fts->regs);
+	}
+
+	fts->irq = platform_get_irq(pdev, 0);
+	if (fts->irq < 0) {
+		dev_err(&pdev->dev, "no irq resource?\n");
+		return fts->irq; /* -ENXIO */
+	}
+
+	if (pdev->dev.of_node) {
+		ftsc->clk = devm_clk_get(&pdev->dev, NULL);
+
+		if (IS_ERR(ftsc->clk))
+			return PTR_ERR(ftsc->clk);
+		ret = clk_prepare_enable(ftsc->clk);
+		if (ret)
+			return ret;
+
+		fts->max_freq = clk_get_rate(ftsc->clk);
+	} else if (has_acpi_companion(&pdev->dev)) {
+		fts->max_freq = 48000000;
+	}
+
+	fts->bus_num = pdev->id;
+	device_property_read_u32(&pdev->dev, "reg-io-width", &fts->reg_io_width);
+
+	num_cs = 4;
+
+	device_property_read_u32(&pdev->dev, "num-cs", &num_cs);
+
+	fts->num_cs = num_cs;
+
+	if (pdev->dev.of_node) {
+		int i;
+
+		for (i = 0; i < fts->num_cs; i++) {
+			int cs_gpio = of_get_named_gpio(pdev->dev.of_node,
+					"cs-gpios", i);
+
+			if (cs_gpio == -EPROBE_DEFER) {
+				ret = cs_gpio;
+				goto out;
+			}
+
+			if (gpio_is_valid(cs_gpio)) {
+				ret = devm_gpio_request(&pdev->dev, cs_gpio,
+						dev_name(&pdev->dev));
+				if (ret)
+					goto out;
+			}
+		}
+	}
+
+	ret = ft_spi_add_host(&pdev->dev, fts);
+	if (ret)
+		goto out;
+
+	platform_set_drvdata(pdev, ftsc);
+	return 0;
+
+out:
+	clk_disable_unprepare(ftsc->clk);
+	return ret;
+}
+
+static int ft_spi_remove(struct platform_device *pdev)
+{
+	struct ft_spi_clk *ftsc = platform_get_drvdata(pdev);
+
+	ft_spi_remove_host(&ftsc->fts);
+	clk_disable_unprepare(ftsc->clk);
+
+	return 0;
+}
+
+static const struct of_device_id ft_spi_of_match[] = {
+	{ .compatible = "phytium,spi", },
+	{ /* end of table */}
+};
+MODULE_DEVICE_TABLE(of, ft_spi_of_match);
+
+static const struct acpi_device_id ft_spi_acpi_match[] = {
+	{"PHTY000E", 0},
+	{}
+};
+MODULE_DEVICE_TABLE(acpi, ft_spi_acpi_match);
+
+static struct platform_driver ft_spi_driver = {
+	.probe		= ft_spi_probe,
+	.remove		= ft_spi_remove,
+	.driver		= {
+		.name	= DRIVER_NAME,
+		.of_match_table = of_match_ptr(ft_spi_of_match),
+		.acpi_match_table = ACPI_PTR(ft_spi_acpi_match),
+	},
+};
+module_platform_driver(ft_spi_driver);
+
+MODULE_AUTHOR("Mingshuai Zhu <zhumingshuai@phytium.com.cn>");
+MODULE_AUTHOR("Chen Baozi <chenbaozi@phytium.com.cn>");
+MODULE_DESCRIPTION("Driver for Phytium SPI controller core");
+MODULE_LICENSE("GPL v2");
diff --git a/include/acpi/actbl2.h b/include/acpi/actbl2.h
index c50ef7e6b942..e764040a2e51 100644
--- a/include/acpi/actbl2.h
+++ b/include/acpi/actbl2.h
@@ -502,7 +502,8 @@ enum acpi_madt_type {
 	ACPI_MADT_TYPE_GENERIC_MSI_FRAME = 13,
 	ACPI_MADT_TYPE_GENERIC_REDISTRIBUTOR = 14,
 	ACPI_MADT_TYPE_GENERIC_TRANSLATOR = 15,
-	ACPI_MADT_TYPE_RESERVED = 16	/* 16 and greater are reserved */
+	ACPI_MADT_TYPE_RESERVED = 16,
+	ACPI_MADT_TYPE_PHYTIUM_2500 = 128
 };
 
 /*
diff --git a/include/linux/irqchip/arm-gic-phytium-2500.h b/include/linux/irqchip/arm-gic-phytium-2500.h
new file mode 100644
index 000000000000..00f217887203
--- /dev/null
+++ b/include/linux/irqchip/arm-gic-phytium-2500.h
@@ -0,0 +1,619 @@
+/*
+ * Copyright (C) 2020 Phytium Corporation.
+ * Author: Wang Yinfeng <wangyinfeng@phytium.com.cn>
+ *         Chen Baozi <chenbaozi@phytium.com.cn>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+#ifndef __LINUX_IRQCHIP_ARM_GIC_PHYTIUM_2500_H
+#define __LINUX_IRQCHIP_ARM_GIC_PHYTIUM_2500_H
+
+/*
+ * Distributor registers. We assume we're running non-secure, with ARE
+ * being set. Secure-only and non-ARE registers are not described.
+ */
+#define GICD_CTLR			0x0000
+#define GICD_TYPER			0x0004
+#define GICD_IIDR			0x0008
+#define GICD_STATUSR			0x0010
+#define GICD_SETSPI_NSR			0x0040
+#define GICD_CLRSPI_NSR			0x0048
+#define GICD_SETSPI_SR			0x0050
+#define GICD_CLRSPI_SR			0x0058
+#define GICD_SEIR			0x0068
+#define GICD_IGROUPR			0x0080
+#define GICD_ISENABLER			0x0100
+#define GICD_ICENABLER			0x0180
+#define GICD_ISPENDR			0x0200
+#define GICD_ICPENDR			0x0280
+#define GICD_ISACTIVER			0x0300
+#define GICD_ICACTIVER			0x0380
+#define GICD_IPRIORITYR			0x0400
+#define GICD_ICFGR			0x0C00
+#define GICD_IGRPMODR			0x0D00
+#define GICD_NSACR			0x0E00
+#define GICD_IROUTER			0x6000
+#define GICD_IDREGS			0xFFD0
+#define GICD_PIDR2			0xFFE8
+
+/*
+ * Those registers are actually from GICv2, but the spec demands that they
+ * are implemented as RES0 if ARE is 1 (which we do in KVM's emulated GICv3).
+ */
+#define GICD_ITARGETSR			0x0800
+#define GICD_SGIR			0x0F00
+#define GICD_CPENDSGIR			0x0F10
+#define GICD_SPENDSGIR			0x0F20
+
+#define GICD_CTLR_RWP			(1U << 31)
+#define GICD_CTLR_DS			(1U << 6)
+#define GICD_CTLR_ARE_NS		(1U << 4)
+#define GICD_CTLR_ENABLE_G1A		(1U << 1)
+#define GICD_CTLR_ENABLE_G1		(1U << 0)
+
+#define GICD_IIDR_IMPLEMENTER_SHIFT	0
+#define GICD_IIDR_IMPLEMENTER_MASK	(0xfff << GICD_IIDR_IMPLEMENTER_SHIFT)
+#define GICD_IIDR_REVISION_SHIFT	12
+#define GICD_IIDR_REVISION_MASK		(0xf << GICD_IIDR_REVISION_SHIFT)
+#define GICD_IIDR_VARIANT_SHIFT		16
+#define GICD_IIDR_VARIANT_MASK		(0xf << GICD_IIDR_VARIANT_SHIFT)
+#define GICD_IIDR_PRODUCT_ID_SHIFT	24
+#define GICD_IIDR_PRODUCT_ID_MASK	(0xff << GICD_IIDR_PRODUCT_ID_SHIFT)
+
+
+/*
+ * In systems with a single security state (what we emulate in KVM)
+ * the meaning of the interrupt group enable bits is slightly different
+ */
+#define GICD_CTLR_ENABLE_SS_G1		(1U << 1)
+#define GICD_CTLR_ENABLE_SS_G0		(1U << 0)
+
+#define GICD_TYPER_RSS			(1U << 26)
+#define GICD_TYPER_LPIS			(1U << 17)
+#define GICD_TYPER_MBIS			(1U << 16)
+
+#define GICD_TYPER_ID_BITS(typer)	((((typer) >> 19) & 0x1f) + 1)
+#define GICD_TYPER_NUM_LPIS(typer)	((((typer) >> 11) & 0x1f) + 1)
+#define GICD_TYPER_IRQS(typer)		((((typer) & 0x1f) + 1) * 32)
+
+#define GICD_IROUTER_SPI_MODE_ONE	(0U << 31)
+#define GICD_IROUTER_SPI_MODE_ANY	(1U << 31)
+
+#define GIC_PIDR2_ARCH_MASK		0xf0
+#define GIC_PIDR2_ARCH_GICv3		0x30
+#define GIC_PIDR2_ARCH_GICv4		0x40
+
+#define GIC_V3_DIST_SIZE		0x10000
+
+/*
+ * Re-Distributor registers, offsets from RD_base
+ */
+#define GICR_CTLR			GICD_CTLR
+#define GICR_IIDR			0x0004
+#define GICR_TYPER			0x0008
+#define GICR_STATUSR			GICD_STATUSR
+#define GICR_WAKER			0x0014
+#define GICR_SETLPIR			0x0040
+#define GICR_CLRLPIR			0x0048
+#define GICR_SEIR			GICD_SEIR
+#define GICR_PROPBASER			0x0070
+#define GICR_PENDBASER			0x0078
+#define GICR_INVLPIR			0x00A0
+#define GICR_INVALLR			0x00B0
+#define GICR_SYNCR			0x00C0
+#define GICR_MOVLPIR			0x0100
+#define GICR_MOVALLR			0x0110
+#define GICR_IDREGS			GICD_IDREGS
+#define GICR_PIDR2			GICD_PIDR2
+
+#define GICR_CTLR_ENABLE_LPIS		(1UL << 0)
+#define GICR_CTLR_RWP			(1UL << 3)
+
+#define GICR_TYPER_CPU_NUMBER(r)	(((r) >> 8) & 0xffff)
+
+#define GICR_WAKER_ProcessorSleep	(1U << 1)
+#define GICR_WAKER_ChildrenAsleep	(1U << 2)
+
+#define GIC_BASER_CACHE_nCnB		0ULL
+#define GIC_BASER_CACHE_SameAsInner	0ULL
+#define GIC_BASER_CACHE_nC		1ULL
+#define GIC_BASER_CACHE_RaWt		2ULL
+#define GIC_BASER_CACHE_RaWb		3ULL
+#define GIC_BASER_CACHE_WaWt		4ULL
+#define GIC_BASER_CACHE_WaWb		5ULL
+#define GIC_BASER_CACHE_RaWaWt		6ULL
+#define GIC_BASER_CACHE_RaWaWb		7ULL
+#define GIC_BASER_CACHE_MASK		7ULL
+#define GIC_BASER_NonShareable		0ULL
+#define GIC_BASER_InnerShareable	1ULL
+#define GIC_BASER_OuterShareable	2ULL
+#define GIC_BASER_SHAREABILITY_MASK	3ULL
+
+#define GIC_BASER_CACHEABILITY(reg, inner_outer, type)			\
+	(GIC_BASER_CACHE_##type << reg##_##inner_outer##_CACHEABILITY_SHIFT)
+
+#define GIC_BASER_SHAREABILITY(reg, type)				\
+	(GIC_BASER_##type << reg##_SHAREABILITY_SHIFT)
+
+/* encode a size field of width @w containing @n - 1 units */
+#define GIC_ENCODE_SZ(n, w) (((unsigned long)(n) - 1) & GENMASK_ULL(((w) - 1), 0))
+
+#define GICR_PROPBASER_SHAREABILITY_SHIFT		(10)
+#define GICR_PROPBASER_INNER_CACHEABILITY_SHIFT		(7)
+#define GICR_PROPBASER_OUTER_CACHEABILITY_SHIFT		(56)
+#define GICR_PROPBASER_SHAREABILITY_MASK				\
+	GIC_BASER_SHAREABILITY(GICR_PROPBASER, SHAREABILITY_MASK)
+#define GICR_PROPBASER_INNER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GICR_PROPBASER, INNER, MASK)
+#define GICR_PROPBASER_OUTER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GICR_PROPBASER, OUTER, MASK)
+#define GICR_PROPBASER_CACHEABILITY_MASK GICR_PROPBASER_INNER_CACHEABILITY_MASK
+
+#define GICR_PROPBASER_InnerShareable					\
+	GIC_BASER_SHAREABILITY(GICR_PROPBASER, InnerShareable)
+
+#define GICR_PROPBASER_nCnB	GIC_BASER_CACHEABILITY(GICR_PROPBASER, INNER, nCnB)
+#define GICR_PROPBASER_nC 	GIC_BASER_CACHEABILITY(GICR_PROPBASER, INNER, nC)
+#define GICR_PROPBASER_RaWt	GIC_BASER_CACHEABILITY(GICR_PROPBASER, INNER, RaWt)
+#define GICR_PROPBASER_RaWb	GIC_BASER_CACHEABILITY(GICR_PROPBASER, INNER, RaWt)
+#define GICR_PROPBASER_WaWt	GIC_BASER_CACHEABILITY(GICR_PROPBASER, INNER, WaWt)
+#define GICR_PROPBASER_WaWb	GIC_BASER_CACHEABILITY(GICR_PROPBASER, INNER, WaWb)
+#define GICR_PROPBASER_RaWaWt	GIC_BASER_CACHEABILITY(GICR_PROPBASER, INNER, RaWaWt)
+#define GICR_PROPBASER_RaWaWb	GIC_BASER_CACHEABILITY(GICR_PROPBASER, INNER, RaWaWb)
+
+#define GICR_PROPBASER_IDBITS_MASK			(0x1f)
+#define GICR_PROPBASER_ADDRESS(x)	((x) & GENMASK_ULL(51, 12))
+#define GICR_PENDBASER_ADDRESS(x)	((x) & GENMASK_ULL(51, 16))
+
+#define GICR_PENDBASER_SHAREABILITY_SHIFT		(10)
+#define GICR_PENDBASER_INNER_CACHEABILITY_SHIFT		(7)
+#define GICR_PENDBASER_OUTER_CACHEABILITY_SHIFT		(56)
+#define GICR_PENDBASER_SHAREABILITY_MASK				\
+	GIC_BASER_SHAREABILITY(GICR_PENDBASER, SHAREABILITY_MASK)
+#define GICR_PENDBASER_INNER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GICR_PENDBASER, INNER, MASK)
+#define GICR_PENDBASER_OUTER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GICR_PENDBASER, OUTER, MASK)
+#define GICR_PENDBASER_CACHEABILITY_MASK GICR_PENDBASER_INNER_CACHEABILITY_MASK
+
+#define GICR_PENDBASER_InnerShareable					\
+	GIC_BASER_SHAREABILITY(GICR_PENDBASER, InnerShareable)
+
+#define GICR_PENDBASER_nCnB	GIC_BASER_CACHEABILITY(GICR_PENDBASER, INNER, nCnB)
+#define GICR_PENDBASER_nC 	GIC_BASER_CACHEABILITY(GICR_PENDBASER, INNER, nC)
+#define GICR_PENDBASER_RaWt	GIC_BASER_CACHEABILITY(GICR_PENDBASER, INNER, RaWt)
+#define GICR_PENDBASER_RaWb	GIC_BASER_CACHEABILITY(GICR_PENDBASER, INNER, RaWt)
+#define GICR_PENDBASER_WaWt	GIC_BASER_CACHEABILITY(GICR_PENDBASER, INNER, WaWt)
+#define GICR_PENDBASER_WaWb	GIC_BASER_CACHEABILITY(GICR_PENDBASER, INNER, WaWb)
+#define GICR_PENDBASER_RaWaWt	GIC_BASER_CACHEABILITY(GICR_PENDBASER, INNER, RaWaWt)
+#define GICR_PENDBASER_RaWaWb	GIC_BASER_CACHEABILITY(GICR_PENDBASER, INNER, RaWaWb)
+
+#define GICR_PENDBASER_PTZ				BIT_ULL(62)
+
+/*
+ * Re-Distributor registers, offsets from SGI_base
+ */
+#define GICR_IGROUPR0			GICD_IGROUPR
+#define GICR_ISENABLER0			GICD_ISENABLER
+#define GICR_ICENABLER0			GICD_ICENABLER
+#define GICR_ISPENDR0			GICD_ISPENDR
+#define GICR_ICPENDR0			GICD_ICPENDR
+#define GICR_ISACTIVER0			GICD_ISACTIVER
+#define GICR_ICACTIVER0			GICD_ICACTIVER
+#define GICR_IPRIORITYR0		GICD_IPRIORITYR
+#define GICR_ICFGR0			GICD_ICFGR
+#define GICR_IGRPMODR0			GICD_IGRPMODR
+#define GICR_NSACR			GICD_NSACR
+
+#define GICR_TYPER_PLPIS		(1U << 0)
+#define GICR_TYPER_VLPIS		(1U << 1)
+#define GICR_TYPER_DirectLPIS		(1U << 3)
+#define GICR_TYPER_LAST			(1U << 4)
+
+#define GIC_V3_REDIST_SIZE		0x20000
+
+#define LPI_PROP_GROUP1			(1 << 1)
+#define LPI_PROP_ENABLED		(1 << 0)
+
+/*
+ * Re-Distributor registers, offsets from VLPI_base
+ */
+#define GICR_VPROPBASER			0x0070
+
+#define GICR_VPROPBASER_IDBITS_MASK	0x1f
+
+#define GICR_VPROPBASER_SHAREABILITY_SHIFT		(10)
+#define GICR_VPROPBASER_INNER_CACHEABILITY_SHIFT	(7)
+#define GICR_VPROPBASER_OUTER_CACHEABILITY_SHIFT	(56)
+
+#define GICR_VPROPBASER_SHAREABILITY_MASK				\
+	GIC_BASER_SHAREABILITY(GICR_VPROPBASER, SHAREABILITY_MASK)
+#define GICR_VPROPBASER_INNER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GICR_VPROPBASER, INNER, MASK)
+#define GICR_VPROPBASER_OUTER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GICR_VPROPBASER, OUTER, MASK)
+#define GICR_VPROPBASER_CACHEABILITY_MASK				\
+	GICR_VPROPBASER_INNER_CACHEABILITY_MASK
+
+#define GICR_VPROPBASER_InnerShareable					\
+	GIC_BASER_SHAREABILITY(GICR_VPROPBASER, InnerShareable)
+
+#define GICR_VPROPBASER_nCnB	GIC_BASER_CACHEABILITY(GICR_VPROPBASER, INNER, nCnB)
+#define GICR_VPROPBASER_nC 	GIC_BASER_CACHEABILITY(GICR_VPROPBASER, INNER, nC)
+#define GICR_VPROPBASER_RaWt	GIC_BASER_CACHEABILITY(GICR_VPROPBASER, INNER, RaWt)
+#define GICR_VPROPBASER_RaWb	GIC_BASER_CACHEABILITY(GICR_VPROPBASER, INNER, RaWt)
+#define GICR_VPROPBASER_WaWt	GIC_BASER_CACHEABILITY(GICR_VPROPBASER, INNER, WaWt)
+#define GICR_VPROPBASER_WaWb	GIC_BASER_CACHEABILITY(GICR_VPROPBASER, INNER, WaWb)
+#define GICR_VPROPBASER_RaWaWt	GIC_BASER_CACHEABILITY(GICR_VPROPBASER, INNER, RaWaWt)
+#define GICR_VPROPBASER_RaWaWb	GIC_BASER_CACHEABILITY(GICR_VPROPBASER, INNER, RaWaWb)
+
+#define GICR_VPENDBASER			0x0078
+
+#define GICR_VPENDBASER_SHAREABILITY_SHIFT		(10)
+#define GICR_VPENDBASER_INNER_CACHEABILITY_SHIFT	(7)
+#define GICR_VPENDBASER_OUTER_CACHEABILITY_SHIFT	(56)
+#define GICR_VPENDBASER_SHAREABILITY_MASK				\
+	GIC_BASER_SHAREABILITY(GICR_VPENDBASER, SHAREABILITY_MASK)
+#define GICR_VPENDBASER_INNER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GICR_VPENDBASER, INNER, MASK)
+#define GICR_VPENDBASER_OUTER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GICR_VPENDBASER, OUTER, MASK)
+#define GICR_VPENDBASER_CACHEABILITY_MASK				\
+	GICR_VPENDBASER_INNER_CACHEABILITY_MASK
+
+#define GICR_VPENDBASER_NonShareable					\
+	GIC_BASER_SHAREABILITY(GICR_VPENDBASER, NonShareable)
+
+#define GICR_VPENDBASER_nCnB	GIC_BASER_CACHEABILITY(GICR_VPENDBASER, INNER, nCnB)
+#define GICR_VPENDBASER_nC 	GIC_BASER_CACHEABILITY(GICR_VPENDBASER, INNER, nC)
+#define GICR_VPENDBASER_RaWt	GIC_BASER_CACHEABILITY(GICR_VPENDBASER, INNER, RaWt)
+#define GICR_VPENDBASER_RaWb	GIC_BASER_CACHEABILITY(GICR_VPENDBASER, INNER, RaWt)
+#define GICR_VPENDBASER_WaWt	GIC_BASER_CACHEABILITY(GICR_VPENDBASER, INNER, WaWt)
+#define GICR_VPENDBASER_WaWb	GIC_BASER_CACHEABILITY(GICR_VPENDBASER, INNER, WaWb)
+#define GICR_VPENDBASER_RaWaWt	GIC_BASER_CACHEABILITY(GICR_VPENDBASER, INNER, RaWaWt)
+#define GICR_VPENDBASER_RaWaWb	GIC_BASER_CACHEABILITY(GICR_VPENDBASER, INNER, RaWaWb)
+
+#define GICR_VPENDBASER_Dirty		(1ULL << 60)
+#define GICR_VPENDBASER_PendingLast	(1ULL << 61)
+#define GICR_VPENDBASER_IDAI		(1ULL << 62)
+#define GICR_VPENDBASER_Valid		(1ULL << 63)
+
+/*
+ * ITS registers, offsets from ITS_base
+ */
+#define GITS_CTLR			0x0000
+#define GITS_IIDR			0x0004
+#define GITS_TYPER			0x0008
+#define GITS_CBASER			0x0080
+#define GITS_CWRITER			0x0088
+#define GITS_CREADR			0x0090
+#define GITS_BASER			0x0100
+#define GITS_IDREGS_BASE		0xffd0
+#define GITS_PIDR0			0xffe0
+#define GITS_PIDR1			0xffe4
+#define GITS_PIDR2			GICR_PIDR2
+#define GITS_PIDR4			0xffd0
+#define GITS_CIDR0			0xfff0
+#define GITS_CIDR1			0xfff4
+#define GITS_CIDR2			0xfff8
+#define GITS_CIDR3			0xfffc
+
+#define GITS_TRANSLATER			0x10040
+
+#define GITS_CTLR_ENABLE		(1U << 0)
+#define GITS_CTLR_ImDe			(1U << 1)
+#define	GITS_CTLR_ITS_NUMBER_SHIFT	4
+#define	GITS_CTLR_ITS_NUMBER		(0xFU << GITS_CTLR_ITS_NUMBER_SHIFT)
+#define GITS_CTLR_QUIESCENT		(1U << 31)
+
+#define GITS_TYPER_PLPIS		(1UL << 0)
+#define GITS_TYPER_VLPIS		(1UL << 1)
+#define GITS_TYPER_ITT_ENTRY_SIZE_SHIFT	4
+#define GITS_TYPER_ITT_ENTRY_SIZE(r)	((((r) >> GITS_TYPER_ITT_ENTRY_SIZE_SHIFT) & 0x1f) + 1)
+#define GITS_TYPER_IDBITS_SHIFT		8
+#define GITS_TYPER_DEVBITS_SHIFT	13
+#define GITS_TYPER_DEVBITS(r)		((((r) >> GITS_TYPER_DEVBITS_SHIFT) & 0x1f) + 1)
+#define GITS_TYPER_PTA			(1UL << 19)
+#define GITS_TYPER_HCC_SHIFT		24
+#define GITS_TYPER_HCC(r)		(((r) >> GITS_TYPER_HCC_SHIFT) & 0xff)
+#define GITS_TYPER_VMOVP		(1ULL << 37)
+
+#define GITS_IIDR_REV_SHIFT		12
+#define GITS_IIDR_REV_MASK		(0xf << GITS_IIDR_REV_SHIFT)
+#define GITS_IIDR_REV(r)		(((r) >> GITS_IIDR_REV_SHIFT) & 0xf)
+#define GITS_IIDR_PRODUCTID_SHIFT	24
+
+#define GITS_CBASER_VALID			(1ULL << 63)
+#define GITS_CBASER_SHAREABILITY_SHIFT		(10)
+#define GITS_CBASER_INNER_CACHEABILITY_SHIFT	(59)
+#define GITS_CBASER_OUTER_CACHEABILITY_SHIFT	(53)
+#define GITS_CBASER_SHAREABILITY_MASK					\
+	GIC_BASER_SHAREABILITY(GITS_CBASER, SHAREABILITY_MASK)
+#define GITS_CBASER_INNER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GITS_CBASER, INNER, MASK)
+#define GITS_CBASER_OUTER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GITS_CBASER, OUTER, MASK)
+#define GITS_CBASER_CACHEABILITY_MASK GITS_CBASER_INNER_CACHEABILITY_MASK
+
+#define GITS_CBASER_InnerShareable					\
+	GIC_BASER_SHAREABILITY(GITS_CBASER, InnerShareable)
+
+#define GITS_CBASER_nCnB	GIC_BASER_CACHEABILITY(GITS_CBASER, INNER, nCnB)
+#define GITS_CBASER_nC		GIC_BASER_CACHEABILITY(GITS_CBASER, INNER, nC)
+#define GITS_CBASER_RaWt	GIC_BASER_CACHEABILITY(GITS_CBASER, INNER, RaWt)
+#define GITS_CBASER_RaWb	GIC_BASER_CACHEABILITY(GITS_CBASER, INNER, RaWt)
+#define GITS_CBASER_WaWt	GIC_BASER_CACHEABILITY(GITS_CBASER, INNER, WaWt)
+#define GITS_CBASER_WaWb	GIC_BASER_CACHEABILITY(GITS_CBASER, INNER, WaWb)
+#define GITS_CBASER_RaWaWt	GIC_BASER_CACHEABILITY(GITS_CBASER, INNER, RaWaWt)
+#define GITS_CBASER_RaWaWb	GIC_BASER_CACHEABILITY(GITS_CBASER, INNER, RaWaWb)
+
+#define GITS_BASER_NR_REGS		8
+
+#define GITS_BASER_VALID			(1ULL << 63)
+#define GITS_BASER_INDIRECT			(1ULL << 62)
+
+#define GITS_BASER_INNER_CACHEABILITY_SHIFT	(59)
+#define GITS_BASER_OUTER_CACHEABILITY_SHIFT	(53)
+#define GITS_BASER_INNER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GITS_BASER, INNER, MASK)
+#define GITS_BASER_CACHEABILITY_MASK		GITS_BASER_INNER_CACHEABILITY_MASK
+#define GITS_BASER_OUTER_CACHEABILITY_MASK				\
+	GIC_BASER_CACHEABILITY(GITS_BASER, OUTER, MASK)
+#define GITS_BASER_SHAREABILITY_MASK					\
+	GIC_BASER_SHAREABILITY(GITS_BASER, SHAREABILITY_MASK)
+
+#define GITS_BASER_nCnB		GIC_BASER_CACHEABILITY(GITS_BASER, INNER, nCnB)
+#define GITS_BASER_nC		GIC_BASER_CACHEABILITY(GITS_BASER, INNER, nC)
+#define GITS_BASER_RaWt		GIC_BASER_CACHEABILITY(GITS_BASER, INNER, RaWt)
+#define GITS_BASER_RaWb		GIC_BASER_CACHEABILITY(GITS_BASER, INNER, RaWt)
+#define GITS_BASER_WaWt		GIC_BASER_CACHEABILITY(GITS_BASER, INNER, WaWt)
+#define GITS_BASER_WaWb		GIC_BASER_CACHEABILITY(GITS_BASER, INNER, WaWb)
+#define GITS_BASER_RaWaWt	GIC_BASER_CACHEABILITY(GITS_BASER, INNER, RaWaWt)
+#define GITS_BASER_RaWaWb	GIC_BASER_CACHEABILITY(GITS_BASER, INNER, RaWaWb)
+
+#define GITS_BASER_TYPE_SHIFT			(56)
+#define GITS_BASER_TYPE(r)		(((r) >> GITS_BASER_TYPE_SHIFT) & 7)
+#define GITS_BASER_ENTRY_SIZE_SHIFT		(48)
+#define GITS_BASER_ENTRY_SIZE(r)	((((r) >> GITS_BASER_ENTRY_SIZE_SHIFT) & 0x1f) + 1)
+#define GITS_BASER_ENTRY_SIZE_MASK	GENMASK_ULL(52, 48)
+#define GITS_BASER_PHYS_52_to_48(phys)					\
+	(((phys) & GENMASK_ULL(47, 16)) | (((phys) >> 48) & 0xf) << 12)
+#define GITS_BASER_SHAREABILITY_SHIFT	(10)
+#define GITS_BASER_InnerShareable					\
+	GIC_BASER_SHAREABILITY(GITS_BASER, InnerShareable)
+#define GITS_BASER_PAGE_SIZE_SHIFT	(8)
+#define GITS_BASER_PAGE_SIZE_4K		(0ULL << GITS_BASER_PAGE_SIZE_SHIFT)
+#define GITS_BASER_PAGE_SIZE_16K	(1ULL << GITS_BASER_PAGE_SIZE_SHIFT)
+#define GITS_BASER_PAGE_SIZE_64K	(2ULL << GITS_BASER_PAGE_SIZE_SHIFT)
+#define GITS_BASER_PAGE_SIZE_MASK	(3ULL << GITS_BASER_PAGE_SIZE_SHIFT)
+#define GITS_BASER_PAGES_MAX		256
+#define GITS_BASER_PAGES_SHIFT		(0)
+#define GITS_BASER_NR_PAGES(r)		(((r) & 0xff) + 1)
+
+#define GITS_BASER_TYPE_NONE		0
+#define GITS_BASER_TYPE_DEVICE		1
+#define GITS_BASER_TYPE_VCPU		2
+#define GITS_BASER_TYPE_RESERVED3	3
+#define GITS_BASER_TYPE_COLLECTION	4
+#define GITS_BASER_TYPE_RESERVED5	5
+#define GITS_BASER_TYPE_RESERVED6	6
+#define GITS_BASER_TYPE_RESERVED7	7
+
+#define GITS_LVL1_ENTRY_SIZE           (8UL)
+
+/*
+ * ITS commands
+ */
+#define GITS_CMD_MAPD			0x08
+#define GITS_CMD_MAPC			0x09
+#define GITS_CMD_MAPTI			0x0a
+#define GITS_CMD_MAPI			0x0b
+#define GITS_CMD_MOVI			0x01
+#define GITS_CMD_DISCARD		0x0f
+#define GITS_CMD_INV			0x0c
+#define GITS_CMD_MOVALL			0x0e
+#define GITS_CMD_INVALL			0x0d
+#define GITS_CMD_INT			0x03
+#define GITS_CMD_CLEAR			0x04
+#define GITS_CMD_SYNC			0x05
+
+/*
+ * GICv4 ITS specific commands
+ */
+#define GITS_CMD_GICv4(x)		((x) | 0x20)
+#define GITS_CMD_VINVALL		GITS_CMD_GICv4(GITS_CMD_INVALL)
+#define GITS_CMD_VMAPP			GITS_CMD_GICv4(GITS_CMD_MAPC)
+#define GITS_CMD_VMAPTI			GITS_CMD_GICv4(GITS_CMD_MAPTI)
+#define GITS_CMD_VMOVI			GITS_CMD_GICv4(GITS_CMD_MOVI)
+#define GITS_CMD_VSYNC			GITS_CMD_GICv4(GITS_CMD_SYNC)
+/* VMOVP is the odd one, as it doesn't have a physical counterpart */
+#define GITS_CMD_VMOVP			GITS_CMD_GICv4(2)
+
+/*
+ * ITS error numbers
+ */
+#define E_ITS_MOVI_UNMAPPED_INTERRUPT		0x010107
+#define E_ITS_MOVI_UNMAPPED_COLLECTION		0x010109
+#define E_ITS_INT_UNMAPPED_INTERRUPT		0x010307
+#define E_ITS_CLEAR_UNMAPPED_INTERRUPT		0x010507
+#define E_ITS_MAPD_DEVICE_OOR			0x010801
+#define E_ITS_MAPD_ITTSIZE_OOR			0x010802
+#define E_ITS_MAPC_PROCNUM_OOR			0x010902
+#define E_ITS_MAPC_COLLECTION_OOR		0x010903
+#define E_ITS_MAPTI_UNMAPPED_DEVICE		0x010a04
+#define E_ITS_MAPTI_ID_OOR			0x010a05
+#define E_ITS_MAPTI_PHYSICALID_OOR		0x010a06
+#define E_ITS_INV_UNMAPPED_INTERRUPT		0x010c07
+#define E_ITS_INVALL_UNMAPPED_COLLECTION	0x010d09
+#define E_ITS_MOVALL_PROCNUM_OOR		0x010e01
+#define E_ITS_DISCARD_UNMAPPED_INTERRUPT	0x010f07
+
+/*
+ * CPU interface registers
+ */
+#define ICC_CTLR_EL1_EOImode_SHIFT	(1)
+#define ICC_CTLR_EL1_EOImode_drop_dir	(0U << ICC_CTLR_EL1_EOImode_SHIFT)
+#define ICC_CTLR_EL1_EOImode_drop	(1U << ICC_CTLR_EL1_EOImode_SHIFT)
+#define ICC_CTLR_EL1_EOImode_MASK	(1 << ICC_CTLR_EL1_EOImode_SHIFT)
+#define ICC_CTLR_EL1_CBPR_SHIFT		0
+#define ICC_CTLR_EL1_CBPR_MASK		(1 << ICC_CTLR_EL1_CBPR_SHIFT)
+#define ICC_CTLR_EL1_PRI_BITS_SHIFT	8
+#define ICC_CTLR_EL1_PRI_BITS_MASK	(0x7 << ICC_CTLR_EL1_PRI_BITS_SHIFT)
+#define ICC_CTLR_EL1_ID_BITS_SHIFT	11
+#define ICC_CTLR_EL1_ID_BITS_MASK	(0x7 << ICC_CTLR_EL1_ID_BITS_SHIFT)
+#define ICC_CTLR_EL1_SEIS_SHIFT		14
+#define ICC_CTLR_EL1_SEIS_MASK		(0x1 << ICC_CTLR_EL1_SEIS_SHIFT)
+#define ICC_CTLR_EL1_A3V_SHIFT		15
+#define ICC_CTLR_EL1_A3V_MASK		(0x1 << ICC_CTLR_EL1_A3V_SHIFT)
+#define ICC_CTLR_EL1_RSS		(0x1 << 18)
+#define ICC_PMR_EL1_SHIFT		0
+#define ICC_PMR_EL1_MASK		(0xff << ICC_PMR_EL1_SHIFT)
+#define ICC_BPR0_EL1_SHIFT		0
+#define ICC_BPR0_EL1_MASK		(0x7 << ICC_BPR0_EL1_SHIFT)
+#define ICC_BPR1_EL1_SHIFT		0
+#define ICC_BPR1_EL1_MASK		(0x7 << ICC_BPR1_EL1_SHIFT)
+#define ICC_IGRPEN0_EL1_SHIFT		0
+#define ICC_IGRPEN0_EL1_MASK		(1 << ICC_IGRPEN0_EL1_SHIFT)
+#define ICC_IGRPEN1_EL1_SHIFT		0
+#define ICC_IGRPEN1_EL1_MASK		(1 << ICC_IGRPEN1_EL1_SHIFT)
+#define ICC_SRE_EL1_DIB			(1U << 2)
+#define ICC_SRE_EL1_DFB			(1U << 1)
+#define ICC_SRE_EL1_SRE			(1U << 0)
+
+/*
+ * Hypervisor interface registers (SRE only)
+ */
+#define ICH_LR_VIRTUAL_ID_MASK		((1ULL << 32) - 1)
+
+#define ICH_LR_EOI			(1ULL << 41)
+#define ICH_LR_GROUP			(1ULL << 60)
+#define ICH_LR_HW			(1ULL << 61)
+#define ICH_LR_STATE			(3ULL << 62)
+#define ICH_LR_PENDING_BIT		(1ULL << 62)
+#define ICH_LR_ACTIVE_BIT		(1ULL << 63)
+#define ICH_LR_PHYS_ID_SHIFT		32
+#define ICH_LR_PHYS_ID_MASK		(0x3ffULL << ICH_LR_PHYS_ID_SHIFT)
+#define ICH_LR_PRIORITY_SHIFT		48
+#define ICH_LR_PRIORITY_MASK		(0xffULL << ICH_LR_PRIORITY_SHIFT)
+
+/* These are for GICv2 emulation only */
+#define GICH_LR_VIRTUALID		(0x3ffUL << 0)
+#define GICH_LR_PHYSID_CPUID_SHIFT	(10)
+#define GICH_LR_PHYSID_CPUID		(7UL << GICH_LR_PHYSID_CPUID_SHIFT)
+
+#define ICH_MISR_EOI			(1 << 0)
+#define ICH_MISR_U			(1 << 1)
+
+#define ICH_HCR_EN			(1 << 0)
+#define ICH_HCR_UIE			(1 << 1)
+#define ICH_HCR_NPIE			(1 << 3)
+#define ICH_HCR_TC			(1 << 10)
+#define ICH_HCR_TALL0			(1 << 11)
+#define ICH_HCR_TALL1			(1 << 12)
+#define ICH_HCR_EOIcount_SHIFT		27
+#define ICH_HCR_EOIcount_MASK		(0x1f << ICH_HCR_EOIcount_SHIFT)
+
+#define ICH_VMCR_ACK_CTL_SHIFT		2
+#define ICH_VMCR_ACK_CTL_MASK		(1 << ICH_VMCR_ACK_CTL_SHIFT)
+#define ICH_VMCR_FIQ_EN_SHIFT		3
+#define ICH_VMCR_FIQ_EN_MASK		(1 << ICH_VMCR_FIQ_EN_SHIFT)
+#define ICH_VMCR_CBPR_SHIFT		4
+#define ICH_VMCR_CBPR_MASK		(1 << ICH_VMCR_CBPR_SHIFT)
+#define ICH_VMCR_EOIM_SHIFT		9
+#define ICH_VMCR_EOIM_MASK		(1 << ICH_VMCR_EOIM_SHIFT)
+#define ICH_VMCR_BPR1_SHIFT		18
+#define ICH_VMCR_BPR1_MASK		(7 << ICH_VMCR_BPR1_SHIFT)
+#define ICH_VMCR_BPR0_SHIFT		21
+#define ICH_VMCR_BPR0_MASK		(7 << ICH_VMCR_BPR0_SHIFT)
+#define ICH_VMCR_PMR_SHIFT		24
+#define ICH_VMCR_PMR_MASK		(0xffUL << ICH_VMCR_PMR_SHIFT)
+#define ICH_VMCR_ENG0_SHIFT		0
+#define ICH_VMCR_ENG0_MASK		(1 << ICH_VMCR_ENG0_SHIFT)
+#define ICH_VMCR_ENG1_SHIFT		1
+#define ICH_VMCR_ENG1_MASK		(1 << ICH_VMCR_ENG1_SHIFT)
+
+#define ICH_VTR_PRI_BITS_SHIFT		29
+#define ICH_VTR_PRI_BITS_MASK		(7 << ICH_VTR_PRI_BITS_SHIFT)
+#define ICH_VTR_ID_BITS_SHIFT		23
+#define ICH_VTR_ID_BITS_MASK		(7 << ICH_VTR_ID_BITS_SHIFT)
+#define ICH_VTR_SEIS_SHIFT		22
+#define ICH_VTR_SEIS_MASK		(1 << ICH_VTR_SEIS_SHIFT)
+#define ICH_VTR_A3V_SHIFT		21
+#define ICH_VTR_A3V_MASK		(1 << ICH_VTR_A3V_SHIFT)
+
+#define ICC_IAR1_EL1_SPURIOUS		0x3ff
+
+#define ICC_SRE_EL2_SRE			(1 << 0)
+#define ICC_SRE_EL2_ENABLE		(1 << 3)
+
+#define ICC_SGI1R_TARGET_LIST_SHIFT	0
+#define ICC_SGI1R_TARGET_LIST_MASK	(0xffff << ICC_SGI1R_TARGET_LIST_SHIFT)
+#define ICC_SGI1R_AFFINITY_1_SHIFT	16
+#define ICC_SGI1R_AFFINITY_1_MASK	(0xff << ICC_SGI1R_AFFINITY_1_SHIFT)
+#define ICC_SGI1R_SGI_ID_SHIFT		24
+#define ICC_SGI1R_SGI_ID_MASK		(0xfULL << ICC_SGI1R_SGI_ID_SHIFT)
+#define ICC_SGI1R_AFFINITY_2_SHIFT	32
+#define ICC_SGI1R_AFFINITY_2_MASK	(0xffULL << ICC_SGI1R_AFFINITY_2_SHIFT)
+#define ICC_SGI1R_IRQ_ROUTING_MODE_BIT	40
+#define ICC_SGI1R_RS_SHIFT		44
+#define ICC_SGI1R_RS_MASK		(0xfULL << ICC_SGI1R_RS_SHIFT)
+#define ICC_SGI1R_AFFINITY_3_SHIFT	48
+#define ICC_SGI1R_AFFINITY_3_MASK	(0xffULL << ICC_SGI1R_AFFINITY_3_SHIFT)
+
+#include <asm/arch_gicv3.h>
+
+#ifndef __ASSEMBLY__
+
+/*
+ * We need a value to serve as a irq-type for LPIs. Choose one that will
+ * hopefully pique the interest of the reviewer.
+ */
+#define GIC_IRQ_TYPE_LPI		0xa110c8ed
+
+struct rdists {
+	struct {
+		void __iomem	*rd_base;
+		struct page	*pend_page;
+		phys_addr_t	phys_base;
+	} __percpu		*rdist;
+	struct page		*prop_page;
+	u64			flags;
+	u32			gicd_typer;
+	bool			has_vlpis;
+	bool			has_direct_lpi;
+};
+
+struct irq_domain;
+struct fwnode_handle;
+int phytium_its_cpu_init(void);
+int phytium_its_init(struct fwnode_handle *handle, struct rdists *rdists,
+	     struct irq_domain *domain);
+
+static inline bool gic_enable_sre(void)
+{
+	u32 val;
+
+	val = gic_read_sre();
+	if (val & ICC_SRE_EL1_SRE)
+		return true;
+
+	val |= ICC_SRE_EL1_SRE;
+	gic_write_sre(val);
+	val = gic_read_sre();
+
+	return !!(val & ICC_SRE_EL1_SRE);
+}
+
+#endif
+
+#endif
diff --git a/include/linux/memblock.h b/include/linux/memblock.h
index 516920549378..c3e5e5e8fa2a 100644
--- a/include/linux/memblock.h
+++ b/include/linux/memblock.h
@@ -316,6 +316,9 @@ static inline int memblock_get_region_node(const struct memblock_region *r)
 }
 #endif /* CONFIG_HAVE_MEMBLOCK_NODE_MAP */
 
+void *memblock_alloc_exact_nid_raw(phys_addr_t size, phys_addr_t align,
+				 phys_addr_t min_addr, phys_addr_t max_addr,
+				 int nid);
 phys_addr_t memblock_alloc_nid(phys_addr_t size, phys_addr_t align, int nid);
 phys_addr_t memblock_alloc_try_nid(phys_addr_t size, phys_addr_t align, int nid);
 
diff --git a/mm/memblock.c b/mm/memblock.c
index 237944479d25..e5fbec3b69f1 100644
--- a/mm/memblock.c
+++ b/mm/memblock.c
@@ -1349,7 +1349,7 @@ phys_addr_t __init memblock_alloc_try_nid(phys_addr_t size, phys_addr_t align, i
 static void * __init memblock_virt_alloc_internal(
 				phys_addr_t size, phys_addr_t align,
 				phys_addr_t min_addr, phys_addr_t max_addr,
-				int nid)
+				int nid, bool exact_nid)
 {
 	phys_addr_t alloc;
 	void *ptr;
@@ -1377,7 +1377,7 @@ static void * __init memblock_virt_alloc_internal(
 	if (alloc && !memblock_reserve(alloc, size))
 		goto done;
 
-	if (nid != NUMA_NO_NODE) {
+	if (nid != NUMA_NO_NODE && !exact_nid) {
 		alloc = memblock_find_in_range_node(size, align, min_addr,
 						    max_addr, NUMA_NO_NODE,
 						    flags);
@@ -1443,7 +1443,7 @@ void * __init memblock_virt_alloc_try_nid_raw(
 		     &max_addr, (void *)_RET_IP_);
 
 	ptr = memblock_virt_alloc_internal(size, align,
-					   min_addr, max_addr, nid);
+					   min_addr, max_addr, nid, false);
 #ifdef CONFIG_DEBUG_VM
 	if (ptr && size > 0)
 		memset(ptr, PAGE_POISON_PATTERN, size);
@@ -1451,6 +1451,43 @@ void * __init memblock_virt_alloc_try_nid_raw(
 	return ptr;
 }
 
+/**
+ * memblock_alloc_exact_nid_raw - allocate boot memory block on the exact node
+ * without zeroing memory
+ * @size: size of memory block to be allocated in bytes
+ * @align: alignment of the region and block's size
+ * @min_addr: the lower bound of the memory region from where the allocation
+ *       is preferred (phys address)
+ * @max_addr: the upper bound of the memory region from where the allocation
+ *           is preferred (phys address), or %MEMBLOCK_ALLOC_ACCESSIBLE to
+ *           allocate only from memory limited by memblock.current_limit value
+ * @nid: nid of the free area to find, %NUMA_NO_NODE for any node
+ *
+ * Public function, provides additional debug information (including caller
+ * info), if enabled. Does not zero allocated memory.
+ *
+ * Return:
+ * Virtual address of allocated memory block on success, NULL on failure.
+ */
+void * __init memblock_alloc_exact_nid_raw(
+                       phys_addr_t size, phys_addr_t align,
+                       phys_addr_t min_addr, phys_addr_t max_addr,
+                       int nid)
+{
+	void *ptr;
+
+	memblock_dbg("%s: %llu bytes align=0x%llx nid=%d from=%pa max_addr=%pa %pS\n",
+		     __func__, (u64)size, (u64)align, nid, &min_addr,
+		     &max_addr, (void *)_RET_IP_);
+
+	ptr = memblock_virt_alloc_internal(size, align,
+                                          min_addr, max_addr, nid, true);
+	if (ptr && size > 0)
+		memset(ptr, PAGE_POISON_PATTERN, size);
+
+       return ptr;
+}
+
 /**
  * memblock_virt_alloc_try_nid_nopanic - allocate boot memory block
  * @size: size of memory block to be allocated in bytes
@@ -1480,7 +1517,7 @@ void * __init memblock_virt_alloc_try_nid_nopanic(
 		     &max_addr, (void *)_RET_IP_);
 
 	ptr = memblock_virt_alloc_internal(size, align,
-					   min_addr, max_addr, nid);
+					   min_addr, max_addr, nid, false);
 	if (ptr)
 		memset(ptr, 0, size);
 	return ptr;
@@ -1515,7 +1552,7 @@ void * __init memblock_virt_alloc_try_nid(
 		     __func__, (u64)size, (u64)align, nid, &min_addr,
 		     &max_addr, (void *)_RET_IP_);
 	ptr = memblock_virt_alloc_internal(size, align,
-					   min_addr, max_addr, nid);
+					   min_addr, max_addr, nid, false);
 	if (ptr) {
 		memset(ptr, 0, size);
 		return ptr;
diff --git a/mm/sparse.c b/mm/sparse.c
index 10b07eea9a6e..ecd34c6b6cb6 100644
--- a/mm/sparse.c
+++ b/mm/sparse.c
@@ -17,6 +17,8 @@
 #include <asm/pgalloc.h>
 #include <asm/pgtable.h>
 
+#include <linux/memblock.h>
+
 /*
  * Permanent SPARSEMEM data:
  *
@@ -405,7 +407,7 @@ static void __init sparse_buffer_init(unsigned long size, int nid)
 {
 	WARN_ON(sparsemap_buf);	/* forgot to call sparse_buffer_fini()? */
 	sparsemap_buf =
-		memblock_virt_alloc_try_nid_raw(size, PAGE_SIZE,
+		memblock_alloc_exact_nid_raw(size, section_map_size(),
 						__pa(MAX_DMA_ADDRESS),
 						BOOTMEM_ALLOC_ACCESSIBLE, nid);
 	sparsemap_buf_end = sparsemap_buf + size;
diff --git a/sound/hda/hdac_stream.c b/sound/hda/hdac_stream.c
index eee422390d8e..38586457ee09 100644
--- a/sound/hda/hdac_stream.c
+++ b/sound/hda/hdac_stream.c
@@ -51,7 +51,11 @@ void snd_hdac_stream_start(struct hdac_stream *azx_dev, bool fresh_start)
 
 	trace_snd_hdac_stream_start(bus, azx_dev);
 
+#ifdef CONFIG_SND_HDA_PHYTIUM
+	azx_dev->start_wallclk = snd_hdac_chip_readl(bus, WALLCLK) / 15;
+#else
 	azx_dev->start_wallclk = snd_hdac_chip_readl(bus, WALLCLK);
+#endif
 	if (!fresh_start)
 		azx_dev->start_wallclk -= azx_dev->period_wallclk;
 
@@ -469,7 +473,11 @@ static u64 azx_cc_read(const struct cyclecounter *cc)
 {
 	struct hdac_stream *azx_dev = container_of(cc, struct hdac_stream, cc);
 
+#ifdef CONFIG_SND_HDA_PHYTIUM
+	return snd_hdac_chip_readl(azx_dev->bus, WALLCLK) / 25;
+#else
 	return snd_hdac_chip_readl(azx_dev->bus, WALLCLK);
+#endif
 }
 
 static void azx_timecounter_init(struct hdac_stream *azx_dev,
diff --git a/sound/pci/hda/Kconfig b/sound/pci/hda/Kconfig
index 4235907b7858..df95dad1233f 100644
--- a/sound/pci/hda/Kconfig
+++ b/sound/pci/hda/Kconfig
@@ -21,6 +21,21 @@ config SND_HDA_INTEL
 	  To compile this driver as a module, choose M here: the module
 	  will be called snd-hda-intel.
 
+config SND_HDA_PHYTIUM
+	tristate "PHYTIUM HD Audio"
+	depends on SOUND
+	select SND_HDA
+	help
+	  Say Y here to support the HDA controller present in PHYTIUM
+	  SoCs
+
+	  This options enables support for the HD Audio controller
+	  present in some PHYTIUM SoCs, used to communicate audio
+	  to the "High Definition Audio" codec.
+
+	  To compile this driver as a module, choose M here: the module
+	  will be called snd-hda-phytium.
+
 config SND_HDA_TEGRA
 	tristate "NVIDIA Tegra HD Audio"
 	depends on ARCH_TEGRA
diff --git a/sound/pci/hda/Makefile b/sound/pci/hda/Makefile
index b57432f00056..90e32c8ce07b 100644
--- a/sound/pci/hda/Makefile
+++ b/sound/pci/hda/Makefile
@@ -1,5 +1,6 @@
 # SPDX-License-Identifier: GPL-2.0
 snd-hda-intel-objs := hda_intel.o
+snd-hda-phytium-objs := hda_phytium.o
 snd-hda-tegra-objs := hda_tegra.o
 
 snd-hda-codec-y := hda_bind.o hda_codec.o hda_jack.o hda_auto_parser.o hda_sysfs.o
@@ -48,3 +49,4 @@ obj-$(CONFIG_SND_HDA_CODEC_HDMI) += snd-hda-codec-hdmi.o
 # when built in kernel
 obj-$(CONFIG_SND_HDA_INTEL) += snd-hda-intel.o
 obj-$(CONFIG_SND_HDA_TEGRA) += snd-hda-tegra.o
+obj-$(CONFIG_SND_HDA_PHYTIUM) += snd-hda-phytium.o
diff --git a/sound/pci/hda/hda_controller.c b/sound/pci/hda/hda_controller.c
index a12e594d4e3b..ff62cfa63c58 100644
--- a/sound/pci/hda/hda_controller.c
+++ b/sound/pci/hda/hda_controller.c
@@ -28,6 +28,8 @@
 #include <linux/pm_runtime.h>
 #include <linux/slab.h>
 
+#include "hda_phytium.h"
+
 #ifdef CONFIG_X86
 /* for art-tsc conversion */
 #include <asm/tsc.h>
@@ -171,6 +173,10 @@ static int azx_pcm_prepare(struct snd_pcm_substream *substream)
 		snd_hda_spdif_out_of_nid(apcm->codec, hinfo->nid);
 	unsigned short ctls = spdif ? spdif->ctls : 0;
 
+	struct hda_ft *hda;
+	hda = container_of(chip, struct hda_ft, chip);
+	hda->substream = substream;
+
 	trace_azx_pcm_prepare(chip, azx_dev);
 	dsp_lock(azx_dev);
 	if (dsp_is_locked(azx_dev)) {
diff --git a/sound/pci/hda/hda_intel.c b/sound/pci/hda/hda_intel.c
index aa4c672dbaf7..62847f7bab09 100644
--- a/sound/pci/hda/hda_intel.c
+++ b/sound/pci/hda/hda_intel.c
@@ -67,7 +67,7 @@
 #include "hda_controller.h"
 #include "hda_intel.h"
 
-#define CREATE_TRACE_POINTS
+//#define CREATE_TRACE_POINTS
 #include "hda_intel_trace.h"
 
 /* position fix mode */
diff --git a/sound/pci/hda/hda_phytium.c b/sound/pci/hda/hda_phytium.c
new file mode 100644
index 000000000000..2dc13f4e638c
--- /dev/null
+++ b/sound/pci/hda/hda_phytium.c
@@ -0,0 +1,1208 @@
+/*
+ *  hda_phytium.c - Implementation of primary alsa driver code base
+ *             for Intel HD Audio of Phytium.
+ *
+ *  Copyright(c) 2018 Phytium Corporation. All rights reserved.
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the Free
+ *  Software Foundation; either version 2 of the License, or (at your option)
+ *  any later version.
+ *
+ *  This program is distributed in the hope that it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ *  more details.
+ */
+
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/dma-mapping.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/mutex.h>
+#include <linux/io.h>
+#include <linux/pm_runtime.h>
+#include <linux/clocksource.h>
+#include <linux/time.h>
+#include <linux/completion.h>
+#include <linux/of_device.h>
+#include <sound/core.h>
+#include <sound/initval.h>
+#include <sound/hdaudio.h>
+#include <sound/hda_i915.h>
+#include <linux/vgaarb.h>
+#include <linux/vga_switcheroo.h>
+#include <linux/firmware.h>
+#include <linux/acpi.h>
+#include "hda_codec.h"
+#include "hda_controller.h"
+#include "hda_phytium.h"
+
+#include "hda_intel_trace.h"
+
+/* position fix mode */
+enum {
+	POS_FIX_AUTO,
+	POS_FIX_LPIB,
+	POS_FIX_POSBUF,
+	POS_FIX_VIACOMBO,
+	POS_FIX_COMBO,
+};
+
+/* Define IN stream 0 FIFO size offset in VIA controller */
+#define VIA_IN_STREAM0_FIFO_SIZE_OFFSET	0x90
+
+/* FT have 4 playback and 4 capture */
+#define FT4C_NUM_CAPTURE	4
+#define FT4C_NUM_PLAYBACK	4
+
+#define DWORD_BYTE_WIDTH 4
+#define BYTE_BIT_WIDTH   8
+
+static int index[SNDRV_CARDS] = SNDRV_DEFAULT_IDX;
+static char *id[SNDRV_CARDS] = SNDRV_DEFAULT_STR;
+static bool enable[SNDRV_CARDS] = SNDRV_DEFAULT_ENABLE_PNP;
+static char *model[SNDRV_CARDS];
+static int position_fix[SNDRV_CARDS] = {[0 ... (SNDRV_CARDS-1)] = 1};
+static int bdl_pos_adj[SNDRV_CARDS] = {[0 ... (SNDRV_CARDS-1)] = -1};
+static int probe_mask[SNDRV_CARDS] = {[0 ... (SNDRV_CARDS-1)] = -1};
+static int probe_only[SNDRV_CARDS];
+static int jackpoll_ms[SNDRV_CARDS];
+static int single_cmd = -1;
+static int enable_msi = -1;
+#ifdef CONFIG_SND_HDA_INPUT_BEEP
+static bool beep_mode[SNDRV_CARDS] = {[0 ... (SNDRV_CARDS-1)] =
+					CONFIG_SND_HDA_INPUT_BEEP_MODE};
+#endif
+
+module_param_array(index, int, NULL, 0444);
+MODULE_PARM_DESC(index, "Index value for Intel HD audio interface.");
+module_param_array(id, charp, NULL, 0444);
+MODULE_PARM_DESC(id, "ID string for Intel HD audio interface.");
+module_param_array(enable, bool, NULL, 0444);
+MODULE_PARM_DESC(enable, "Enable Intel HD audio interface.");
+module_param_array(model, charp, NULL, 0444);
+MODULE_PARM_DESC(model, "Use the given board model.");
+module_param_array(position_fix, int, NULL, 0444);
+MODULE_PARM_DESC(position_fix, "DMA pointer read method."
+		 "(-1 = system default, 0 = auto, 1 = LPIB, 2 = POSBUF, 3 = VIACOMBO, 4 = COMBO).");
+module_param_array(bdl_pos_adj, int, NULL, 0644);
+MODULE_PARM_DESC(bdl_pos_adj, "BDL position adjustment offset.");
+module_param_array(probe_mask, int, NULL, 0444);
+MODULE_PARM_DESC(probe_mask, "Bitmask to probe codecs (default = -1).");
+module_param_array(probe_only, int, NULL, 0444);
+MODULE_PARM_DESC(probe_only, "Only probing and no codec initialization.");
+module_param_array(jackpoll_ms, int, NULL, 0444);
+MODULE_PARM_DESC(jackpoll_ms, "Ms between polling for jack events (default = 0, using unsol events only)");
+module_param(single_cmd, bint, 0444);
+MODULE_PARM_DESC(single_cmd, "Use single command to communicate with codecs "
+		 "(for debugging only).");
+module_param(enable_msi, bint, 0444);
+MODULE_PARM_DESC(enable_msi, "Enable Message Signaled Interrupt (MSI)");
+#ifdef CONFIG_SND_HDA_INPUT_BEEP
+module_param_array(beep_mode, bool, NULL, 0444);
+MODULE_PARM_DESC(beep_mode, "Select HDA Beep registration mode "
+			    "(0=off, 1=on) (default=1).");
+#endif
+
+#define power_save 0
+
+static int align_buffer_size = -1;
+module_param(align_buffer_size, bint, 0644);
+MODULE_PARM_DESC(align_buffer_size,
+		"Force buffer and period sizes to be multiple of 128 bytes.");
+
+/* driver types */
+enum {
+	AZX_DRIVER_ICH,
+	AZX_DRIVER_PCH,
+	AZX_DRIVER_SCH,
+	AZX_DRIVER_HDMI,
+	AZX_DRIVER_ATI,
+	AZX_DRIVER_ATIHDMI,
+	AZX_DRIVER_ATIHDMI_NS,
+	AZX_DRIVER_VIA,
+	AZX_DRIVER_SIS,
+	AZX_DRIVER_ULI,
+	AZX_DRIVER_NVIDIA,
+	AZX_DRIVER_TERA,
+	AZX_DRIVER_CTX,
+	AZX_DRIVER_CTHDA,
+	AZX_DRIVER_CMEDIA,
+	AZX_DRIVER_GENERIC,
+	AZX_DRIVER_FT,
+	AZX_NUM_DRIVERS, /* keep this as last entry */
+};
+
+/* NOP for other archs */
+static inline void mark_pages_wc(struct azx *chip, struct snd_dma_buffer *buf,
+				 bool on)
+{
+}
+
+static inline void mark_runtime_wc(struct azx *chip, struct azx_dev *azx_dev,
+				   struct snd_pcm_substream *substream, bool on)
+{
+}
+
+static int azx_acquire_irq(struct azx *chip, int do_disconnect);
+
+/* calculate runtime delay from LPIB */
+static int azx_get_delay_from_lpib(struct azx *chip, struct azx_dev *azx_dev,
+				   unsigned int pos)
+{
+	struct snd_pcm_substream *substream = azx_dev->core.substream;
+	int stream = substream->stream;
+	unsigned int lpib_pos = azx_get_pos_lpib(chip, azx_dev);
+	int delay;
+
+	if (stream == SNDRV_PCM_STREAM_PLAYBACK)
+		delay = pos - lpib_pos;
+	else
+		delay = lpib_pos - pos;
+	if (delay < 0) {
+		if (delay >= azx_dev->core.delay_negative_threshold)
+			delay = 0;
+		else
+			delay += azx_dev->core.bufsize;
+	}
+
+	if (delay >= azx_dev->core.period_bytes) {
+		dev_info(chip->card->dev,
+			 "Unstable LPIB (%d >= %d); disabling LPIB delay counting\n",
+			 delay, azx_dev->core.period_bytes);
+		delay = 0;
+		chip->driver_caps &= ~AZX_DCAPS_COUNT_LPIB_DELAY;
+		chip->get_delay[stream] = NULL;
+	}
+
+	return bytes_to_frames(substream->runtime, delay);
+}
+
+static int azx_position_ok(struct azx *chip, struct azx_dev *azx_dev);
+
+/* called from IRQ */
+static int azx_position_check(struct azx *chip, struct azx_dev *azx_dev)
+{
+	struct hda_ft *hda = container_of(chip, struct hda_ft, chip);
+	int ok;
+
+	ok = azx_position_ok(chip, azx_dev);
+	if (ok == 1) {
+		azx_dev->irq_pending = 0;
+		return ok;
+	} else if (ok == 0) {
+		/* bogus IRQ, process it later */
+		azx_dev->irq_pending = 1;
+		schedule_work(&hda->irq_pending_work);
+	}
+	return 0;
+}
+
+static int azx_ft_link_power(struct azx *chip, bool enable)
+{
+	return 0;
+}
+
+/*
+ * Check whether the current DMA position is acceptable for updating
+ * periods.  Returns non-zero if it's OK.
+ *
+ * Many HD-audio controllers appear pretty inaccurate about
+ * the update-IRQ timing.  The IRQ is issued before actually the
+ * data is processed.  So, we need to process it afterwords in a
+ * workqueue.
+ */
+static int azx_position_ok(struct azx *chip, struct azx_dev *azx_dev)
+{
+	struct snd_pcm_substream *substream = azx_dev->core.substream;
+	int stream = substream->stream;
+	u32 wallclk;
+	unsigned int pos;
+
+	wallclk = (azx_readl(chip, WALLCLK) - azx_dev->core.start_wallclk);
+
+	if (wallclk < (azx_dev->core.period_wallclk * 2) / 3)
+		return -1;	/* bogus (too early) interrupt */
+
+	if (chip->get_position[stream])
+		pos = chip->get_position[stream](chip, azx_dev);
+	else { /* use the position buffer as default */
+		pos = azx_get_pos_posbuf(chip, azx_dev);
+		if (!pos || pos == (u32)-1) {
+			dev_info(chip->card->dev,
+				 "Invalid position buffer, using LPIB read method instead.\n");
+			chip->get_position[stream] = azx_get_pos_lpib;
+			if (chip->get_position[0] == azx_get_pos_lpib &&
+			    chip->get_position[1] == azx_get_pos_lpib)
+				azx_bus(chip)->use_posbuf = false;
+			pos = azx_get_pos_lpib(chip, azx_dev);
+			chip->get_delay[stream] = NULL;
+		} else {
+			chip->get_position[stream] = azx_get_pos_posbuf;
+			if (chip->driver_caps & AZX_DCAPS_COUNT_LPIB_DELAY)
+				chip->get_delay[stream] = azx_get_delay_from_lpib;
+		}
+	}
+
+	if (pos >= azx_dev->core.bufsize)
+		pos = 0;
+
+	if (WARN_ONCE(!azx_dev->core.period_bytes,
+		      "hda-ft: zero azx_dev->period_bytes"))
+		return -1; /* this shouldn't happen! */
+	if (wallclk < (azx_dev->core.period_wallclk * 5) / 4 &&
+	    pos % azx_dev->core.period_bytes > azx_dev->core.period_bytes / 2)
+		/* NG - it's below the first next period boundary */
+		return chip->bdl_pos_adj ? 0 : -1;
+
+	azx_dev->core.start_wallclk += wallclk;
+
+	return 1; /* OK, it's fine */
+}
+
+/* The work for pending PCM period updates. */
+static void azx_irq_pending_work(struct work_struct *work)
+{
+	struct hda_ft *hda = container_of(work, struct hda_ft, irq_pending_work);
+	struct azx *chip = &hda->chip;
+	struct hdac_bus *bus = azx_bus(chip);
+	struct hdac_stream *s;
+	int pending, ok;
+
+	if (!hda->irq_pending_warned) {
+		dev_info(chip->card->dev,
+			 "IRQ timing workaround is activated for card #%d. Suggest a bigger bdl_pos_adj.\n",
+			 chip->card->number);
+		hda->irq_pending_warned = 1;
+	}
+
+	for (;;) {
+		pending = 0;
+		spin_lock_irq(&bus->reg_lock);
+		list_for_each_entry(s, &bus->stream_list, list) {
+			struct azx_dev *azx_dev = stream_to_azx_dev(s);
+			if (!azx_dev->irq_pending ||
+			    !s->substream ||
+			    !s->running)
+				continue;
+			ok = azx_position_ok(chip, azx_dev);
+			if (ok > 0) {
+				azx_dev->irq_pending = 0;
+				spin_unlock(&bus->reg_lock);
+				snd_pcm_period_elapsed(s->substream);
+				spin_lock(&bus->reg_lock);
+			} else if (ok < 0) {
+				pending = 0;	/* too early */
+			} else
+				pending++;
+		}
+		spin_unlock_irq(&bus->reg_lock);
+		if (!pending)
+			return;
+		msleep(1);
+	}
+}
+
+/* clear irq_pending flags and assure no on-going workq */
+static void azx_clear_irq_pending(struct azx *chip)
+{
+	struct hdac_bus *bus = azx_bus(chip);
+	struct hdac_stream *s;
+
+	spin_lock_irq(&bus->reg_lock);
+	list_for_each_entry(s, &bus->stream_list, list) {
+		struct azx_dev *azx_dev = stream_to_azx_dev(s);
+		azx_dev->irq_pending = 0;
+	}
+	spin_unlock_irq(&bus->reg_lock);
+}
+
+static int azx_acquire_irq(struct azx *chip, int do_disconnect)
+{
+	struct hdac_bus *bus = azx_bus(chip);
+
+	struct hda_ft *hda = container_of(chip, struct hda_ft, chip);
+	struct platform_device *pdev = to_platform_device(hda->dev);
+	int irq_id = platform_get_irq(pdev, 0);
+	int err;
+
+	err = devm_request_irq(chip->card->dev, irq_id, azx_interrupt,
+			     IRQF_SHARED, KBUILD_MODNAME, chip);
+	if (err) {
+		dev_err(chip->card->dev,
+			"unable to request IRQ %d, disabling device\n",
+			irq_id);
+		if (do_disconnect)
+			snd_card_disconnect(chip->card);
+		return err;
+	}
+	bus->irq = irq_id;
+
+	return 0;
+}
+
+/* get the current DMA position with correction on VIA chips */
+static unsigned int azx_via_get_position(struct azx *chip,
+					 struct azx_dev *azx_dev)
+{
+	unsigned int link_pos, mini_pos, bound_pos;
+	unsigned int mod_link_pos, mod_dma_pos, mod_mini_pos;
+	unsigned int fifo_size;
+
+	link_pos = snd_hdac_stream_get_pos_lpib(azx_stream(azx_dev));
+	if (azx_dev->core.substream->stream == SNDRV_PCM_STREAM_PLAYBACK) {
+		/* Playback, no problem using link position */
+		return link_pos;
+	}
+
+	/* Capture */
+	/* For new chipset,
+	 * use mod to get the DMA position just like old chipset
+	 */
+	mod_dma_pos = le32_to_cpu(*azx_dev->core.posbuf);
+	mod_dma_pos %= azx_dev->core.period_bytes;
+
+	/* azx_dev->fifo_size can't get FIFO size of in stream.
+	 * Get from base address + offset.
+	 */
+	fifo_size = readw(azx_bus(chip)->remap_addr +
+			  VIA_IN_STREAM0_FIFO_SIZE_OFFSET);
+
+	if (azx_dev->insufficient) {
+		/* Link position never gather than FIFO size */
+		if (link_pos <= fifo_size)
+			return 0;
+
+		azx_dev->insufficient = 0;
+	}
+
+	if (link_pos <= fifo_size)
+		mini_pos = azx_dev->core.bufsize + link_pos - fifo_size;
+	else
+		mini_pos = link_pos - fifo_size;
+
+	/* Find nearest previous boudary */
+	mod_mini_pos = mini_pos % azx_dev->core.period_bytes;
+	mod_link_pos = link_pos % azx_dev->core.period_bytes;
+	if (mod_link_pos >= fifo_size)
+		bound_pos = link_pos - mod_link_pos;
+	else if (mod_dma_pos >= mod_mini_pos)
+		bound_pos = mini_pos - mod_mini_pos;
+	else {
+		bound_pos = mini_pos - mod_mini_pos + azx_dev->core.period_bytes;
+		if (bound_pos >= azx_dev->core.bufsize)
+			bound_pos = 0;
+	}
+
+	/* Calculate real DMA position we want */
+	return bound_pos + mod_dma_pos;
+}
+
+#ifdef CONFIG_PM
+static DEFINE_MUTEX(card_list_lock);
+static LIST_HEAD(card_list);
+
+static void azx_add_card_list(struct azx *chip)
+{
+	struct hda_ft *hda = container_of(chip, struct hda_ft, chip);
+	mutex_lock(&card_list_lock);
+	list_add(&hda->list, &card_list);
+	mutex_unlock(&card_list_lock);
+}
+
+static void azx_del_card_list(struct azx *chip)
+{
+	struct hda_ft *hda = container_of(chip, struct hda_ft, chip);
+	mutex_lock(&card_list_lock);
+	list_del_init(&hda->list);
+	mutex_unlock(&card_list_lock);
+}
+
+#else
+#define azx_add_card_list(chip) /* NOP */
+#define azx_del_card_list(chip) /* NOP */
+#endif /* CONFIG_PM */
+
+#if defined(CONFIG_PM_SLEEP)
+/* power management */
+static int azx_suspend(struct device *dev)
+{
+	struct snd_card *card = dev_get_drvdata(dev);
+	struct azx *chip;
+	struct hda_ft *hda;
+	struct hdac_bus *bus;
+
+	if (!card)
+		return 0;
+
+	chip = card->private_data;
+	hda = container_of(chip, struct hda_ft, chip);
+	if (chip->disabled || !chip->running)
+		return 0;
+
+	bus = azx_bus(chip);
+	snd_power_change_state(card, SNDRV_CTL_POWER_D3hot);
+	azx_clear_irq_pending(chip);
+	azx_stop_chip(chip);
+	azx_enter_link_reset(chip);
+	if (bus->irq >= 0) {
+		free_irq(bus->irq, chip);
+		bus->irq = -1;
+	}
+
+	return 0;
+}
+
+static int azx_resume(struct device *dev)
+{
+	struct snd_card *card = dev_get_drvdata(dev);
+	struct azx *chip;
+	struct hda_ft *hda;
+	struct hdac_bus *bus;
+	int index;
+	struct snd_pcm_substream *substream;
+	struct azx_dev *azx_dev;
+	int err;
+
+	if (!card)
+		return 0;
+
+	chip = card->private_data;
+	hda = container_of(chip, struct hda_ft, chip);
+	bus = azx_bus(chip);
+	if (chip->disabled || !chip->running)
+		return 0;
+
+	if (azx_acquire_irq(chip, 1) < 0)
+		return -EIO;
+
+	index = chip->dev_index;
+	azx_init_chip(chip, (probe_only[index] & 2) == 0);
+
+	snd_power_change_state(card, SNDRV_CTL_POWER_D0);
+
+	if(hda->substream){
+		substream = hda->substream;
+
+		if(substream->runtime->status->state == SNDRV_PCM_STATE_SUSPENDED){
+			substream->runtime->status->state = substream->runtime->status->suspended_state;
+			err = substream->ops->prepare(substream);
+			if (err < 0)
+			return err;
+		}
+
+		azx_dev = get_azx_dev(substream);
+		snd_hdac_stream_start(azx_stream(azx_dev), true);
+		hda->substream = NULL;
+	}
+
+	return 0;
+}
+#endif /* CONFIG_PM_SLEEP */
+
+#ifdef CONFIG_PM
+static int azx_runtime_suspend(struct device *dev)
+{
+	struct snd_card *card = dev_get_drvdata(dev);
+	struct azx *chip;
+	struct hda_ft *hda;
+
+	if (!card)
+		return 0;
+
+	chip = card->private_data;
+	hda = container_of(chip, struct hda_ft, chip);
+	if (chip->disabled)
+		return 0;
+
+	if (!azx_has_pm_runtime(chip))
+		return 0;
+
+	azx_stop_chip(chip);
+	azx_enter_link_reset(chip);
+	azx_clear_irq_pending(chip);
+
+	return 0;
+}
+
+static int azx_runtime_resume(struct device *dev)
+{
+	struct snd_card *card = dev_get_drvdata(dev);
+	struct azx *chip;
+	struct hda_ft *hda;
+	struct hdac_bus *bus;
+	struct hda_codec *codec;
+	int status;
+	int index;
+
+	if (!card)
+		return 0;
+
+	chip = card->private_data;
+	hda = container_of(chip, struct hda_ft, chip);
+	bus = azx_bus(chip);
+	if (chip->disabled)
+		return 0;
+
+	if (!azx_has_pm_runtime(chip))
+		return 0;
+
+	/* Read STATESTS before controller reset */
+	status = azx_readw(chip, STATESTS);
+
+	index = chip->dev_index;
+	azx_init_chip(chip, (probe_only[index] & 2) == 0);
+
+	if (status) {
+		list_for_each_codec(codec, &chip->bus)
+			if (status & (1 << codec->addr))
+				schedule_delayed_work(&codec->jackpoll_work,
+						      codec->jackpoll_interval);
+	}
+
+	return 0;
+}
+
+static int azx_runtime_idle(struct device *dev)
+{
+	struct snd_card *card = dev_get_drvdata(dev);
+	struct azx *chip;
+	struct hda_ft *hda;
+
+	if (!card)
+		return 0;
+
+	chip = card->private_data;
+	hda = container_of(chip, struct hda_ft, chip);
+	if (chip->disabled)
+		return 0;
+
+	if (!azx_has_pm_runtime(chip) ||
+	    azx_bus(chip)->codec_powered || !chip->running)
+		return -EBUSY;
+
+	return 0;
+}
+
+static const struct dev_pm_ops azx_pm = {
+	SET_SYSTEM_SLEEP_PM_OPS(azx_suspend, azx_resume)
+	SET_RUNTIME_PM_OPS(azx_runtime_suspend, azx_runtime_resume, azx_runtime_idle)
+};
+
+#define hda_ft_pm	&azx_pm
+#else
+#define hda_ft_pm	NULL
+#endif /* CONFIG_PM */
+
+static int azx_probe_continue(struct azx *chip);
+
+/*
+ * destructor
+ */
+static int azx_free(struct azx *chip)
+{
+	struct hda_ft *hda = container_of(chip, struct hda_ft, chip);
+	struct hdac_bus *bus = azx_bus(chip);
+	struct platform_device *pdev = to_platform_device(hda->dev);
+	struct device *hddev = hda->dev;
+	struct resource *res;
+	resource_size_t size;
+
+	if (azx_has_pm_runtime(chip) && chip->running)
+		pm_runtime_get_noresume(&pdev->dev);
+
+	azx_del_card_list(chip);
+
+	complete_all(&hda->probe_wait);
+
+	if (bus->chip_init) {
+		azx_clear_irq_pending(chip);
+		azx_stop_all_streams(chip);
+		azx_stop_chip(chip);
+	}
+
+	if (bus->irq >= 0)
+		free_irq(bus->irq, (void*)chip);
+
+	devm_iounmap(hddev, bus->remap_addr);
+
+	azx_free_stream_pages(chip);
+	azx_free_streams(chip);
+	snd_hdac_bus_exit(bus);
+
+	if (chip->region_requested){
+		res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+		size = resource_size(res);
+		devm_release_mem_region(hddev, res->start, size);
+	}
+
+	kfree(hda);
+
+	return 0;
+}
+
+static int azx_dev_disconnect(struct snd_device *device)
+{
+	struct azx *chip = device->device_data;
+
+	chip->bus.shutdown = 1;
+	return 0;
+}
+
+static int azx_dev_free(struct snd_device *device)
+{
+	return azx_free(device->device_data);
+}
+
+static int check_position_fix(struct azx *chip, int fix)
+{
+	switch (fix) {
+	case POS_FIX_AUTO:
+	case POS_FIX_LPIB:
+	case POS_FIX_POSBUF:
+	case POS_FIX_VIACOMBO:
+	case POS_FIX_COMBO:
+		return fix;
+	}
+
+	if (chip->driver_caps & AZX_DCAPS_POSFIX_LPIB) {
+		dev_dbg(chip->card->dev, "Using LPIB position fix\n");
+		return POS_FIX_LPIB;
+	}
+	return POS_FIX_AUTO;
+}
+
+static void assign_position_fix(struct azx *chip, int fix)
+{
+	static azx_get_pos_callback_t callbacks[] = {
+		[POS_FIX_AUTO] = NULL,
+		[POS_FIX_LPIB] = azx_get_pos_lpib,
+		[POS_FIX_POSBUF] = azx_get_pos_posbuf,
+		[POS_FIX_VIACOMBO] = azx_via_get_position,
+		[POS_FIX_COMBO] = azx_get_pos_lpib,
+	};
+
+	chip->get_position[0] = chip->get_position[1] = callbacks[fix];
+
+	/* combo mode uses LPIB only for playback */
+	if (fix == POS_FIX_COMBO)
+		chip->get_position[1] = NULL;
+
+	if (fix == POS_FIX_POSBUF &&
+	    (chip->driver_caps & AZX_DCAPS_COUNT_LPIB_DELAY)) {
+		chip->get_delay[0] = chip->get_delay[1] =
+			azx_get_delay_from_lpib;
+	}
+
+}
+
+#define AZX_FORCE_CODEC_MASK	0x100
+
+static void check_probe_mask(struct azx *chip, int dev)
+{
+	chip->codec_probe_mask = probe_mask[dev];
+
+	/* check forced option */
+	if (chip->codec_probe_mask != -1 &&
+	    (chip->codec_probe_mask & AZX_FORCE_CODEC_MASK)) {
+		azx_bus(chip)->codec_mask = chip->codec_probe_mask & 0xff;
+		dev_info(chip->card->dev, "codec_mask forced to 0x%x\n",
+			 (int)azx_bus(chip)->codec_mask);
+	}
+}
+
+static void azx_probe_work(struct work_struct *work)
+{
+	struct hda_ft *hda = container_of(work, struct hda_ft, probe_work);
+	azx_probe_continue(&hda->chip);
+}
+
+/*
+ * constructor
+ */
+static const struct hdac_io_ops axi_hda_io_ops;
+static const struct hda_controller_ops axi_hda_ops;
+
+static int hda_ft_create(struct snd_card *card, struct platform_device *pdev,
+			int dev, unsigned int driver_caps,
+			struct azx **rchip)
+{
+	static struct snd_device_ops ops = {
+		.dev_disconnect = azx_dev_disconnect,
+		.dev_free = azx_dev_free,
+	};
+	struct hda_ft *hda;
+	struct azx *chip;
+	int err;
+
+	*rchip = NULL;
+
+	hda = devm_kzalloc(&pdev->dev, sizeof(*hda), GFP_KERNEL);
+	if (!hda)
+		return -ENOMEM;
+	hda->dev = &pdev->dev;
+	chip = &hda->chip;
+	mutex_init(&chip->open_mutex);
+	chip->card = card;
+	chip->ops = &axi_hda_ops;
+	chip->driver_caps = driver_caps;
+	chip->driver_type = driver_caps & 0xff;
+	chip->dev_index = dev;
+	chip->jackpoll_ms = jackpoll_ms;
+	INIT_LIST_HEAD(&chip->pcm_list);
+	INIT_WORK(&hda->irq_pending_work, azx_irq_pending_work);
+	INIT_LIST_HEAD(&hda->list);
+
+	init_completion(&hda->probe_wait);
+	assign_position_fix(chip, check_position_fix(chip, position_fix[dev]));
+	check_probe_mask(chip, dev);
+
+	if (single_cmd < 0) /* allow fallback to single_cmd at errors */
+		chip->fallback_to_single_cmd = 1;
+	else /* explicitly set to single_cmd or not */
+		chip->single_cmd = single_cmd;
+
+	if (bdl_pos_adj[dev] < 0) {
+		switch (chip->driver_type) {
+		case AZX_DRIVER_FT:
+			bdl_pos_adj[dev] = 32;
+			break;
+		default:
+			bdl_pos_adj[dev] = 32;
+			break;
+		}
+	}
+	chip->bdl_pos_adj = bdl_pos_adj[dev];
+
+	err = azx_bus_init(chip, model[dev], &axi_hda_io_ops);
+	if (err < 0) {
+		kfree(hda);
+		return err;
+	}
+
+	if (chip->driver_type == AZX_DRIVER_NVIDIA) {
+		dev_dbg(chip->card->dev, "Enable delay in RIRB handling\n");
+		chip->bus.needs_damn_long_delay = 1;
+	}
+
+	err = snd_device_new(card, SNDRV_DEV_LOWLEVEL, chip, &ops);
+	if (err < 0) {
+		dev_err(card->dev, "Error creating device [card]!\n");
+		azx_free(chip);
+		return err;
+	}
+
+	/* continue probing in work context as may trigger request module */
+	INIT_WORK(&hda->probe_work, azx_probe_work);
+
+	*rchip = chip;
+
+	return 0;
+}
+
+static int azx_first_init(struct azx *chip)
+{
+	struct hda_ft *hda = container_of(chip, struct hda_ft, chip);
+	struct platform_device *pdev = to_platform_device(hda->dev);
+	struct device *hddev = hda->dev;
+
+	int dev = chip->dev_index;
+	struct snd_card *card = chip->card;
+	struct hdac_bus *bus = azx_bus(chip);
+	int err;
+	unsigned short gcap;
+	unsigned int dma_bits = 64;
+
+	struct resource *res;
+	const struct acpi_device_id *match;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	hda->regs = devm_ioremap_resource(hddev, res);
+	if (IS_ERR(hda->regs))
+		return PTR_ERR(hda->regs);
+	chip->region_requested = 1;
+
+	bus->corbrp_self_clear = 0;
+
+	bus->addr = res->start;
+	bus->remap_addr = hda->regs;
+	if (bus->remap_addr == NULL) {
+		dev_err(card->dev, "ioremap error\n");
+		return -ENXIO;
+	}
+
+	if (azx_acquire_irq(chip, 0) < 0)
+		return -EBUSY;
+
+	synchronize_irq(bus->irq);
+
+	gcap = azx_readw(chip, GCAP);
+	dev_dbg(card->dev, "chipset global capabilities = 0x%x\n", gcap);
+
+	/* disable 64bit DMA address on some devices */
+	if (chip->driver_caps & AZX_DCAPS_NO_64BIT) {
+		dev_dbg(card->dev, "Disabling 64bit DMA\n");
+		gcap &= ~AZX_GCAP_64OK;
+	}
+
+	/* disable buffer size rounding to 128-byte multiples if supported */
+	if (align_buffer_size >= 0)
+		chip->align_buffer_size = !!align_buffer_size;
+	else {
+		if (chip->driver_caps & AZX_DCAPS_NO_ALIGN_BUFSIZE)
+			chip->align_buffer_size = 0;
+		else
+			chip->align_buffer_size = 1;
+	}
+
+	if (hddev->of_node) {
+
+	} else if (has_acpi_companion(hddev)){
+		match = acpi_match_device(hddev->driver->acpi_match_table, hddev);
+		if (!match) {
+			dev_err(card->dev, "Error ACPI match data is missing\n");
+			return -ENODEV;
+		}
+		acpi_dma_configure(hddev,DEV_DMA_NOT_SUPPORTED);
+	}
+
+	/* allow 64bit DMA address if supported by H/W */
+	if (!(gcap & AZX_GCAP_64OK))
+		dma_bits = 32;
+	if (!dma_set_mask(hddev, DMA_BIT_MASK(dma_bits))) {
+		dma_set_coherent_mask(hddev, DMA_BIT_MASK(dma_bits));
+	} else {
+		dma_set_mask(hddev, DMA_BIT_MASK(32));
+		dma_set_coherent_mask(hddev, DMA_BIT_MASK(32));
+	}
+
+	/* read number of streams from GCAP register instead of using
+	 * hardcoded value
+	 */
+	chip->capture_streams = (gcap >> 8) & 0x0f;
+	chip->playback_streams = (gcap >> 12) & 0x0f;
+	if (!chip->playback_streams && !chip->capture_streams) {
+		/* gcap didn't give any info, switching to old method */
+		chip->playback_streams = FT4C_NUM_PLAYBACK;
+		chip->capture_streams  = FT4C_NUM_CAPTURE;
+	}
+	chip->capture_index_offset = 0;
+	chip->playback_index_offset = chip->capture_streams;
+	chip->num_streams = chip->playback_streams + chip->capture_streams;
+
+	/* initialize streams */
+	err = azx_init_streams(chip);
+	if (err < 0)
+		return err;
+
+	err = azx_alloc_stream_pages(chip);
+	if (err < 0)
+		return err;
+
+	azx_init_chip(chip, (probe_only[dev] & 2) == 0);
+#define AZX_REG_INTMODE	0x230
+	snd_hdac_chip_writel(bus, INTMODE, 0XFF1);
+
+	/* codec detection */
+	if (!azx_bus(chip)->codec_mask) {
+		dev_err(card->dev, "no codecs found!\n");
+		return -ENODEV;
+	}
+
+	strcpy(card->driver, "ft-hda");
+	strcpy(card->shortname, "ft-hda");
+	snprintf(card->longname, sizeof(card->longname),
+		 "%s at 0x%lx irq %i",
+		 card->shortname, bus->addr, bus->irq);
+
+	return 0;
+}
+
+/*
+ * HDA controller ops.
+ */
+
+/* APB register access. */
+static void axi_azx_writel(u32 value, u32 __iomem *addr)
+{
+	writel(value, addr);
+}
+
+static u32 axi_azx_readl(u32 __iomem *addr)
+{
+	return readl(addr);
+}
+
+static void axi_azx_writew(u16 value, u16 __iomem *addr)
+{
+	u32 data;
+	u32 offset;
+
+	offset = (u64)addr & 0x03;
+	addr  = (u16 __iomem *)((u64)addr & 0xFFFFFFFFFFFFFFFC);
+	data = readl(addr);
+	data &= ~(0xFFFF << offset * BYTE_BIT_WIDTH);
+	data |= (value << offset * BYTE_BIT_WIDTH);
+	writel(data, addr);
+}
+
+static u16 axi_azx_readw(u16 __iomem *addr)
+{
+	return readw(addr);
+}
+
+static void axi_azx_writeb(u8 value, u8 __iomem *addr)
+{
+	u32 data;
+	u32 offset;
+
+	offset = (u64)addr & 0x03;
+	addr  = (u8 __iomem *)((u64)addr & 0xFFFFFFFFFFFFFFFC);
+	data = readl(addr);
+	data &= ~(0xFF << offset * BYTE_BIT_WIDTH);
+	data |= (value << offset * BYTE_BIT_WIDTH);
+	writel(data, addr);
+}
+
+static u8 axi_azx_readb(u8 __iomem *addr)
+{
+	return readb(addr);
+}
+
+/* DMA page allocation helpers.  */
+static int dma_alloc_pages(struct hdac_bus *bus,
+			   int type,
+			   size_t size,
+			   struct snd_dma_buffer *buf)
+{
+	struct azx *chip = bus_to_azx(bus);
+	int err;
+
+	err = snd_dma_alloc_pages(type,
+				  bus->dev,
+				  size, buf);
+	if (err < 0)
+		return err;
+	mark_pages_wc(chip, buf, true);
+	return 0;
+}
+
+static void dma_free_pages(struct hdac_bus *bus, struct snd_dma_buffer *buf)
+{
+	struct azx *chip = bus_to_azx(bus);
+
+	mark_pages_wc(chip, buf, false);
+	snd_dma_free_pages(buf);
+}
+
+static int substream_alloc_pages(struct azx *chip,
+				 struct snd_pcm_substream *substream,
+				 size_t size)
+{
+	struct azx_dev *azx_dev = get_azx_dev(substream);
+	int ret;
+
+	mark_runtime_wc(chip, azx_dev, substream, false);
+	ret = snd_pcm_lib_malloc_pages(substream, size);
+	if (ret < 0)
+		return ret;
+
+	mark_runtime_wc(chip, azx_dev, substream, true);
+	return 0;
+}
+
+static int substream_free_pages(struct azx *chip,
+				struct snd_pcm_substream *substream)
+{
+	struct azx_dev *azx_dev = get_azx_dev(substream);
+	mark_runtime_wc(chip, azx_dev, substream, false);
+	return snd_pcm_lib_free_pages(substream);
+}
+
+static void pcm_mmap_prepare(struct snd_pcm_substream *substream,
+			     struct vm_area_struct *area)
+{
+
+}
+
+static const struct hdac_io_ops axi_hda_io_ops = {
+	.reg_writel = axi_azx_writel,
+	.reg_readl = axi_azx_readl,
+	.reg_writew = axi_azx_writew,
+	.reg_readw = axi_azx_readw,
+	.reg_writeb = axi_azx_writeb,
+	.reg_readb = axi_azx_readb,
+	.dma_alloc_pages = dma_alloc_pages,
+	.dma_free_pages = dma_free_pages,
+};
+
+static const struct hda_controller_ops axi_hda_ops = {
+	.substream_alloc_pages = substream_alloc_pages,
+	.substream_free_pages = substream_free_pages,
+	.pcm_mmap_prepare = pcm_mmap_prepare,
+	.position_check = azx_position_check,
+	.link_power = azx_ft_link_power,
+};
+
+static int hda_ft_probe(struct platform_device *pdev)
+{
+	const unsigned int driver_flags = AZX_DCAPS_CORBRP_SELF_CLEAR | AZX_DRIVER_FT;
+	static int dev;
+	struct snd_card *card;
+	struct hda_ft *hda;
+	struct azx *chip;
+	bool schedule_probe;
+	int err;
+
+	if (dev >= SNDRV_CARDS)
+		return -ENODEV;
+	if (!enable[dev]) {
+		dev++;
+		return -ENOENT;
+	}
+
+	err = snd_card_new(&pdev->dev, index[dev], id[dev], THIS_MODULE,
+			   0, &card);
+	if (err < 0) {
+		dev_err(&pdev->dev, "Error creating card!\n");
+		return err;
+	}
+
+	err = hda_ft_create(card, pdev,dev, driver_flags, &chip);
+	if (err < 0)
+		goto out_free;
+	card->private_data = chip;
+	hda = container_of(chip, struct hda_ft, chip);
+
+	dev_set_drvdata(&pdev->dev, card);
+
+	schedule_probe = !chip->disabled;
+
+	if (schedule_probe)
+		schedule_work(&hda->probe_work);
+
+	dev++;
+	if (chip->disabled)
+		complete_all(&hda->probe_wait);
+	return 0;
+
+out_free:
+	snd_card_free(card);
+	return err;
+}
+
+/* number of codec slots for each chipset: 0 = default slots (i.e. 4) */
+static unsigned int azx_max_codecs[AZX_NUM_DRIVERS] = {
+	[AZX_DRIVER_FT] = 4,
+};
+
+static int azx_probe_continue(struct azx *chip)
+{
+	struct hda_ft *hda = container_of(chip, struct hda_ft, chip);
+	struct device *hddev = hda->dev;
+	int dev = chip->dev_index;
+	int err;
+
+	hda->probe_continued = 1;
+
+	err = azx_first_init(chip);
+	if (err < 0)
+		goto out_free;
+
+#ifdef CONFIG_SND_HDA_INPUT_BEEP
+	chip->beep_mode = beep_mode[dev];
+#endif
+
+	/* create codec instances */
+	err = azx_probe_codecs(chip, azx_max_codecs[chip->driver_type]);
+	if (err < 0)
+		goto out_free;
+
+	if ((probe_only[dev] & 1) == 0) {
+		err = azx_codec_configure(chip);
+		if (err < 0)
+			goto out_free;
+	}
+
+	err = snd_card_register(chip->card);
+	if (err < 0)
+		goto out_free;
+
+	chip->running = 1;
+	azx_add_card_list(chip);
+	snd_hda_set_power_save(&chip->bus, power_save * 1000);
+
+	if (azx_has_pm_runtime(chip))
+			pm_runtime_put_noidle(hddev);
+
+out_free:
+	return err;
+}
+
+static int hda_ft_remove(struct platform_device *pdev)
+{
+	struct snd_card *card = dev_get_drvdata(&pdev->dev);
+	struct azx *chip;
+	struct hda_ft *hda;
+
+	if (card) {
+		/* cancel the pending probing work */
+		chip = card->private_data;
+		hda = container_of(chip, struct hda_ft, chip);
+		cancel_work_sync(&hda->probe_work);
+
+		snd_card_free(card);
+		return 0;
+	}
+	return 0;
+}
+
+static void hda_ft_shutdown(struct platform_device *pdev)
+{
+	struct snd_card *card = dev_get_drvdata(&pdev->dev);
+	struct azx *chip;
+
+	if (!card)
+		return;
+	chip = card->private_data;
+	if (chip && chip->running)
+		azx_stop_chip(chip);
+}
+
+static const struct of_device_id hda_ft_of_match[] = {
+	{ .compatible = "phytium,hda" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, hda_ft_of_match);
+
+#ifdef CONFIG_ACPI
+static const struct acpi_device_id hda_ft_acpi_match[] = {
+	{ .id = "PHYT0006" },
+	{}
+};
+MODULE_DEVICE_TABLE(acpi, hda_ft_acpi_match);
+#else
+#define hda_ft_acpi_match NULL
+#endif
+
+static struct platform_driver ft_platform_hda = {
+	.driver = {
+		.name = "ft-hda",
+		.pm = hda_ft_pm,
+		.of_match_table = hda_ft_of_match,
+		.acpi_match_table = hda_ft_acpi_match,
+	},
+	.probe = hda_ft_probe,
+	.remove = hda_ft_remove,
+	.shutdown = hda_ft_shutdown,
+};
+
+module_platform_driver(ft_platform_hda);
+
+MODULE_DESCRIPTION("FT HDA bus driver");
+MODULE_LICENSE("GPL v2");
diff --git a/sound/pci/hda/hda_phytium.h b/sound/pci/hda/hda_phytium.h
new file mode 100644
index 000000000000..23412cb4c711
--- /dev/null
+++ b/sound/pci/hda/hda_phytium.h
@@ -0,0 +1,51 @@
+/*
+ *  hda_ft.h - Implementation of primary alsa driver code base
+ *                for Intel HD Audio of Phytium.
+ *
+ *  Copyright(c) 2018 Phytium Corporation. All rights reserved.
+ *
+ *  Copyright(c) 2018 Leo Hou <houyuefei@phytium.com.cn>
+ *
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License as published by the Free
+ *  Software Foundation; either version 2 of the License, or (at your option)
+ *  any later version.
+ *
+ *  This program is distributed in the hope that it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ *  more details.
+ *
+ *  You should have received a copy of the GNU General Public License along with
+ *  this program; if not, write to the Free Software Foundation, Inc., 59
+ *  Temple Place - Suite 330, Boston, MA  02111-1307, USA.
+ */
+#ifndef __SOUND_HDA_PHYTIUM_H__
+#define __SOUND_HDA_PHYTIUM_H__
+
+#include "hda_controller.h"
+
+struct hda_ft {
+	struct azx chip;
+	struct snd_pcm_substream *substream;
+	struct device *dev;
+	void __iomem *regs;
+
+	/* for pending irqs */
+	struct work_struct irq_pending_work;
+
+	/* sync probing */
+	struct completion probe_wait;
+	struct work_struct probe_work;
+
+	/* card list (for power_save trigger) */
+	struct list_head list;
+
+	/* extra flags */
+	unsigned int irq_pending_warned:1;
+	unsigned int probe_continued:1;
+
+};
+
+#endif
